
<!DOCTYPE html>


<html lang="en" data-content_root="./" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="viewport" content="width=device-width, initial-scale=1" />

    <title>27. Robustness &#8212; Advanced Quantitative Economics with Python</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css?v=03e43079" />
    <link rel="stylesheet" href="_static/styles/quantecon-book-theme.css?digest=9a92145369e9a304bdc7848b31c103894a5801ea" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css?v=13237357" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css?v=76b2166b" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.8ecb98da25f57f5357bf6f572d296f466b2cfe2517ffebfabe82451661e28f02.css?v=6644e6bb" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css?v=4fa983c6" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css?v=982b99e0" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css?v=b4b7a797" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.min.css?v=95c83b7e" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>


    <script src="_static/documentation_options.js?v=9eb32ce0"></script>
    <script src="_static/doctools.js?v=9a2dae69"></script>
    <script src="_static/sphinx_highlight.js?v=dc90522c"></script>
    <script src="_static/clipboard.min.js?v=a7894cd8"></script>
    <script src="_static/copybutton.js?v=f281be69"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js?v=4a39c7ea"></script>
    <script src="_static/scripts/quantecon-book-theme.js?digest=06ebc90d5139b434c2742937a4ef3b185cb93e2f"></script>
    <script src="_static/scripts/jquery.js?v=5d32c60e"></script>
    <script src="_static/scripts/_sphinx_javascript_frameworks_compat.js?v=2cd50e6c"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js?v=f930bc37"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-KZLV7PM9LL"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-KZLV7PM9LL');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js?v=c100c467"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-KZLV7PM9LL');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "arg\\,max", "argmin": "arg\\,min", "col": "col", "Span": "span", "epsilon": "\\varepsilon", "EE": "\\mathbb{E}", "PP": "\\mathbb{P}", "RR": "\\mathbb{R}", "NN": "\\mathbb{N}", "ZZ": "\\mathbb{Z}", "aA": "\\mathcal{A}", "bB": "\\mathcal{B}", "cC": "\\mathcal{C}", "dD": "\\mathcal{D}", "eE": "\\mathcal{E}", "fF": "\\mathcal{F}", "gG": "\\mathcal{G}", "hH": "\\mathcal{H}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'robustness';</script>
    <link rel="canonical" href="https://python-advanced.quantecon.org/robustness.html" />
    <link rel="icon" href="_static/lectures-favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="28. Robust Markov Perfect Equilibrium" href="rob_markov_perf.html" />
    <link rel="prev" title="26. Etymology of Entropy" href="entropy.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Thomas J. Sargent &amp; John Stachurski" />
<meta name="keywords" content="Python, QuantEcon, Quantitative Economics, Economics, Sloan, Alfred P. Sloan Foundation, Tom J. Sargent, John Stachurski" />
<meta name="description" content=This website presents a set of lectures on advanced quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="Robustness"/>
<meta name="twitter:description" content="This website presents a set of lectures on advanced quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="Robustness" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://python-advanced.quantecon.org/robustness.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents a set of lectures on advanced quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski." />
<meta property="og:site_name" content="Advanced Quantitative Economics with Python" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>

<!-- Override QuantEcon theme colors -->

    <span id="top"></span>

    <div class="qe-wrapper">

        <div class="qe-main">

            <div class="qe-page" id=robustness>

                <div class="qe-page__toc">

                    <div class="inner">

                        
                        <div class="qe-page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="qe-page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">27.1. Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#sets-of-models-imply-sets-of-values">27.1.1. Sets of models imply sets of values</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#inspiring-video">27.1.2. Inspiring video</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#other-references">27.1.3. Other references</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-model">27.2. The model</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#constructing-more-robust-policies">27.3. Constructing more robust policies</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#analyzing-the-bellman-equation">27.3.1. Analyzing the Bellman equation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#robustness-as-outcome-of-a-two-person-zero-sum-game">27.4. Robustness as outcome of a two-person zero-sum game</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#agent-2s-problem">27.4.1. Agent 2’s problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#using-agent-2s-problem-to-construct-bounds-on-value-sets">27.4.2. Using Agent 2’s problem to construct bounds on value sets</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-lower-bound">27.4.2.1. The lower bound</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#the-upper-bound">27.4.2.2. The upper bound</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#reshaping-the-set-of-values">27.4.2.3. Reshaping the set of values</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#agent-1s-problem">27.4.3. Agent 1’s problem</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#nash-equilibrium">27.4.4. Nash equilibrium</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-stochastic-case">27.5. The stochastic case</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-the-model">27.5.1. Solving the model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#computing-other-quantities">27.5.2. Computing other quantities</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#worst-case-value-of-a-policy">27.5.2.1. Worst-case value of a policy</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#implementation">27.6. Implementation</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#application">27.7. Application</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix">27.8. Appendix</a></li>
</ul>
                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="_static/qe-logo-large.png" class="logo logo-img" alt="logo"></a>
                                    
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/en/stable/">Jupyter Book</a></p>

                        </nav>

                        <div class="qe-page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="qe-page__header">

                    <div class="qe-page__header-copy">

                        <p class="qe-page__header-heading"><a href="intro.html">Advanced Quantitative Economics with Python</a></p>

                        <p class="qe-page__header-subheading">Robustness</p>

                    </div>
                    <!-- length 2, since its a string and empty dict has length 2 - {} -->
                        <p class="qe-page__header-authors" font-size="18">
                            
                                
                                    <a href="http://www.tomsargent.com/" target="_blank"><span>Thomas J. Sargent</span></a>
                                
                            
                                
                                    and <a href="https://johnstachurski.net/" target="_blank"><span>John Stachurski</span></a>
                                
                            
                        </p>


                </div> <!-- .page__header -->



                
                <main class="qe-page__content" role="main">
                    
                    <div>
                        
  <div id="qe-notebook-header" align="right" style="text-align:right;">
        <a href="https://quantecon.org/" title="quantecon.org">
                <img style="width:250px;display:inline;" width="250px" src="https://assets.quantecon.org/img/qe-menubar-logo.svg" alt="QuantEcon">
        </a>
</div><section class="tex2jax_ignore mathjax_ignore" id="robustness">
<h1><span class="section-number">27. </span>Robustness<a class="headerlink" href="#robustness" title="Link to this heading">#</a></h1>
<p id="index-0">In addition to what’s in Anaconda, this lecture will need the following libraries:</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>quantecon
</pre></div>
</div>
</div>
<details class="admonition hide below-input">
<summary aria-label="Toggle hidden content">
<p class="collapsed admonition-title">Show code cell output</p>
<p class="expanded admonition-title">Hide code cell output</p>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: quantecon in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (0.10.1)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: numba&gt;=0.49.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (0.61.0)
Requirement already satisfied: numpy&gt;=1.17.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (2.1.3)
Requirement already satisfied: requests in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (2.32.3)
Requirement already satisfied: scipy&gt;=1.5.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (1.15.3)
Requirement already satisfied: sympy in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from quantecon) (1.13.3)
Requirement already satisfied: llvmlite&lt;0.45,&gt;=0.44.0dev0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from numba&gt;=0.49.0-&gt;quantecon) (0.44.0)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from requests-&gt;quantecon) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from requests-&gt;quantecon) (3.7)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from requests-&gt;quantecon) (2.3.0)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from requests-&gt;quantecon) (2025.4.26)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.13/site-packages (from sympy-&gt;quantecon) (1.3.0)
</pre></div>
</div>
</div>
</details>
</div>
<section id="overview">
<h2><span class="section-number">27.1. </span>Overview<a class="headerlink" href="#overview" title="Link to this heading">#</a></h2>
<p id="index-1">This lecture modifies a Bellman equation to express a decision-maker’s doubts about  transition dynamics.</p>
<p>His specification doubts make the decision-maker want a <em>robust</em> decision rule.</p>
<p><em>Robust</em> means insensitive to misspecification of transition dynamics.</p>
<p>The decision-maker has a single <em>approximating model</em> of the transition dynamics.</p>
<p>He calls it <em>approximating</em> to acknowledge that he doesn’t completely trust it.</p>
<p>He fears that transition dynamics are  actually  determined by another model that he cannot describe explicitly.</p>
<p>All that he knows is that the actual data-generating model is in some (uncountable) set of models that surrounds his approximating model.</p>
<p>He quantifies the discrepancy between his approximating model and the genuine data-generating model by using a quantity called <em>entropy</em>.</p>
<p>(We’ll explain what entropy means below)</p>
<p>He wants a decision rule that will work well enough no matter which of those other models actually governs outcomes.</p>
<p>This is what it means for his decision rule to be “robust to misspecification of an approximating model”.</p>
<p>This may  sound like too much to ask for, but <span class="math notranslate nohighlight">\(\ldots\)</span>.</p>
<p><span class="math notranslate nohighlight">\(\ldots\)</span>  a <em>secret weapon</em> is available to design robust decision rules.</p>
<p>The secret weapon is max-min control theory.</p>
<p>A value-maximizing decision-maker enlists the aid of an (imaginary) value-minimizing model chooser to construct <em>bounds</em> on the value attained by a given decision rule under different models of the transition dynamics.</p>
<p>The original decision-maker uses those bounds to construct a decision rule with an assured performance level, no matter which model actually governs outcomes.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>In reading this lecture, please don’t think that our decision-maker is paranoid when he conducts a worst-case analysis. By designing a rule that works well against a worst-case, his intention is to construct a rule that will work well across a <em>set</em> of models.</p>
</div>
<p>Let’s start with some imports:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span><span class="w"> </span><span class="nn">pandas</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">pd</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">numpy</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">np</span>
<span class="kn">from</span><span class="w"> </span><span class="nn">scipy.linalg</span><span class="w"> </span><span class="kn">import</span> <span class="n">eig</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">matplotlib.pyplot</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">plt</span>
<span class="kn">import</span><span class="w"> </span><span class="nn">quantecon</span><span class="w"> </span><span class="k">as</span><span class="w"> </span><span class="nn">qe</span>
</pre></div>
</div>
</div>
</div>
<section id="sets-of-models-imply-sets-of-values">
<span id="rb-vec"></span><h3><span class="section-number">27.1.1. </span>Sets of models imply sets of values<a class="headerlink" href="#sets-of-models-imply-sets-of-values" title="Link to this heading">#</a></h3>
<p>Our “robust” decision-maker wants to know how well a given rule will work when he does not <em>know</em> a single transition law  <span class="math notranslate nohighlight">\(\ldots\)</span>.</p>
<p><span class="math notranslate nohighlight">\(\ldots\)</span> he wants to know  <em>sets</em> of values that will be attained by a given decision rule <span class="math notranslate nohighlight">\(F\)</span> under a <em>set</em> of transition laws.</p>
<p>Ultimately, he wants to design a decision rule <span class="math notranslate nohighlight">\(F\)</span> that shapes the <em>set</em> of values in ways that he prefers.</p>
<p>With this in mind, consider the following graph, which relates to a particular decision problem to be explained below</p>
<figure class="align-default">
<img alt="_images/kg0.png" src="_images/kg0.png" />
</figure>
<p>The figure shows a <em>value-entropy correspondence</em> for a particular decision rule <span class="math notranslate nohighlight">\(F\)</span>.</p>
<p>The shaded set is the graph of the correspondence, which maps entropy to a set of values associated with a set of models that surround the decision-maker’s approximating model.</p>
<p>Here</p>
<ul class="simple">
<li><p><em>Value</em> refers to a sum of discounted rewards obtained by applying the decision rule <span class="math notranslate nohighlight">\(F\)</span> when the state starts at some fixed initial state <span class="math notranslate nohighlight">\(x_0\)</span>.</p></li>
<li><p><em>Entropy</em> is a non-negative number that measures the size of a set of models surrounding the decision-maker’s approximating model.</p>
<ul>
<li><p>Entropy is zero when the set includes only the approximating model, indicating that the decision-maker completely trusts the approximating model.</p></li>
<li><p>Entropy is bigger, and the set of surrounding models is bigger, the less the decision-maker trusts the approximating model of the transition dynamics.</p></li>
</ul>
</li>
</ul>
<p>The shaded region indicates that for <strong>all</strong> models having entropy less than or equal to the number on the horizontal axis, the value obtained will be somewhere within the indicated set of values.</p>
<p>Now let’s compare sets of values associated with two different decision rules, <span class="math notranslate nohighlight">\(F_r\)</span> and <span class="math notranslate nohighlight">\(F_b\)</span>.</p>
<p>In the next figure,</p>
<ul class="simple">
<li><p>The red set shows the value-entropy correspondence for decision rule <span class="math notranslate nohighlight">\(F_r\)</span>.</p></li>
<li><p>The blue set shows the value-entropy correspondence for decision rule <span class="math notranslate nohighlight">\(F_b\)</span>.</p></li>
</ul>
<figure class="align-default">
<img alt="_images/kg.png" src="_images/kg.png" />
</figure>
<p>The blue correspondence is skinnier than the red correspondence.</p>
<p>This conveys the sense in which the decision rule <span class="math notranslate nohighlight">\(F_b\)</span> is <em>more robust</em> than the decision rule <span class="math notranslate nohighlight">\(F_r\)</span></p>
<ul class="simple">
<li><p><em>more robust</em> means that the set of values is less sensitive to <em>increasing misspecification</em> as measured by entropy</p></li>
</ul>
<p>Notice that the less robust rule <span class="math notranslate nohighlight">\(F_r\)</span> promises higher values for small misspecifications (small entropy).</p>
<p>(But it is more fragile in the sense that it is more sensitive to perturbations of the approximating model)</p>
<p>Below we’ll explain in detail how to construct these sets of values for a given <span class="math notranslate nohighlight">\(F\)</span>, but for now <span class="math notranslate nohighlight">\(\ldots\)</span>.</p>
<p>Here is a hint about the  <em>secret weapons</em> we’ll use to construct these sets</p>
<ul class="simple">
<li><p>We’ll use some min problems to construct the lower bounds</p></li>
<li><p>We’ll use some max problems to construct the upper bounds</p></li>
</ul>
<p>We will also describe how to choose <span class="math notranslate nohighlight">\(F\)</span> to shape the sets of values.</p>
<p>This will involve crafting a <em>skinnier</em> set at the cost of  a lower <em>level</em> (at least for low values of entropy).</p>
</section>
<section id="inspiring-video">
<h3><span class="section-number">27.1.2. </span>Inspiring video<a class="headerlink" href="#inspiring-video" title="Link to this heading">#</a></h3>
<p>If you want to understand more about why one serious quantitative researcher is interested in this approach, we recommend <a class="reference external" href="https://www.nobelprize.org/prizes/economic-sciences/2013/hansen/lecture/">Lars Peter Hansen’s Nobel lecture</a>.</p>
</section>
<section id="other-references">
<h3><span class="section-number">27.1.3. </span>Other references<a class="headerlink" href="#other-references" title="Link to this heading">#</a></h3>
<p>Our discussion in this lecture is based on</p>
<ul class="simple">
<li><p><span id="id1">[<a class="reference internal" href="zreferences.html#id161" title="Lars Peter Hansen and Thomas J Sargent. Wanting robustness in macroeconomics. Manuscript, Department of Economics, Stanford University., 2000.">Hansen and Sargent, 2000</a>]</span></p></li>
<li><p><span id="id2">[<a class="reference internal" href="zreferences.html#id160" title="L P Hansen and T J Sargent. Robustness. Princeton University Press, 2008.">Hansen and Sargent, 2008</a>]</span></p></li>
</ul>
</section>
</section>
<section id="the-model">
<h2><span class="section-number">27.2. </span>The model<a class="headerlink" href="#the-model" title="Link to this heading">#</a></h2>
<p>For simplicity, we present ideas in the context of a class of problems with linear transition laws and quadratic objective functions.</p>
<p>To fit in with <a class="reference external" href="https://python-intro.quantecon.org/lqcontrol.html">our earlier lecture on LQ control</a>, we will treat loss minimization rather than value maximization.</p>
<p>To begin, recall the <a class="reference external" href="https://python.quantecon.org/lqcontrol.html#infinite-horizon">infinite horizon LQ problem</a>, where an agent chooses a sequence of controls <span class="math notranslate nohighlight">\(\{u_t\}\)</span> to minimize</p>
<div class="math notranslate nohighlight" id="equation-rob-sih">
<span class="eqno">(27.1)<a class="headerlink" href="#equation-rob-sih" title="Link to this equation">#</a></span>\[\sum_{t=0}^{\infty} \beta^t
   \left\{
       x_t' R x_t +  u_t' Q u_t
   \right\}\]</div>
<p>subject to the linear law of motion</p>
<div class="math notranslate nohighlight" id="equation-rob-lom">
<span class="eqno">(27.2)<a class="headerlink" href="#equation-rob-lom" title="Link to this equation">#</a></span>\[x_{t+1} = A x_t + B u_t + C w_{t+1},
\qquad t = 0, 1, 2, \ldots\]</div>
<p>As before,</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_t\)</span> is <span class="math notranslate nohighlight">\(n \times 1\)</span>, <span class="math notranslate nohighlight">\(A\)</span> is <span class="math notranslate nohighlight">\(n \times n\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(u_t\)</span> is <span class="math notranslate nohighlight">\(k \times 1\)</span>, <span class="math notranslate nohighlight">\(B\)</span> is <span class="math notranslate nohighlight">\(n \times k\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(w_t\)</span> is <span class="math notranslate nohighlight">\(j \times 1\)</span>, <span class="math notranslate nohighlight">\(C\)</span> is <span class="math notranslate nohighlight">\(n \times j\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(n \times n\)</span> and <span class="math notranslate nohighlight">\(Q\)</span> is <span class="math notranslate nohighlight">\(k \times k\)</span></p></li>
</ul>
<p>Here <span class="math notranslate nohighlight">\(x_t\)</span> is the state, <span class="math notranslate nohighlight">\(u_t\)</span> is the control,  and <span class="math notranslate nohighlight">\(w_t\)</span> is a shock vector.</p>
<p>For now, we take <span class="math notranslate nohighlight">\(\{ w_t \} := \{ w_t \}_{t=1}^{\infty}\)</span> to be deterministic — a single fixed sequence.</p>
<p>We also allow for <em>model uncertainty</em> on the part of the agent solving this optimization problem.</p>
<p>In particular, the agent takes <span class="math notranslate nohighlight">\(w_t = 0\)</span> for all <span class="math notranslate nohighlight">\(t \geq 0\)</span> as a benchmark model but admits the possibility that this model might be wrong.</p>
<p>As a consequence, she also considers a set of alternative models expressed in terms of  sequences <span class="math notranslate nohighlight">\(\{ w_t \}\)</span> that are more or less “close” to the zero sequence.</p>
<p>She seeks a policy that will do well enough for a set of alternative models whose members are pinned down by  sequences <span class="math notranslate nohighlight">\(\{ w_t \}\)</span>.</p>
<p>A sequence <span class="math notranslate nohighlight">\(\{ w_t \}\)</span> might represent</p>
<ul class="simple">
<li><p>nonlinearities absent from the approximating model</p></li>
<li><p>time variations in parameters of the approximating model</p></li>
<li><p>omitted state variables in the approximating model</p></li>
<li><p>neglected history dependencies <span class="math notranslate nohighlight">\(\ldots\)</span></p></li>
<li><p>and other potential sources of misspecification</p></li>
</ul>
<p>Soon we’ll quantify the quality of a model specification in terms of the maximal size of the discounted sum <span class="math notranslate nohighlight">\(\sum_{t=0}^{\infty} \beta^{t+1}w_{t+1}' w_{t+1}\)</span>.</p>
</section>
<section id="constructing-more-robust-policies">
<h2><span class="section-number">27.3. </span>Constructing more robust policies<a class="headerlink" href="#constructing-more-robust-policies" title="Link to this heading">#</a></h2>
<p>If our agent takes <span class="math notranslate nohighlight">\(\{ w_t \}\)</span> as a given deterministic sequence, then, drawing on ideas in  earlier lectures on dynamic programming, we can anticipate Bellman equations such as</p>
<div class="math notranslate nohighlight">
\[
J_{t-1} (x)
= \min_u
\{
    x' R x + u' Q u + \beta \,
    J_t (Ax + B u + C w)
\}
\]</div>
<p>(Here <span class="math notranslate nohighlight">\(J\)</span> depends on <span class="math notranslate nohighlight">\(t\)</span> because the sequence <span class="math notranslate nohighlight">\(\{w_t\}\)</span> is not recursive)</p>
<p>Our tool for studying robustness is to construct a rule that works well even if an adverse sequence <span class="math notranslate nohighlight">\(\{ w_t \}\)</span> occurs.</p>
<p>In our framework, “adverse” means “loss increasing”.</p>
<p>As we’ll see, this will eventually lead us to construct a Bellman equation</p>
<div class="math notranslate nohighlight" id="equation-rb-wcb0">
<span class="eqno">(27.3)<a class="headerlink" href="#equation-rb-wcb0" title="Link to this equation">#</a></span>\[J (x) =
\min_u
\max_w
\{
    x' R x + u' Q u + \beta \,
    [J (Ax + B u + C w) - \theta w'w]
\}\]</div>
<p>Notice that we’ve added the penalty term <span class="math notranslate nohighlight">\(- \theta w'w\)</span>.</p>
<p>Since <span class="math notranslate nohighlight">\(w'w = \| w \|^2\)</span>, this term becomes influential when <span class="math notranslate nohighlight">\(w\)</span> moves away from the origin.</p>
<p>The penalty parameter <span class="math notranslate nohighlight">\(\theta\)</span> controls how much we penalize the maximizing agent for “harming” the minimizing agent.</p>
<p>By raising <span class="math notranslate nohighlight">\(\theta\)</span> more and more, we more and more limit the ability of maximizing agent to distort outcomes relative to the approximating model.</p>
<p>So bigger <span class="math notranslate nohighlight">\(\theta\)</span> is implicitly associated with smaller distortion sequences <span class="math notranslate nohighlight">\(\{w_t \}\)</span>.</p>
<section id="analyzing-the-bellman-equation">
<h3><span class="section-number">27.3.1. </span>Analyzing the Bellman equation<a class="headerlink" href="#analyzing-the-bellman-equation" title="Link to this heading">#</a></h3>
<p>So what does <span class="math notranslate nohighlight">\(J\)</span> in <a class="reference internal" href="#equation-rb-wcb0">(27.3)</a> look like?</p>
<p>As with the <a class="reference external" href="https://python-intro.quantecon.org/lqcontrol.html">ordinary LQ control model</a>, <span class="math notranslate nohighlight">\(J\)</span> takes the form <span class="math notranslate nohighlight">\(J(x) = x' P x\)</span> for some symmetric positive definite matrix <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>One of our main tasks will be to analyze and compute the matrix <span class="math notranslate nohighlight">\(P\)</span>.</p>
<p>Related tasks will be to study associated feedback rules for <span class="math notranslate nohighlight">\(u_t\)</span> and <span class="math notranslate nohighlight">\(w_{t+1}\)</span>.</p>
<p>First, using <a class="reference external" href="https://python-intro.quantecon.org/linear_algebra.html#la-mcalc">matrix calculus</a>, you will be able to verify that</p>
<div class="math notranslate nohighlight" id="equation-rb-mp0">
<span class="eqno">(27.4)<a class="headerlink" href="#equation-rb-mp0" title="Link to this equation">#</a></span>\[\begin{split}\begin{aligned}
\max_w
&amp;\{
    (Ax + B u + C w)' P (Ax + B u + C w) - \theta w'w
\}
\\
&amp; \hspace{20mm} = (Ax + Bu)' \mathcal D(P) (Ax + Bu)
\end{aligned}\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-rb-d">
<span class="eqno">(27.5)<a class="headerlink" href="#equation-rb-d" title="Link to this equation">#</a></span>\[\mathcal D(P) := P + PC (\theta I - C' P C)^{-1} C' P\]</div>
<p>and <span class="math notranslate nohighlight">\(I\)</span> is a <span class="math notranslate nohighlight">\(j \times j\)</span> identity matrix.  Substituting this expression for the maximum into <a class="reference internal" href="#equation-rb-wcb0">(27.3)</a> yields</p>
<div class="math notranslate nohighlight" id="equation-rb-owb">
<span class="eqno">(27.6)<a class="headerlink" href="#equation-rb-owb" title="Link to this equation">#</a></span>\[x'Px =
\min_u
\{
    x' R x + u' Q u + \beta \,
   (Ax + Bu)' \mathcal D(P) (Ax + Bu)
\}\]</div>
<p>Using similar mathematics, the solution to this minimization problem is <span class="math notranslate nohighlight">\(u  = - F x\)</span> where <span class="math notranslate nohighlight">\(F := (Q + \beta B' \mathcal D (P) B)^{-1} \beta B' \mathcal D(P) A\)</span>.</p>
<p>Substituting this minimizer back into <a class="reference internal" href="#equation-rb-owb">(27.6)</a> and working through the algebra gives
<span class="math notranslate nohighlight">\(x' P x = x' \mathcal B ( \mathcal D( P )) x\)</span> for all <span class="math notranslate nohighlight">\(x\)</span>, or, equivalently,</p>
<div class="math notranslate nohighlight">
\[
P = \mathcal B ( \mathcal D( P ))
\]</div>
<p>where <span class="math notranslate nohighlight">\(\mathcal D\)</span> is the operator defined in <a class="reference internal" href="#equation-rb-d">(27.5)</a> and</p>
<div class="math notranslate nohighlight">
\[
\mathcal B(P)
:= R - \beta^2 A' P B (Q + \beta B' P B)^{-1} B' P A + \beta A' P A
\]</div>
<p>The operator <span class="math notranslate nohighlight">\(\mathcal B\)</span> is the standard (i.e., non-robust) LQ Bellman operator, and <span class="math notranslate nohighlight">\(P = \mathcal B(P)\)</span> is the standard matrix Riccati equation coming from the
Bellman equation — see <a class="reference external" href="https://python.quantecon.org/lqcontrol.html#infinite-horizon">this discussion</a>.</p>
<p>Under some regularity conditions (see <span id="id3">[<a class="reference internal" href="zreferences.html#id160" title="L P Hansen and T J Sargent. Robustness. Princeton University Press, 2008.">Hansen and Sargent, 2008</a>]</span>), the operator <span class="math notranslate nohighlight">\(\mathcal B \circ \mathcal D\)</span>
has a unique positive definite fixed point, which we denote below by <span class="math notranslate nohighlight">\(\hat P\)</span>.</p>
<p>A robust policy, indexed by <span class="math notranslate nohighlight">\(\theta\)</span>, is <span class="math notranslate nohighlight">\(u  = - \hat F x\)</span> where</p>
<div class="math notranslate nohighlight" id="equation-rb-oc-ih">
<span class="eqno">(27.7)<a class="headerlink" href="#equation-rb-oc-ih" title="Link to this equation">#</a></span>\[\hat F
:= (Q + \beta B' \mathcal D (\hat P) B)^{-1} \beta B' \mathcal D(\hat P) A\]</div>
<p>We also define</p>
<div class="math notranslate nohighlight" id="equation-rb-kd">
<span class="eqno">(27.8)<a class="headerlink" href="#equation-rb-kd" title="Link to this equation">#</a></span>\[\hat K
:= (\theta I - C' \hat PC)^{-1} C'  \hat P (A - B \hat F)\]</div>
<p>The interpretation of <span class="math notranslate nohighlight">\(\hat K\)</span> is that <span class="math notranslate nohighlight">\(w_{t+1} = \hat K x_t\)</span> on the worst-case path of <span class="math notranslate nohighlight">\(\{x_t \}\)</span>, in the sense that this vector is the maximizer of <a class="reference internal" href="#equation-rb-mp0">(27.4)</a> evaluated at the fixed rule <span class="math notranslate nohighlight">\(u  = - \hat F x\)</span>.</p>
<p>Note that <span class="math notranslate nohighlight">\(\hat P, \hat F, \hat K\)</span> are all determined by the
primitives and <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>Note also that if <span class="math notranslate nohighlight">\(\theta\)</span> is very large, then <span class="math notranslate nohighlight">\(\mathcal D\)</span> is
approximately equal to the identity mapping.</p>
<p>Hence, when <span class="math notranslate nohighlight">\(\theta\)</span> is large,  <span class="math notranslate nohighlight">\(\hat P\)</span> and <span class="math notranslate nohighlight">\(\hat F\)</span> are approximately equal to their standard LQ values.</p>
<p>Furthermore, when <span class="math notranslate nohighlight">\(\theta\)</span> is large, <span class="math notranslate nohighlight">\(\hat K\)</span> is approximately equal to zero.</p>
<p>Conversely, smaller <span class="math notranslate nohighlight">\(\theta\)</span> is associated with greater fear of model misspecification and greater concern for robustness.</p>
</section>
</section>
<section id="robustness-as-outcome-of-a-two-person-zero-sum-game">
<h2><span class="section-number">27.4. </span>Robustness as outcome of a two-person zero-sum game<a class="headerlink" href="#robustness-as-outcome-of-a-two-person-zero-sum-game" title="Link to this heading">#</a></h2>
<p>What we have done above can be interpreted in terms of  a two-person zero-sum game in which <span class="math notranslate nohighlight">\(\hat F, \hat K\)</span> are Nash equilibrium objects.</p>
<p>Agent 1 is our original agent, who seeks to minimize loss in the LQ program while admitting the possibility of misspecification.</p>
<p>Agent 2 is an imaginary malevolent player.</p>
<p>Agent 2’s malevolence helps the original agent to compute bounds on his value function across a set of models.</p>
<p>We begin with agent 2’s problem.</p>
<section id="agent-2s-problem">
<span id="rb-a2"></span><h3><span class="section-number">27.4.1. </span>Agent 2’s problem<a class="headerlink" href="#agent-2s-problem" title="Link to this heading">#</a></h3>
<p>Agent 2</p>
<ol class="arabic simple">
<li><p>knows a fixed policy <span class="math notranslate nohighlight">\(F\)</span> specifying the behavior of agent 1, in the sense that <span class="math notranslate nohighlight">\(u_t = - F x_t\)</span> for all <span class="math notranslate nohighlight">\(t\)</span></p></li>
<li><p>responds by choosing a shock sequence <span class="math notranslate nohighlight">\(\{ w_t \}\)</span> from a set of paths sufficiently close to the benchmark sequence <span class="math notranslate nohighlight">\(\{0, 0, 0, \ldots\}\)</span></p></li>
</ol>
<p>A natural way to say “sufficiently close to the zero sequence” is to restrict the
summed inner product <span class="math notranslate nohighlight">\(\sum_{t=1}^{\infty} w_t' w_t\)</span> to be small.</p>
<p>However, to obtain a time-invariant recursive formulation, it turns out to be convenient to
restrict a  discounted inner product</p>
<div class="math notranslate nohighlight" id="equation-rb-dec">
<span class="eqno">(27.9)<a class="headerlink" href="#equation-rb-dec" title="Link to this equation">#</a></span>\[\sum_{t=1}^{\infty} \beta^t w_t' w_t \leq \eta\]</div>
<p>Now let <span class="math notranslate nohighlight">\(F\)</span> be a fixed policy, and let <span class="math notranslate nohighlight">\(J_F(x_0, \mathbf w)\)</span> be the
present-value cost of that policy given sequence <span class="math notranslate nohighlight">\(\mathbf w := \{w_t\}\)</span>
and initial condition <span class="math notranslate nohighlight">\(x_0 \in \mathbb R^n\)</span>.</p>
<p>Substituting <span class="math notranslate nohighlight">\(-F x_t\)</span> for <span class="math notranslate nohighlight">\(u_t\)</span> in <a class="reference internal" href="#equation-rob-sih">(27.1)</a>, this value can be written as</p>
<div class="math notranslate nohighlight" id="equation-rob-fpv">
<span class="eqno">(27.10)<a class="headerlink" href="#equation-rob-fpv" title="Link to this equation">#</a></span>\[J_F(x_0, \mathbf w) :=
    \sum_{t=0}^{\infty} \beta^t
    x_t' (R + F' Q F) x_t\]</div>
<p>where</p>
<div class="math notranslate nohighlight" id="equation-rob-lomf">
<span class="eqno">(27.11)<a class="headerlink" href="#equation-rob-lomf" title="Link to this equation">#</a></span>\[x_{t+1} = (A - B F) x_t + C w_{t+1}\]</div>
<p>and the initial condition <span class="math notranslate nohighlight">\(x_0\)</span> is as specified in the left side of <a class="reference internal" href="#equation-rob-fpv">(27.10)</a>.</p>
<p>Agent 2 chooses <span class="math notranslate nohighlight">\({\mathbf w}\)</span> to maximize agent 1’s loss <span class="math notranslate nohighlight">\(J_F(x_0, \mathbf w)\)</span> subject to <a class="reference internal" href="#equation-rb-dec">(27.9)</a>.</p>
<p>Using a Lagrangian formulation, we can express this problem as</p>
<div class="math notranslate nohighlight">
\[
\max_{\mathbf w}
 \sum_{t=0}^{\infty} \beta^t
  \left\{
    x_t' (R + F' Q F) x_t - \beta \theta (w_{t+1}' w_{t+1} - \eta)
  \right\}
\]</div>
<p>where <span class="math notranslate nohighlight">\(\{x_t\}\)</span> satisfied  <a class="reference internal" href="#equation-rob-lomf">(27.11)</a> and <span class="math notranslate nohighlight">\(\theta\)</span> is a Lagrange multiplier on constraint <a class="reference internal" href="#equation-rb-dec">(27.9)</a>.</p>
<p>For the moment, let’s take <span class="math notranslate nohighlight">\(\theta\)</span> as fixed, allowing us to drop the constant <span class="math notranslate nohighlight">\(\beta \theta \eta\)</span> term in the objective function, and hence write the problem as</p>
<div class="math notranslate nohighlight">
\[
\max_{\mathbf w}
 \sum_{t=0}^{\infty} \beta^t
  \left\{
    x_t' (R + F' Q F) x_t - \beta \theta w_{t+1}' w_{t+1}
  \right\}
\]</div>
<p>or, equivalently,</p>
<div class="math notranslate nohighlight" id="equation-rb-a2o">
<span class="eqno">(27.12)<a class="headerlink" href="#equation-rb-a2o" title="Link to this equation">#</a></span>\[\min_{\mathbf w}
\sum_{t=0}^{\infty} \beta^t
\left\{
    -x_t' (R + F' Q F) x_t + \beta \theta w_{t+1}' w_{t+1}
\right\}\]</div>
<p>subject to <a class="reference internal" href="#equation-rob-lomf">(27.11)</a>.</p>
<p>What’s striking about this optimization problem is that it is once again an LQ discounted dynamic programming problem, with <span class="math notranslate nohighlight">\(\mathbf w = \{ w_t \}\)</span> as the sequence of controls.</p>
<p>The expression for the optimal policy can be found by applying the usual LQ formula (<a class="reference external" href="https://python.quantecon.org/lqcontrol.html#infinite-horizon">see here</a>).</p>
<p>We denote it by <span class="math notranslate nohighlight">\(K(F, \theta)\)</span>, with the interpretation <span class="math notranslate nohighlight">\(w_{t+1} = K(F, \theta) x_t\)</span>.</p>
<p>The remaining step for agent 2’s problem is to set <span class="math notranslate nohighlight">\(\theta\)</span> to enforce the constraint <a class="reference internal" href="#equation-rb-dec">(27.9)</a>, which can be done by choosing <span class="math notranslate nohighlight">\(\theta = \theta_{\eta}\)</span> such that</p>
<div class="math notranslate nohighlight" id="equation-rb-pdt">
<span class="eqno">(27.13)<a class="headerlink" href="#equation-rb-pdt" title="Link to this equation">#</a></span>\[\beta \sum_{t=0}^{\infty} \beta^t x_t' K(F, \theta_\eta)' K(F, \theta_\eta) x_t = \eta\]</div>
<p>Here <span class="math notranslate nohighlight">\(x_t\)</span> is given by <a class="reference internal" href="#equation-rob-lomf">(27.11)</a> — which in this case becomes <span class="math notranslate nohighlight">\(x_{t+1} = (A - B F + CK(F, \theta)) x_t\)</span>.</p>
</section>
<section id="using-agent-2s-problem-to-construct-bounds-on-value-sets">
<span id="rb-a1"></span><h3><span class="section-number">27.4.2. </span>Using Agent 2’s problem to construct bounds on value sets<a class="headerlink" href="#using-agent-2s-problem-to-construct-bounds-on-value-sets" title="Link to this heading">#</a></h3>
<section id="the-lower-bound">
<h4><span class="section-number">27.4.2.1. </span>The lower bound<a class="headerlink" href="#the-lower-bound" title="Link to this heading">#</a></h4>
<p>Define the minimized object on the right side of problem <a class="reference internal" href="#equation-rb-a2o">(27.12)</a> as <span class="math notranslate nohighlight">\(R_\theta(x_0, F)\)</span>.</p>
<p>Because “minimizers minimize” we have</p>
<div class="math notranslate nohighlight">
\[
R_\theta(x_0, F) \leq \sum_{t=0}^\infty \beta^t \left\{  - x_t' (R + F' Q F) x_t \right\} + \beta \theta \sum_{t=0}^\infty \beta^t w_{t+1}' w_{t+1},
\]</div>
<p>where <span class="math notranslate nohighlight">\(x_{t+1} = (A - B F + CK(F, \theta)) x_t\)</span> and <span class="math notranslate nohighlight">\(x_0\)</span> is a given initial condition.</p>
<p>This inequality in turn implies the inequality</p>
<div class="math notranslate nohighlight" id="equation-rob-bound">
<span class="eqno">(27.14)<a class="headerlink" href="#equation-rob-bound" title="Link to this equation">#</a></span>\[R_\theta(x_0, F) - \theta \ {\rm ent}
\leq \sum_{t=0}^\infty \beta^t \left\{  - x_t' (R + F' Q F) x_t \right\}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
{\rm ent} := \beta \sum_{t=0}^\infty \beta^t w_{t+1}' w_{t+1}
\]</div>
<p>The left side of inequality <a class="reference internal" href="#equation-rob-bound">(27.14)</a> is a straight line with slope <span class="math notranslate nohighlight">\(-\theta\)</span>.</p>
<p>Technically, it is  a “separating hyperplane”.</p>
<p>At a particular value of entropy, the line is tangent to the lower bound of values  as a function of entropy.</p>
<p>In particular, the lower bound on the left side of <a class="reference internal" href="#equation-rob-bound">(27.14)</a> is attained when</p>
<div class="math notranslate nohighlight" id="equation-rb-pdt22">
<span class="eqno">(27.15)<a class="headerlink" href="#equation-rb-pdt22" title="Link to this equation">#</a></span>\[{\rm ent} =  \beta \sum_{t=0}^{\infty} \beta^t x_t' K(F, \theta)' K(F, \theta) x_t\]</div>
<p>To construct the <em>lower bound</em> on the set of values associated with all perturbations <span class="math notranslate nohighlight">\({\mathbf w}\)</span> satisfying the entropy constraint <a class="reference internal" href="#equation-rb-dec">(27.9)</a> at a  given entropy level, we proceed as follows:</p>
<ul class="simple">
<li><p>For a given <span class="math notranslate nohighlight">\(\theta\)</span>, solve the minimization problem <a class="reference internal" href="#equation-rb-a2o">(27.12)</a>.</p></li>
<li><p>Compute the minimizer <span class="math notranslate nohighlight">\(R_\theta(x_0, F)\)</span> and the associated entropy using <a class="reference internal" href="#equation-rb-pdt22">(27.15)</a>.</p></li>
<li><p>Compute the lower bound on the value function <span class="math notranslate nohighlight">\(R_\theta(x_0, F) - \theta \ {\rm  ent}\)</span> and plot it against <span class="math notranslate nohighlight">\({\rm ent}\)</span>.</p></li>
<li><p>Repeat the preceding three steps  for a range of values of <span class="math notranslate nohighlight">\(\theta\)</span> to trace out the lower bound.</p></li>
</ul>
<div class="admonition note">
<p class="admonition-title">Note</p>
<p>This procedure  sweeps  out a set of separating hyperplanes indexed by different values for  the Lagrange multiplier <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
</div>
</section>
<section id="the-upper-bound">
<h4><span class="section-number">27.4.2.2. </span>The upper bound<a class="headerlink" href="#the-upper-bound" title="Link to this heading">#</a></h4>
<p>To construct an <em>upper bound</em> we use a very similar procedure.</p>
<p>We simply replace the <em>minimization</em> problem <a class="reference internal" href="#equation-rb-a2o">(27.12)</a> with the <em>maximization</em> problem</p>
<div class="math notranslate nohighlight" id="equation-rba2omax">
<span class="eqno">(27.16)<a class="headerlink" href="#equation-rba2omax" title="Link to this equation">#</a></span>\[V_{\tilde \theta}(x_0, F) =  \max_{\mathbf w}
  \sum_{t=0}^{\infty} \beta^t
  \left\{
      -x_t' (R + F' Q F) x_t - \beta \tilde \theta w_{t+1}' w_{t+1}
  \right\}\]</div>
<p>where now <span class="math notranslate nohighlight">\(\tilde \theta  &gt;0\)</span>  penalizes the choice of <span class="math notranslate nohighlight">\({\mathbf w}\)</span> with larger entropy.</p>
<p>(Notice that <span class="math notranslate nohighlight">\(\tilde \theta = - \theta\)</span> in problem <a class="reference internal" href="#equation-rb-a2o">(27.12)</a>)</p>
<p>Because “maximizers maximize” we have</p>
<div class="math notranslate nohighlight">
\[
V_{\tilde \theta}(x_0, F) \geq \sum_{t=0}^\infty \beta^t \left\{  - x_t' (R + F' Q F) x_t \right\} - \beta \tilde \theta \sum_{t=0}^\infty \beta^t w_{t+1}' w_{t+1}
\]</div>
<p>which in turn implies the inequality</p>
<div class="math notranslate nohighlight" id="equation-robboundmax">
<span class="eqno">(27.17)<a class="headerlink" href="#equation-robboundmax" title="Link to this equation">#</a></span>\[V_{\tilde \theta}(x_0, F) + \tilde \theta \ {\rm ent} \geq \sum_{t=0}^\infty \beta^t \left\{  - x_t' (R + F' Q F) x_t \right\}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
{\rm ent} \equiv \beta \sum_{t=0}^\infty \beta^t w_{t+1}' w_{t+1}
\]</div>
<p>The left side of inequality <a class="reference internal" href="#equation-robboundmax">(27.17)</a> is a straight line with slope <span class="math notranslate nohighlight">\(\tilde \theta\)</span>.</p>
<p>The upper bound on the left side of <a class="reference internal" href="#equation-robboundmax">(27.17)</a> is attained when</p>
<div class="math notranslate nohighlight" id="equation-rbpdt223">
<span class="eqno">(27.18)<a class="headerlink" href="#equation-rbpdt223" title="Link to this equation">#</a></span>\[{\rm ent} =  \beta \sum_{t=0}^{\infty} \beta^t x_t' K(F, \tilde \theta)' K(F, \tilde \theta) x_t\]</div>
<p>To construct the <em>upper bound</em> on the set of values associated all perturbations <span class="math notranslate nohighlight">\({\mathbf w}\)</span> with a given entropy we proceed much as we did for the lower bound</p>
<ul class="simple">
<li><p>For a given <span class="math notranslate nohighlight">\(\tilde \theta\)</span>, solve the maximization problem <a class="reference internal" href="#equation-rba2omax">(27.16)</a>.</p></li>
<li><p>Compute the maximizer <span class="math notranslate nohighlight">\(V_{\tilde \theta}(x_0, F)\)</span> and the associated entropy using <a class="reference internal" href="#equation-rbpdt223">(27.18)</a>.</p></li>
<li><p>Compute the upper bound on the value function <span class="math notranslate nohighlight">\(V_{\tilde \theta}(x_0, F) + \tilde \theta \ {\rm ent}\)</span> and plot it against <span class="math notranslate nohighlight">\({\rm ent}\)</span>.</p></li>
<li><p>Repeat the preceding three steps  for a range of values of <span class="math notranslate nohighlight">\(\tilde \theta\)</span> to trace out the upper bound.</p></li>
</ul>
</section>
<section id="reshaping-the-set-of-values">
<h4><span class="section-number">27.4.2.3. </span>Reshaping the set of values<a class="headerlink" href="#reshaping-the-set-of-values" title="Link to this heading">#</a></h4>
<p>Now in the interest of <em>reshaping</em> these sets of values by choosing <span class="math notranslate nohighlight">\(F\)</span>, we turn to agent 1’s problem.</p>
</section>
</section>
<section id="agent-1s-problem">
<h3><span class="section-number">27.4.3. </span>Agent 1’s problem<a class="headerlink" href="#agent-1s-problem" title="Link to this heading">#</a></h3>
<p>Now we turn to agent 1, who solves</p>
<div class="math notranslate nohighlight" id="equation-rob-sihk">
<span class="eqno">(27.19)<a class="headerlink" href="#equation-rob-sihk" title="Link to this equation">#</a></span>\[\min_{\{u_t\}}
    \sum_{t=0}^{\infty} \beta^t
    \left\{
        x_t' R x_t + u_t' Q u_t - \beta \theta w_{t+1}' w_{t+1}
    \right\}\]</div>
<p>where  <span class="math notranslate nohighlight">\(\{ w_{t+1} \}\)</span>  satisfies <span class="math notranslate nohighlight">\(w_{t+1} = K x_t\)</span>.</p>
<p>In other words, agent 1 minimizes</p>
<div class="math notranslate nohighlight" id="equation-rob-sihk2">
<span class="eqno">(27.20)<a class="headerlink" href="#equation-rob-sihk2" title="Link to this equation">#</a></span>\[\sum_{t=0}^{\infty} \beta^t
    \left\{
        x_t' (R - \beta \theta K' K ) x_t + u_t' Q u_t
    \right\}\]</div>
<p>subject to</p>
<div class="math notranslate nohighlight" id="equation-rob-lomk">
<span class="eqno">(27.21)<a class="headerlink" href="#equation-rob-lomk" title="Link to this equation">#</a></span>\[x_{t+1} = (A + C K) x_t + B u_t\]</div>
<p>Once again, the expression for the optimal policy can be found <a class="reference external" href="https://python.quantecon.org/lqcontrol.html#infinite-horizon">here</a> — we denote
it by <span class="math notranslate nohighlight">\(\tilde F\)</span>.</p>
</section>
<section id="nash-equilibrium">
<span id="rb-eq"></span><h3><span class="section-number">27.4.4. </span>Nash equilibrium<a class="headerlink" href="#nash-equilibrium" title="Link to this heading">#</a></h3>
<p>Clearly, the <span class="math notranslate nohighlight">\(\tilde F\)</span> we have obtained depends on <span class="math notranslate nohighlight">\(K\)</span>, which, in agent 2’s problem,
depended on an initial policy <span class="math notranslate nohighlight">\(F\)</span>.</p>
<p>Holding all other parameters fixed, we can represent this relationship as a mapping <span class="math notranslate nohighlight">\(\Phi\)</span>, where</p>
<div class="math notranslate nohighlight">
\[
\tilde F = \Phi(K(F, \theta))
\]</div>
<p>The map <span class="math notranslate nohighlight">\(F \mapsto \Phi (K(F, \theta))\)</span> corresponds to a situation in which</p>
<ol class="arabic simple">
<li><p>agent 1 uses an arbitrary initial policy <span class="math notranslate nohighlight">\(F\)</span></p></li>
<li><p>agent 2 best responds to agent 1 by choosing <span class="math notranslate nohighlight">\(K(F, \theta)\)</span></p></li>
<li><p>agent 1 best responds to agent 2 by choosing <span class="math notranslate nohighlight">\(\tilde F = \Phi (K(F, \theta))\)</span></p></li>
</ol>
<p>As you may have already guessed, the robust policy <span class="math notranslate nohighlight">\(\hat F\)</span> defined in <a class="reference internal" href="#equation-rb-oc-ih">(27.7)</a> is a fixed point of the mapping <span class="math notranslate nohighlight">\(\Phi\)</span>.</p>
<p>In particular, for any given <span class="math notranslate nohighlight">\(\theta\)</span>,</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(K(\hat F, \theta) = \hat K\)</span>, where <span class="math notranslate nohighlight">\(\hat K\)</span> is as given in <a class="reference internal" href="#equation-rb-kd">(27.8)</a></p></li>
<li><p><span class="math notranslate nohighlight">\(\Phi(\hat K) = \hat F\)</span></p></li>
</ol>
<p>A sketch of the proof is given in <a class="reference internal" href="#rb-appendix"><span class="std std-ref">the appendix</span></a>.</p>
</section>
</section>
<section id="the-stochastic-case">
<h2><span class="section-number">27.5. </span>The stochastic case<a class="headerlink" href="#the-stochastic-case" title="Link to this heading">#</a></h2>
<p>Now we turn to the stochastic case, where the sequence <span class="math notranslate nohighlight">\(\{w_t\}\)</span> is treated as an IID sequence of random vectors.</p>
<p>In this setting, we suppose that our agent is uncertain about the <em>conditional probability distribution</em> of <span class="math notranslate nohighlight">\(w_{t+1}\)</span>.</p>
<p>The agent takes the standard normal distribution <span class="math notranslate nohighlight">\(N(0, I)\)</span> as the baseline conditional distribution, while admitting the possibility that other “nearby” distributions prevail.</p>
<p>These alternative conditional distributions of <span class="math notranslate nohighlight">\(w_{t+1}\)</span> might depend nonlinearly on the history  <span class="math notranslate nohighlight">\(x_s, s \leq t\)</span>.</p>
<p>To implement this idea, we need a notion of what it means for one distribution
to be near another one.</p>
<p>Here we adopt a very useful measure of closeness for distributions known as the <em>relative entropy</em>, or <a class="reference external" href="https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence">Kullback-Leibler divergence</a>.</p>
<p>For densities <span class="math notranslate nohighlight">\(p, q\)</span>, the Kullback-Leibler divergence of <span class="math notranslate nohighlight">\(q\)</span> from <span class="math notranslate nohighlight">\(p\)</span> is defined as</p>
<div class="math notranslate nohighlight">
\[
D_{KL} (p, q) := \int \ln \left[ \frac{p(x)}{q(x)} \right] p(x) \, dx
\]</div>
<p>Using this notation, we replace <a class="reference internal" href="#equation-rb-wcb0">(27.3)</a> with the stochastic analog</p>
<div class="math notranslate nohighlight" id="equation-rb-wcb1">
<span class="eqno">(27.22)<a class="headerlink" href="#equation-rb-wcb1" title="Link to this equation">#</a></span>\[J (x) =
\min_u
\max_{\psi \in \mathcal P}
\left\{
    x' R x + u' Q u + \beta \,
    \left[
    \int J (Ax + B u + C w) \, \psi(dw) - \theta D_{KL}(\psi, \phi)
    \right]
\right\}\]</div>
<p>Here <span class="math notranslate nohighlight">\(\mathcal P\)</span> represents the set of all densities on <span class="math notranslate nohighlight">\(\mathbb R^n\)</span> and <span class="math notranslate nohighlight">\(\phi\)</span> is the benchmark distribution <span class="math notranslate nohighlight">\(N(0, I)\)</span>.</p>
<p>The distribution <span class="math notranslate nohighlight">\(\phi\)</span> is chosen as the least desirable conditional distribution in terms of next period outcomes, while taking into account the penalty term <span class="math notranslate nohighlight">\(\theta D_{KL}(\psi, \phi)\)</span>.</p>
<p>This penalty term plays a role analogous to the one played by the deterministic penalty <span class="math notranslate nohighlight">\(\theta w'w\)</span> in <a class="reference internal" href="#equation-rb-wcb0">(27.3)</a>, since it discourages large deviations from the benchmark.</p>
<section id="solving-the-model">
<h3><span class="section-number">27.5.1. </span>Solving the model<a class="headerlink" href="#solving-the-model" title="Link to this heading">#</a></h3>
<p>The maximization problem in <a class="reference internal" href="#equation-rb-wcb1">(27.22)</a> appears highly nontrivial — after all,
we are maximizing over an infinite dimensional space consisting of the entire set of densities.</p>
<p>However, it turns out that the solution is  tractable, and in fact also falls within the class of normal distributions.</p>
<p>First, we note that <span class="math notranslate nohighlight">\(J\)</span> has the form <span class="math notranslate nohighlight">\(J(x) = x' P x + d\)</span> for some positive definite matrix <span class="math notranslate nohighlight">\(P\)</span> and constant real number <span class="math notranslate nohighlight">\(d\)</span>.</p>
<p>Moreover, it turns out that if <span class="math notranslate nohighlight">\((I - \theta^{-1} C' P C)^{-1}\)</span> is nonsingular, then</p>
<div class="math notranslate nohighlight" id="equation-rb-mls">
<span class="eqno">(27.23)<a class="headerlink" href="#equation-rb-mls" title="Link to this equation">#</a></span>\[\begin{split}\begin{aligned}
\max_{\psi \in \mathcal P}
&amp;\left\{
    \int (Ax + B u + C w)' P (Ax + B u + C w) \, \psi(dw) - \theta D_{KL}(\psi, \phi)
\right\}
\\
&amp; \hspace{20mm} = (Ax + Bu)' \mathcal D (P) (Ax + Bu) + \kappa(\theta, P)
\end{aligned}\end{split}\]</div>
<p>where</p>
<div class="math notranslate nohighlight">
\[
\kappa(\theta, P) := \theta \ln [ \det(I - \theta^{-1} C' P C)^{-1} ]
\]</div>
<p>and the maximizer is the Gaussian distribution</p>
<div class="math notranslate nohighlight" id="equation-rb-md">
<span class="eqno">(27.24)<a class="headerlink" href="#equation-rb-md" title="Link to this equation">#</a></span>\[\psi = N
\left(
    (\theta I -  C' P C)^{-1} C' P (Ax + Bu), (I - \theta^{-1} C' P C)^{-1}
\right)\]</div>
<p>Substituting the expression for the maximum into  Bellman equation
<a class="reference internal" href="#equation-rb-wcb1">(27.22)</a> and using <span class="math notranslate nohighlight">\(J(x) = x'Px + d\)</span> gives</p>
<div class="math notranslate nohighlight" id="equation-rb-wcb2">
<span class="eqno">(27.25)<a class="headerlink" href="#equation-rb-wcb2" title="Link to this equation">#</a></span>\[x' P x + d =
\min_u
\left\{
    x' R x + u' Q u + \beta \,
    (Ax + Bu)' \mathcal D (P) (Ax + Bu) + \beta \, [d + \kappa(\theta, P)]
\right\}\]</div>
<p>Since constant terms do not affect minimizers, the solution is the same as
<a class="reference internal" href="#equation-rb-owb">(27.6)</a>, leading to</p>
<div class="math notranslate nohighlight">
\[
x' P x + d
= x' \mathcal B( \mathcal D(P)) x + \beta \, [d + \kappa(\theta, P)]
\]</div>
<p>To solve this Bellman equation, we take <span class="math notranslate nohighlight">\(\hat P\)</span> to be the positive definite fixed point of
<span class="math notranslate nohighlight">\(\mathcal B \circ \mathcal D\)</span>.</p>
<p>In addition, we take <span class="math notranslate nohighlight">\(\hat d\)</span> as the real number solving <span class="math notranslate nohighlight">\(d = \beta \, [d + \kappa(\theta, P)]\)</span>, which is</p>
<div class="math notranslate nohighlight" id="equation-rb-hatd">
<span class="eqno">(27.26)<a class="headerlink" href="#equation-rb-hatd" title="Link to this equation">#</a></span>\[\hat d := \frac{\beta}{1 - \beta} \kappa(\theta, P)\]</div>
<p>The robust policy in this stochastic case is the minimizer in
<a class="reference internal" href="#equation-rb-wcb2">(27.25)</a>, which is once again <span class="math notranslate nohighlight">\(u  = - \hat F x\)</span> for <span class="math notranslate nohighlight">\(\hat F\)</span> given by <a class="reference internal" href="#equation-rb-oc-ih">(27.7)</a>.</p>
<p>Substituting the robust policy into <a class="reference internal" href="#equation-rb-md">(27.24)</a> we obtain the worst-case shock
distribution:</p>
<div class="math notranslate nohighlight">
\[
w_{t+1} \sim
N( \hat K x_t, (I - \theta^{-1} C' \hat PC)^{-1} )
\]</div>
<p>where <span class="math notranslate nohighlight">\(\hat K\)</span> is given by <a class="reference internal" href="#equation-rb-kd">(27.8)</a>.</p>
<p>Note that the mean of the worst-case shock distribution is equal to the same  worst-case <span class="math notranslate nohighlight">\(w_{t+1}\)</span> as in the earlier deterministic setting.</p>
</section>
<section id="computing-other-quantities">
<span id="rb-coq"></span><h3><span class="section-number">27.5.2. </span>Computing other quantities<a class="headerlink" href="#computing-other-quantities" title="Link to this heading">#</a></h3>
<p>Before turning to implementation, we briefly outline how to compute several other quantities of interest.</p>
<section id="worst-case-value-of-a-policy">
<h4><span class="section-number">27.5.2.1. </span>Worst-case value of a policy<a class="headerlink" href="#worst-case-value-of-a-policy" title="Link to this heading">#</a></h4>
<p>One thing we will be interested in doing is holding a policy fixed and
computing the discounted loss associated with that policy.</p>
<p>So let <span class="math notranslate nohighlight">\(F\)</span> be a given policy and let <span class="math notranslate nohighlight">\(J_F(x)\)</span> be
the associated loss, which, by analogy with <a class="reference internal" href="#equation-rb-wcb1">(27.22)</a>, satisfies</p>
<div class="math notranslate nohighlight">
\[
J_F(x) =
\max_{\psi \in \mathcal P}
\left\{
    x' (R + F'QF) x + \beta \,
    \left[
    \int J_F ( (A - BF)x + C w) \, \psi(dw) - \theta D_{KL}(\psi, \phi)
    \right]
\right\}
\]</div>
<p>Writing <span class="math notranslate nohighlight">\(J_F(x) = x'P_Fx + d_F\)</span> and applying the same argument used to
derive <a class="reference internal" href="#equation-rb-mls">(27.23)</a> we get</p>
<div class="math notranslate nohighlight">
\[
x' P_F x + d_F =
x' (R + F'QF) x + \beta \,
\left[
 x' (A - BF)' \mathcal D(P_F) (A - BF) x + d_F + \kappa(\theta, P_F)
\right]
\]</div>
<p>To solve this we take <span class="math notranslate nohighlight">\(P_F\)</span> to be the fixed point</p>
<div class="math notranslate nohighlight">
\[
P_F = R + F'QF + \beta (A - BF)' \mathcal D(P_F) (A - BF)
\]</div>
<p>and</p>
<div class="math notranslate nohighlight" id="equation-rb-hatd2">
<span class="eqno">(27.27)<a class="headerlink" href="#equation-rb-hatd2" title="Link to this equation">#</a></span>\[d_F
:= \frac{\beta}{1 - \beta} \kappa(\theta, P_F)
= \frac{\beta}{1 - \beta}
 \theta \ln [ \det(I - \theta^{-1} C' P_F C)^{-1} ]\]</div>
<p>If you skip ahead to <a class="reference internal" href="#rb-appendix"><span class="std std-ref">the appendix</span></a>, you will be able to
verify that <span class="math notranslate nohighlight">\(-P_F\)</span> is the solution to the Bellman equation in
agent 2’s problem <a class="reference internal" href="#rb-a2"><span class="std std-ref">discussed above</span></a>  — we use this in our
computations.</p>
</section>
</section>
</section>
<section id="implementation">
<h2><span class="section-number">27.6. </span>Implementation<a class="headerlink" href="#implementation" title="Link to this heading">#</a></h2>
<p>The <a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon.py</a> package provides a class called <code class="docutils literal notranslate"><span class="pre">RBLQ</span></code> for implementation of robust LQ optimal control.</p>
<p>The code can be found <a class="reference external" href="https://github.com/QuantEcon/QuantEcon.py/blob/master/quantecon/robustlq.py">on GitHub</a>.</p>
<p>Here is a brief description of the methods of the class</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">d_operator()</span></code> and <code class="docutils literal notranslate"><span class="pre">b_operator()</span></code> implement <span class="math notranslate nohighlight">\(\mathcal D\)</span>
and <span class="math notranslate nohighlight">\(\mathcal B\)</span> respectively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">robust_rule()</span></code> and <code class="docutils literal notranslate"><span class="pre">robust_rule_simple()</span></code> both solve for the
triple <span class="math notranslate nohighlight">\(\hat F, \hat K, \hat P\)</span>, as described in equations <a class="reference internal" href="#equation-rb-oc-ih">(27.7)</a> – <a class="reference internal" href="#equation-rb-kd">(27.8)</a> and the surrounding discussion</p>
<ul>
<li><p><code class="docutils literal notranslate"><span class="pre">robust_rule()</span></code> is more efficient</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">robust_rule_simple()</span></code> is more transparent and easier to follow</p></li>
</ul>
</li>
<li><p><code class="docutils literal notranslate"><span class="pre">K_to_F()</span></code> and <code class="docutils literal notranslate"><span class="pre">F_to_K()</span></code> solve the decision problems
of <a class="reference internal" href="#rb-a1"><span class="std std-ref">agent 1</span></a> and <a class="reference internal" href="#rb-a2"><span class="std std-ref">agent 2</span></a> respectively</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">compute_deterministic_entropy()</span></code> computes the left-hand side of <a class="reference internal" href="#equation-rb-pdt">(27.13)</a></p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">evaluate_F()</span></code> computes the loss and entropy associated with a given
policy — see <a class="reference internal" href="#rb-coq"><span class="std std-ref">this discussion</span></a></p></li>
</ul>
</section>
<section id="application">
<h2><span class="section-number">27.7. </span>Application<a class="headerlink" href="#application" title="Link to this heading">#</a></h2>
<p>Let us consider a monopolist similar to <a class="reference external" href="https://python-intro.quantecon.org/lqcontrol.html#lqc-mwac">this one</a>, but now facing model uncertainty.</p>
<p>The inverse demand function is <span class="math notranslate nohighlight">\(p_t = a_0 - a_1 y_t + d_t\)</span>.</p>
<p>where</p>
<div class="math notranslate nohighlight">
\[
d_{t+1} = \rho d_t + \sigma_d w_{t+1},
\quad \{w_t\} \stackrel{\textrm{IID}}{\sim} N(0,1)
\]</div>
<p>and all parameters are strictly positive.</p>
<p>The period return function for the monopolist is</p>
<div class="math notranslate nohighlight">
\[
r_t =  p_t y_t - \gamma \frac{(y_{t+1} - y_t)^2}{2} - c y_t
\]</div>
<p>Its objective is to maximize expected discounted profits, or, equivalently, to minimize <span class="math notranslate nohighlight">\(\mathbb E \sum_{t=0}^\infty \beta^t (- r_t)\)</span>.</p>
<p>To form a linear regulator problem, we take the state and control to be</p>
<div class="math notranslate nohighlight">
\[\begin{split}
x_t
= \begin{bmatrix}
      1 \\ y_t \\ d_t
  \end{bmatrix}
  \quad \text{and} \quad
  u_t = y_{t+1} - y_t
\end{split}\]</div>
<p>Setting <span class="math notranslate nohighlight">\(b := (a_0 - c) / 2\)</span> we define</p>
<div class="math notranslate nohighlight">
\[\begin{split}
R
= -
\begin{bmatrix}
   0 &amp;  b &amp; 0 \\
   b &amp; -a_1 &amp; 1/2 \\
   0 &amp; 1/2 &amp; 0
\end{bmatrix}
\quad \text{and} \quad
Q = \gamma / 2
\end{split}\]</div>
<p>For the transition matrices, we set</p>
<div class="math notranslate nohighlight">
\[\begin{split}
A
= \begin{bmatrix}
   1 &amp; 0 &amp; 0 \\
   0 &amp; 1 &amp; 0 \\
   0 &amp; 0 &amp; \rho
  \end{bmatrix},
\qquad
B
= \begin{bmatrix}
   0 \\
   1 \\
   0
  \end{bmatrix},
\qquad
C
= \begin{bmatrix}
   0 \\
   0 \\
   \sigma_d
  \end{bmatrix}
\end{split}\]</div>
<p>Our aim is to compute the value-entropy correspondences <a class="reference internal" href="#rb-vec"><span class="std std-ref">shown above</span></a>.</p>
<p>The parameters are</p>
<div class="math notranslate nohighlight">
\[
a_0 = 100, a_1 = 0.5, \rho = 0.9, \sigma_d = 0.05, \beta = 0.95, c = 2, \gamma = 50.0
\]</div>
<p>The standard normal distribution for <span class="math notranslate nohighlight">\(w_t\)</span> is understood as the
agent’s baseline, with uncertainty parameterized by <span class="math notranslate nohighlight">\(\theta\)</span>.</p>
<p>We compute value-entropy correspondences for two policies</p>
<ol class="arabic simple">
<li><p>The no concern for robustness policy <span class="math notranslate nohighlight">\(F_0\)</span>, which is the ordinary LQ
loss minimizer.</p></li>
<li><p>A “moderate” concern for robustness policy <span class="math notranslate nohighlight">\(F_b\)</span>, with <span class="math notranslate nohighlight">\(\theta = 0.02\)</span>.</p></li>
</ol>
<p>The code for producing the graph shown above, with blue being for the robust policy, is as follows</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Model parameters</span>

<span class="n">a_0</span> <span class="o">=</span> <span class="mi">100</span>
<span class="n">a_1</span> <span class="o">=</span> <span class="mf">0.5</span>
<span class="n">ρ</span> <span class="o">=</span> <span class="mf">0.9</span>
<span class="n">σ_d</span> <span class="o">=</span> <span class="mf">0.05</span>
<span class="n">β</span> <span class="o">=</span> <span class="mf">0.95</span>
<span class="n">c</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">γ</span> <span class="o">=</span> <span class="mf">50.0</span>

<span class="n">θ</span> <span class="o">=</span> <span class="mf">0.02</span>
<span class="n">ac</span> <span class="o">=</span> <span class="p">(</span><span class="n">a_0</span> <span class="o">-</span> <span class="n">c</span><span class="p">)</span> <span class="o">/</span> <span class="mf">2.0</span>

<span class="c1"># Define LQ matrices</span>

<span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">,</span>   <span class="n">ac</span><span class="p">,</span>   <span class="mf">0.</span><span class="p">],</span>
            <span class="p">[</span><span class="n">ac</span><span class="p">,</span> <span class="o">-</span><span class="n">a_1</span><span class="p">,</span>  <span class="mf">0.5</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">0.</span><span class="p">,</span>  <span class="mf">0.5</span><span class="p">,</span>  <span class="mf">0.</span><span class="p">]])</span>

<span class="n">R</span> <span class="o">=</span> <span class="o">-</span><span class="n">R</span>  <span class="c1"># For minimization</span>
<span class="n">Q</span> <span class="o">=</span> <span class="n">γ</span> <span class="o">/</span> <span class="mi">2</span>

<span class="n">A</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">1.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">0.</span><span class="p">,</span> <span class="mf">0.</span><span class="p">,</span> <span class="n">ρ</span><span class="p">]])</span>
<span class="n">B</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">1.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">0.</span><span class="p">]])</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">0.</span><span class="p">],</span>
            <span class="p">[</span><span class="mf">0.</span><span class="p">],</span>
            <span class="p">[</span><span class="n">σ_d</span><span class="p">]])</span>

<span class="c1"># ----------------------------------------------------------------------- #</span>
<span class="c1">#                                 Functions</span>
<span class="c1"># ----------------------------------------------------------------------- #</span>


<span class="k">def</span><span class="w"> </span><span class="nf">evaluate_policy</span><span class="p">(</span><span class="n">θ</span><span class="p">,</span> <span class="n">F</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Given θ (scalar, dtype=float) and policy F (array_like), returns the</span>
<span class="sd">    value associated with that policy under the worst case path for {w_t},</span>
<span class="sd">    as well as the entropy level.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">rlq</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">RBLQ</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">β</span><span class="p">,</span> <span class="n">θ</span><span class="p">)</span>
    <span class="n">K_F</span><span class="p">,</span> <span class="n">P_F</span><span class="p">,</span> <span class="n">d_F</span><span class="p">,</span> <span class="n">O_F</span><span class="p">,</span> <span class="n">o_F</span> <span class="o">=</span> <span class="n">rlq</span><span class="o">.</span><span class="n">evaluate_F</span><span class="p">(</span><span class="n">F</span><span class="p">)</span>
    <span class="n">x0</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">([[</span><span class="mf">1.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">],</span> <span class="p">[</span><span class="mf">0.</span><span class="p">]])</span>
    <span class="n">value</span> <span class="o">=</span> <span class="o">-</span> <span class="n">x0</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">P_F</span> <span class="o">@</span> <span class="n">x0</span> <span class="o">-</span> <span class="n">d_F</span>
    <span class="n">entropy</span> <span class="o">=</span> <span class="n">x0</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">O_F</span> <span class="o">@</span> <span class="n">x0</span> <span class="o">+</span> <span class="n">o_F</span>
    <span class="k">return</span> <span class="nb">list</span><span class="p">(</span><span class="nb">map</span><span class="p">(</span><span class="nb">float</span><span class="p">,</span> <span class="p">(</span><span class="n">value</span><span class="o">.</span><span class="n">item</span><span class="p">(),</span> <span class="n">entropy</span><span class="o">.</span><span class="n">item</span><span class="p">())))</span>


<span class="k">def</span><span class="w"> </span><span class="nf">value_and_entropy</span><span class="p">(</span><span class="n">emax</span><span class="p">,</span> <span class="n">F</span><span class="p">,</span> <span class="n">bw</span><span class="p">,</span> <span class="n">grid_size</span><span class="o">=</span><span class="mi">1000</span><span class="p">):</span>

<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Compute the value function and entropy levels for a θ path</span>
<span class="sd">    increasing until it reaches the specified target entropy value.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ==========</span>
<span class="sd">    emax: scalar</span>
<span class="sd">        The target entropy value</span>

<span class="sd">    F: array_like</span>
<span class="sd">        The policy function to be evaluated</span>

<span class="sd">    bw: str</span>
<span class="sd">        A string specifying whether the implied shock path follows best</span>
<span class="sd">        or worst assumptions. The only acceptable values are &#39;best&#39; and</span>
<span class="sd">        &#39;worst&#39;.</span>

<span class="sd">    Returns</span>
<span class="sd">    =======</span>
<span class="sd">    df: pd.DataFrame</span>
<span class="sd">        A pandas DataFrame containing the value function and entropy</span>
<span class="sd">        values up to the emax parameter. The columns are &#39;value&#39; and</span>
<span class="sd">        &#39;entropy&#39;.</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="k">if</span> <span class="n">bw</span> <span class="o">==</span> <span class="s1">&#39;worst&#39;</span><span class="p">:</span>
        <span class="n">θs</span> <span class="o">=</span> <span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1e-8</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">θs</span> <span class="o">=</span> <span class="o">-</span><span class="mi">1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1e-8</span><span class="p">,</span> <span class="mi">1000</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">)</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">DataFrame</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">θs</span><span class="p">,</span> <span class="n">columns</span><span class="o">=</span><span class="p">(</span><span class="s1">&#39;value&#39;</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">θ</span> <span class="ow">in</span> <span class="n">θs</span><span class="p">:</span>
        <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">θ</span><span class="p">]</span> <span class="o">=</span> <span class="n">evaluate_policy</span><span class="p">(</span><span class="n">θ</span><span class="p">,</span> <span class="n">F</span><span class="p">)</span>
        <span class="k">if</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">θ</span><span class="p">,</span> <span class="s1">&#39;entropy&#39;</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="n">emax</span><span class="p">:</span>
            <span class="k">break</span>

    <span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">how</span><span class="o">=</span><span class="s1">&#39;any&#39;</span><span class="p">)</span>
    <span class="k">return</span> <span class="n">df</span>


<span class="c1"># ------------------------------------------------------------------------ #</span>
<span class="c1">#                                    Main</span>
<span class="c1"># ------------------------------------------------------------------------ #</span>


<span class="c1"># Compute the optimal rule</span>
<span class="n">optimal_lq</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">LQ</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">beta</span><span class="o">=</span><span class="n">β</span><span class="p">)</span>
<span class="n">Po</span><span class="p">,</span> <span class="n">Fo</span><span class="p">,</span> <span class="n">do</span> <span class="o">=</span> <span class="n">optimal_lq</span><span class="o">.</span><span class="n">stationary_values</span><span class="p">()</span>

<span class="c1"># Compute a robust rule given θ</span>
<span class="n">baseline_robust</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">RBLQ</span><span class="p">(</span><span class="n">Q</span><span class="p">,</span> <span class="n">R</span><span class="p">,</span> <span class="n">A</span><span class="p">,</span> <span class="n">B</span><span class="p">,</span> <span class="n">C</span><span class="p">,</span> <span class="n">β</span><span class="p">,</span> <span class="n">θ</span><span class="p">)</span>
<span class="n">Fb</span><span class="p">,</span> <span class="n">Kb</span><span class="p">,</span> <span class="n">Pb</span> <span class="o">=</span> <span class="n">baseline_robust</span><span class="o">.</span><span class="n">robust_rule</span><span class="p">()</span>

<span class="c1"># Check the positive definiteness of worst-case covariance matrix to</span>
<span class="c1"># ensure that θ exceeds the breakdown point</span>
<span class="n">test_matrix</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">identity</span><span class="p">(</span><span class="n">Pb</span><span class="o">.</span><span class="n">shape</span><span class="p">[</span><span class="mi">0</span><span class="p">])</span> <span class="o">-</span> <span class="p">(</span><span class="n">C</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">Pb</span> <span class="o">@</span> <span class="n">C</span><span class="p">)</span> <span class="o">/</span> <span class="n">θ</span>
<span class="n">eigenvals</span><span class="p">,</span> <span class="n">eigenvecs</span> <span class="o">=</span> <span class="n">eig</span><span class="p">(</span><span class="n">test_matrix</span><span class="p">)</span>
<span class="k">assert</span> <span class="p">(</span><span class="n">eigenvals</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">(),</span> <span class="s1">&#39;θ below breakdown point.&#39;</span>


<span class="n">emax</span> <span class="o">=</span> <span class="mf">1.6e6</span>

<span class="n">optimal_best_case</span> <span class="o">=</span> <span class="n">value_and_entropy</span><span class="p">(</span><span class="n">emax</span><span class="p">,</span> <span class="n">Fo</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">robust_best_case</span> <span class="o">=</span> <span class="n">value_and_entropy</span><span class="p">(</span><span class="n">emax</span><span class="p">,</span> <span class="n">Fb</span><span class="p">,</span> <span class="s1">&#39;best&#39;</span><span class="p">)</span>
<span class="n">optimal_worst_case</span> <span class="o">=</span> <span class="n">value_and_entropy</span><span class="p">(</span><span class="n">emax</span><span class="p">,</span> <span class="n">Fo</span><span class="p">,</span> <span class="s1">&#39;worst&#39;</span><span class="p">)</span>
<span class="n">robust_worst_case</span> <span class="o">=</span> <span class="n">value_and_entropy</span><span class="p">(</span><span class="n">emax</span><span class="p">,</span> <span class="n">Fb</span><span class="p">,</span> <span class="s1">&#39;worst&#39;</span><span class="p">)</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">()</span>

<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">emax</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;Value&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;Entropy&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">grid</span><span class="p">()</span>

<span class="k">for</span> <span class="n">axis</span> <span class="ow">in</span> <span class="s1">&#39;x&#39;</span><span class="p">,</span> <span class="s1">&#39;y&#39;</span><span class="p">:</span>
    <span class="n">plt</span><span class="o">.</span><span class="n">ticklabel_format</span><span class="p">(</span><span class="n">style</span><span class="o">=</span><span class="s1">&#39;sci&#39;</span><span class="p">,</span> <span class="n">axis</span><span class="o">=</span><span class="n">axis</span><span class="p">,</span> <span class="n">scilimits</span><span class="o">=</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">))</span>

<span class="n">plot_args</span> <span class="o">=</span> <span class="p">{</span><span class="s1">&#39;lw&#39;</span><span class="p">:</span> <span class="mi">2</span><span class="p">,</span> <span class="s1">&#39;alpha&#39;</span><span class="p">:</span> <span class="mf">0.7</span><span class="p">}</span>

<span class="n">colors</span> <span class="o">=</span> <span class="s1">&#39;r&#39;</span><span class="p">,</span> <span class="s1">&#39;b&#39;</span>

<span class="n">df_pairs</span> <span class="o">=</span> <span class="p">((</span><span class="n">optimal_best_case</span><span class="p">,</span> <span class="n">optimal_worst_case</span><span class="p">),</span>
            <span class="p">(</span><span class="n">robust_best_case</span><span class="p">,</span> <span class="n">robust_worst_case</span><span class="p">))</span>


<span class="k">class</span><span class="w"> </span><span class="nc">Curve</span><span class="p">:</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span> <span class="o">=</span> <span class="n">x</span><span class="p">,</span> <span class="n">y</span>

    <span class="k">def</span><span class="w"> </span><span class="fm">__call__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">z</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">interp</span><span class="p">(</span><span class="n">z</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">x</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">y</span><span class="p">)</span>


<span class="k">for</span> <span class="n">c</span><span class="p">,</span> <span class="n">df_pair</span> <span class="ow">in</span> <span class="nb">zip</span><span class="p">(</span><span class="n">colors</span><span class="p">,</span> <span class="n">df_pairs</span><span class="p">):</span>
    <span class="n">curves</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="k">for</span> <span class="n">df</span> <span class="ow">in</span> <span class="n">df_pair</span><span class="p">:</span>
        <span class="c1"># Plot curves</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;entropy&#39;</span><span class="p">],</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;value&#39;</span><span class="p">]</span>
        <span class="n">x</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">a</span><span class="p">,</span> <span class="n">dtype</span><span class="o">=</span><span class="s1">&#39;float&#39;</span><span class="p">)</span> <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">))</span>
        <span class="n">egrid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="n">emax</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span>
        <span class="n">curve</span> <span class="o">=</span> <span class="n">Curve</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
        <span class="nb">print</span><span class="p">(</span><span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">egrid</span><span class="p">,</span> <span class="n">curve</span><span class="p">(</span><span class="n">egrid</span><span class="p">),</span> <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="o">**</span><span class="n">plot_args</span><span class="p">))</span>
        <span class="n">curves</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">curve</span><span class="p">)</span>
    <span class="c1"># Color fill between curves</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">fill_between</span><span class="p">(</span><span class="n">egrid</span><span class="p">,</span>
                    <span class="n">curves</span><span class="p">[</span><span class="mi">0</span><span class="p">](</span><span class="n">egrid</span><span class="p">),</span>
                    <span class="n">curves</span><span class="p">[</span><span class="mi">1</span><span class="p">](</span><span class="n">egrid</span><span class="p">),</span>
                    <span class="n">color</span><span class="o">=</span><span class="n">c</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.1</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&lt;matplotlib.lines.Line2D object at 0x7fa6e29c7610&gt;]
[&lt;matplotlib.lines.Line2D object at 0x7fa6e281b890&gt;]
[&lt;matplotlib.lines.Line2D object at 0x7fa6e2819090&gt;]
[&lt;matplotlib.lines.Line2D object at 0x7fa6e281bb10&gt;]
</pre></div>
</div>
<img alt="_images/1ad2c40cc3fc94687ac1686196b30ff4a3214b50575a2eb4ee48381d131d426f.png" src="_images/1ad2c40cc3fc94687ac1686196b30ff4a3214b50575a2eb4ee48381d131d426f.png" />
</div>
</div>
<p>Here’s another such figure, with <span class="math notranslate nohighlight">\(\theta = 0.002\)</span> instead of <span class="math notranslate nohighlight">\(0.02\)</span></p>
<figure class="align-default">
<img alt="_images/kg_small_theta.png" src="_images/kg_small_theta.png" />
</figure>
<p>Can you explain the different shape of the value-entropy correspondence for the robust policy?</p>
</section>
<section id="appendix">
<span id="rb-appendix"></span><h2><span class="section-number">27.8. </span>Appendix<a class="headerlink" href="#appendix" title="Link to this heading">#</a></h2>
<p>We sketch the proof only of the first claim in <a class="reference internal" href="#rb-eq"><span class="std std-ref">this section</span></a>,
which is that, for any given <span class="math notranslate nohighlight">\(\theta\)</span>, <span class="math notranslate nohighlight">\(K(\hat F, \theta) = \hat K\)</span>,
where <span class="math notranslate nohighlight">\(\hat K\)</span> is as given in <a class="reference internal" href="#equation-rb-kd">(27.8)</a>.</p>
<p>This is the content of the next lemma.</p>
<p><strong>Lemma.</strong> If <span class="math notranslate nohighlight">\(\hat P\)</span> is the fixed point of the map <span class="math notranslate nohighlight">\(\mathcal B \circ \mathcal D\)</span> and <span class="math notranslate nohighlight">\(\hat F\)</span> is the robust policy as given in <a class="reference internal" href="#equation-rb-oc-ih">(27.7)</a>, then</p>
<div class="math notranslate nohighlight" id="equation-rb-kft">
<span class="eqno">(27.28)<a class="headerlink" href="#equation-rb-kft" title="Link to this equation">#</a></span>\[K(\hat F, \theta) = (\theta I - C'\hat P C)^{-1} C' \hat P  (A - B \hat F)\]</div>
<p><em>Proof:</em> As a first step, observe that when <span class="math notranslate nohighlight">\(F = \hat F\)</span>, the Bellman equation associated with the LQ problem  <a class="reference internal" href="#equation-rob-lomf">(27.11)</a> – <a class="reference internal" href="#equation-rb-a2o">(27.12)</a> is</p>
<div class="math notranslate nohighlight" id="equation-rb-a2be">
<span class="eqno">(27.29)<a class="headerlink" href="#equation-rb-a2be" title="Link to this equation">#</a></span>\[\tilde P = -R - \hat F' Q \hat F -
\beta^2 (A - B \hat F)' \tilde P C
(\beta \theta I + \beta C' \tilde P C)^{-1} C' \tilde P (A - B \hat F) +
\beta (A - B \hat F)' \tilde P (A - B \hat F)\]</div>
<p>(revisit <a class="reference external" href="https://python.quantecon.org/lqcontrol.html#infinite-horizon">this discussion</a> if you don’t know where <a class="reference internal" href="#equation-rb-a2be">(27.29)</a> comes from) and the optimal policy is</p>
<div class="math notranslate nohighlight">
\[
w_{t+1} = - \beta (\beta \theta I + \beta C' \tilde P C)^{-1}
C' \tilde P (A - B \hat F) x_t
\]</div>
<p>Suppose for a moment that <span class="math notranslate nohighlight">\(- \hat P\)</span> solves the Bellman equation <a class="reference internal" href="#equation-rb-a2be">(27.29)</a>.</p>
<p>In this case, the policy becomes</p>
<div class="math notranslate nohighlight">
\[
w_{t+1} = (\theta I - C' \hat P C)^{-1} C' \hat P (A - B \hat F) x_t
\]</div>
<p>which is exactly the claim in <a class="reference internal" href="#equation-rb-kft">(27.28)</a>.</p>
<p>Hence it remains only to show that <span class="math notranslate nohighlight">\(- \hat P\)</span> solves <a class="reference internal" href="#equation-rb-a2be">(27.29)</a>,
or, in other words,</p>
<div class="math notranslate nohighlight">
\[
\hat  P =
R + \hat F' Q \hat F +
\beta (A - B \hat F)' \hat P C
(\theta I - C' \hat P C)^{-1} C' \hat P (A - B \hat F) +
\beta (A - B \hat F)' \hat P (A - B \hat F)
\]</div>
<p>Using the definition of <span class="math notranslate nohighlight">\(\mathcal D\)</span>, we can rewrite the right-hand
side more simply as</p>
<div class="math notranslate nohighlight">
\[
R + \hat F' Q \hat F +
\beta (A - B \hat F)' \mathcal D(\hat P) (A - B \hat F)
\]</div>
<p>Although it involves a substantial amount of algebra, it can be shown that the
latter is just <span class="math notranslate nohighlight">\(\hat P\)</span>.</p>
<div class="admonition hint">
<p class="admonition-title">Hint</p>
<p>Use the fact that <span class="math notranslate nohighlight">\(\hat P = \mathcal B( \mathcal D( \hat P))\)</span></p>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="qe-page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                    <p>A theme by <a href="https://quantecon.org">QuantEcon</a></p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="qe-sidebar bd-sidebar inactive" id="site-navigation">

                <div class="qe-sidebar__header">


                    Contents

                </div>

                <nav class="qe-sidebar__nav" id="qe-sidebar-nav" aria-label="Main navigation">
                    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tools and Techniques
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="orth_proj.html">
   1. Orthogonal Projections and Their Applications
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="stationary_densities.html">
   2. Continuous State Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="muth_kalman.html">
   3. Reverse Engineering a la Muth
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="discrete_dp.html">
   4. Discrete State Dynamic Programming
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  LQ Control
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="cons_news.html">
   5. Information and Consumption Smoothing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="smoothing.html">
   6. Consumption Smoothing with Complete and Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="smoothing_tax.html">
   7. Tax Smoothing with Complete and Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markov_jump_lq.html">
   8. Markov Jump Linear Quadratic Dynamic Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tax_smoothing_1.html">
   9. How to Pay for a War: Part 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tax_smoothing_2.html">
   10. How to Pay for a War: Part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tax_smoothing_3.html">
   11. How to Pay for a War: Part 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lqramsey.html">
   12. Optimal Taxation in an LQ Economy
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Multiple Agent Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="arellano.html">
   13. Default Risk and Income Fluctuations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="matsuyama.html">
   14. Globalization and Cycles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="coase.html">
   15. Coase’s Theory of the Firm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="match_transport.html">
   16. Composite Sorting
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dynamic Linear Economies
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="hs_recursive_models.html">
   17. Recursive Models of Dynamic Linear Economies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="growth_in_dles.html">
   18. Growth in Dynamic Linear Economies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lucas_asset_pricing_dles.html">
   19. Lucas Asset Pricing Using DLE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="irfs_in_hall_model.html">
   20. IRFs in Hall Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="permanent_income_dles.html">
   21. Permanent Income Model using the DLE Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rosen_schooling_model.html">
   22. Rosen Schooling Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cattle_cycles.html">
   23. Cattle Cycles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hs_invertibility_example.html">
   24. Shock Non Invertibility
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Risk, Model Uncertainty, and Robustness
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="five_preferences.html">
   25. Risk and Model Uncertainty
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="entropy.html">
   26. Etymology of Entropy
  </a>
 </li>
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   27. Robustness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rob_markov_perf.html">
   28. Robust Markov Perfect Equilibrium
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Time Series Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="arma.html">
   29. Covariance Stationary Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="estspec.html">
   30. Estimation of Spectra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="additive_functionals.html">
   31. Additive and Multiplicative Functionals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lu_tricks.html">
   32. Classical Control with Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classical_filtering.html">
   33. Classical Prediction and Filtering With Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="knowing_forecasts_of_others.html">
   34. Knowing the Forecasts of Others
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Asset Pricing and Finance
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="lucas_model.html">
   35. Asset Pricing II: The Lucas Asset Pricing Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="asset_pricing_lph.html">
   36. Elementary Asset Pricing Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="black_litterman.html">
   37. Two Modifications of Mean-Variance Portfolio Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="BCG_complete_mkts.html">
   38. Irrelevance of Capital Structures with Complete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="BCG_incomplete_mkts.html">
   39. Equilibrium Capital Structures with Incomplete Markets
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dynamic Programming Squared
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="un_insure.html">
   40. Optimal Unemployment Insurance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dyn_stack.html">
   41. Stackelberg Plans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calvo_machine_learn.html">
   42. Machine Learning a Ramsey Plan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calvo.html">
   43. Time Inconsistency of Ramsey Plans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calvo_abreu.html">
   44. Sustainable Plans for a Calvo Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="opt_tax_recur.html">
   45. Optimal Taxation with State-Contingent Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="amss.html">
   46. Optimal Taxation without State-Contingent Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="amss2.html">
   47. Fluctuating Interest Rates Deliver Fiscal Insurance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="amss3.html">
   48. Fiscal Risk and Government Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chang_ramsey.html">
   49. Competitive Equilibria of a Model of Chang
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chang_credible.html">
   50. Credible Government Policies in a Model of Chang
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="troubleshooting.html">
   51. Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   52. References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="status.html">
   53. Execution Statistics
  </a>
 </li>
</ul>

                </nav>

                <div class="qe-sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="qe-toolbar">

            <div class="qe-toolbar__inner">

                <ul class="qe-toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="intro.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                </ul>

                <ul class="qe-toolbar__links">
                    <li class="btn__search">
                        <form action="search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off" accesskey="k">
                            <i data-feather="search" id="search-icon"></i>
                        </form>
                    </li>
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="/_notebooks/robustness.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li class="download-pdf" id="downloadButton"><i data-feather="file"></i></li>
                    <!--
                    # Enable if looking for link to specific document hosted on GitHub
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-python-advanced.myst/blob/main/lectures/robustness.md" download><i data-feather="github"></i></a></li>
                    -->
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-python-advanced.myst" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="/_pdf/quantecon-python-advanced.pdf" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://colab.research.google.com/github/QuantEcon/lecture-python-advanced.notebooks/blob/main/robustness.ipynb">Colab</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/QuantEcon/lecture-python-advanced.notebooks" data-urlpath="tree/lecture-python-advanced.notebooks/robustness.ipynb" data-branch=main>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://colab.research.google.com/github/QuantEcon/lecture-python-advanced.notebooks/blob/main/robustness.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "robustness";
                const repoURL = "https://github.com/QuantEcon/lecture-python-advanced.notebooks";
                const urlPath = "tree/lecture-python-advanced.notebooks/robustness.ipynb";
                const branch = "main"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
  </body>
</html>