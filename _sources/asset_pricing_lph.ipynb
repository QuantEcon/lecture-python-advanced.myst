{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "32ccae83",
   "metadata": {},
   "source": [
    "# Elementary Asset Pricing Theory\n",
    "\n",
    "\n",
    "```{index} single: Elementary Asset Pricing\n",
    "```\n",
    "\n",
    "```{contents} Contents\n",
    ":depth: 2\n",
    "```\n",
    "\n",
    "## Overview\n",
    "\n",
    "This lecture is about  some implications of  asset-pricing theories that are based on the equation\n",
    "$E m R = 1,$ where $R$ is the gross return on an asset, $m$ is  a stochastic discount factor, and $E$ is a mathematical expectation with respect to a joint probability distribution of $R$ and $m$.\n",
    "\n",
    "Instances of this equation occur in  many models. \n",
    "\n",
    "```{note}\n",
    "Chapter 1 of {cite}`Ljungqvist2012` describes the role that this equation plays in a diverse set of\n",
    "models in macroeconomics, monetary economics, and public finance.\n",
    "```\n",
    "\n",
    "\n",
    "We aim to convey insights about empirical implications of this equation brought out in the work of Lars Peter Hansen {cite}`HansenRichard1987` and Lars Peter Hansen and Ravi Jagannathan {cite}`Hansen_Jagannathan_1991`. \n",
    "\n",
    "By following their footsteps, from  that single equation  we'll derive \n",
    "\n",
    "* a mean-variance frontier \n",
    "\n",
    "* a single-factor model of  excess  returns  \n",
    "\n",
    "\n",
    "To do this, we use two ideas:\n",
    "\n",
    "  * the equation $E m R =1 $ that is  implied by an application of a *law of one price*\n",
    "  \n",
    "  * a Cauchy-Schwartz inequality\n",
    "\n",
    "In particular, we'll apply a Cauchy-Schwartz inequality to a population linear least squares regression equation that is\n",
    "implied by $E m R =1$.\n",
    "\n",
    "We'll also describe how  practitioners have implemented the model using\n",
    "\n",
    "* cross sections of returns on many assets\n",
    "* time series of returns on various assets\n",
    "\n",
    "\n",
    "For background and basic  concepts about linear least squares projections, see our lecture [orthogonal projections and their applications](https://python-advanced.quantecon.org/orth_proj.html).\n",
    "\n",
    "As a sequel to the material here, please see our lecture [two modifications of mean-variance portfolio theory](https://python-advanced.quantecon.org/black_litterman.html).\n",
    "\n",
    "## Key Equation\n",
    "\n",
    "We  begin with a **key asset pricing equation**:\n",
    "\n",
    "\n",
    "$$\n",
    "E m R^i = 1  \n",
    "$$ (eq:EMR1)\n",
    "\n",
    "for $i=1, \\ldots, I$ and where\n",
    " \n",
    "$$\n",
    "\\begin{aligned}\n",
    "m &=\\text { stochastic discount factor } \\\\\n",
    "R^{i} &= \\text {random gross return  on asset }  i \\\\\n",
    "E &\\sim \\text { mathematical expectation }\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "The random gross return $R^i$ for every asset $i$ and the scalar stochastic discount factor $m$ \n",
    "live in a common probability space. \n",
    "\n",
    "{cite}`HansenRichard1987` and {cite}`Hansen_Jagannathan_1991` explain how **existence** of a scalar stochastic discount factor that verifies  equation\n",
    "{eq}`eq:EMR1` is implied by a __law of one price__ that requires that all portfolios of assets \n",
    "that bring the  same payouts  have the same price.\n",
    "\n",
    "They also explain how the __absence of an arbitrage__ opportunity implies that the stochastic discount\n",
    "factor $m \\geq 0$.\n",
    "\n",
    "In order to say something about the **uniqueness** of a stochastic discount factor, we  would have to impose more theoretical structure than we do in this\n",
    "lecture.   \n",
    "\n",
    "For example, in **complete markets** models like those illustrated in this lecture [equilibrium capital structures with incomplete markets](https://python-advanced.quantecon.org/BCG_incomplete_mkts.html),\n",
    "the stochastic discount factor is unique.\n",
    "\n",
    "In **incomplete markets** models like those illustrated in this lecture [the Aiyagari model](https://python.quantecon.org/aiyagari.html), the stochastic discount factor is not unique.\n",
    "\n",
    "\n",
    "## Implications of Key Equation\n",
    "\n",
    "\n",
    "We combine  key equation {eq}`eq:EMR1` with a  remark of Lars Peter Hansen that   \"asset pricing theory is all about covariances\".\n",
    "\n",
    "```{note}\n",
    "Lars Hansen's remark is a concise summary of ideas in {cite}`HansenRichard1987` and\n",
    "{cite}`Hansen_Jagannathan_1991`. Important foundations of these ideas were set down by\n",
    "{cite}`Ross_76`, {cite}`Ross_78`, {cite}`Harrison_Kreps_JET_79`, {cite}`Kreps_81`, and\n",
    "{cite}`Chamberlain_Rothschild`.\n",
    "```\n",
    "\n",
    "This remark of Lars Hansen refers to the fact that interesting restrictions can be deduced by recognizing that $E m R^i$ is a component of the covariance between $m $ and $R^i$ and then using that fact to rearrange  equation  {eq}`eq:EMR1`.\n",
    "\n",
    "\n",
    "Let's do this step by step.\n",
    "\n",
    "First note  that the definition of a\n",
    "covariance \n",
    "$\\operatorname{cov}\\left(m, R^{i}\\right)  =  E (m - E m)(R^i - E R^i) $\n",
    " implies that\n",
    "\n",
    "$$ \n",
    "E m R^i = E m E R^{i}+\\operatorname{cov}\\left(m, R^{i}\\right)\n",
    "$$\n",
    "\n",
    "Substituting this result into \n",
    " equation {eq}`eq:EMR1` gives\n",
    "\n",
    "$$\n",
    "1 = E m E R^{i}+\\operatorname{cov}\\left(m, R^{i}\\right) \n",
    "$$ (eq:EMR2) \n",
    " \n",
    "Next note that for a risk-free asset with non-random gross return $R^f$, equation\n",
    "{eq}`eq:EMR1` becomes \n",
    "\n",
    "$$\n",
    "1 = E R^f m = R^f E m.\n",
    "$$\n",
    "\n",
    "This is true because we can pull the constant $R^f$ outside the mathematical expectation. \n",
    "\n",
    "It follows that the  gross return on a risk-free asset is\n",
    "\n",
    "$$ \n",
    "R^{f}  = 1 / E(m) \n",
    "$$\n",
    "\n",
    "Using this formula for $R^f$ in equation {eq}`eq:EMR2` and rearranging, it follows that\n",
    "\n",
    "$$\n",
    "R^{f} = E R^{i}+\\operatorname{cov}\\left(m, R^{i} \\right) R^{f}\n",
    "$$\n",
    "\n",
    "which can be rearranged to become\n",
    "\n",
    "$$\n",
    "E R^i = R^{f}-\\operatorname{cov}\\left(m, R^{i}\\right) R^{f} . \n",
    "$$\n",
    "\n",
    "It follows that we can express an **excess return** $E R^{i}-R^{f}$ on asset $i$ relative to the risk-free rate as\n",
    "\n",
    "$$ \n",
    "E R^{i}-R^{f} = -\\operatorname{cov}\\left(m, R^{i}\\right) R^{f} \n",
    "$$ (eq:EMR3)\n",
    " \n",
    "\n",
    "Equation {eq}`eq:EMR3` can be rearranged to display important parts of asset pricing theory.\n",
    "\n",
    "\n",
    "## Expected Return - Beta Representation\n",
    "\n",
    "We can obtain the celebrated **expected-return-Beta -representation** for gross return $R^i$  by simply  rearranging excess return equation {eq}`eq:EMR3` to become\n",
    "\n",
    "$$\n",
    "E R^{i}=R^{f}+\\left(\\underbrace{\\frac{\\operatorname{cov}\\left(R^{i}, m\\right)}{\\operatorname{var}(m)}}_{\\quad\\quad\\beta_{i,m} = \\text{regression coefficient}}\\right)\\left(\\underbrace{-\\frac{\\operatorname{var}(m)}{E(m)}}_{\\quad\\lambda_{m} = \\text{price of risk}}\\right) \n",
    "$$\n",
    " \n",
    "or\n",
    "\n",
    "$$\n",
    "E R^{i}=R^{f}+\\beta_{i, m} \\lambda_{m} \n",
    "$$ (eq:ERbetarep)\n",
    "\n",
    "Here \n",
    "\n",
    " * $\\beta_{i,m}$ is a (population) least squares regression coefficient of gross return $R^i$ on stochastic discount factor $m$\n",
    " \n",
    " * $\\lambda_m$ is minus the variance of $m$ divided by the mean of $m$, an object that is sometimes called a **price of risk**.\n",
    "\n",
    "\n",
    "Because $\\lambda_m < 0$, equation {eq}`eq:ERbetarep` asserts that \n",
    "\n",
    "* assets whose returns are **positively** correlated with the stochastic discount factor (SDF) $m$ have expected returns **lower** than the risk-free rate $R^f$\n",
    " * assets whose returns are **negatively** correlated with the SDF $m$ have expected returns **higher** than the risk-free rate $R^f$\n",
    "\n",
    "These patterns will be discussed more below.\n",
    "\n",
    "In particular, we'll see that returns that are **perfectly** negatively correlated with the SDF $m$ have a special\n",
    "status:\n",
    "\n",
    "* they are on a **mean-variance frontier**\n",
    "\n",
    "\n",
    "Before we dive into that more, we'll pause to look at an example of an SDF.\n",
    " \n",
    "To interpret  representation {eq}`eq:ERbetarep`, the following widely used example helps.\n",
    " \n",
    "\n",
    "\n",
    " \n",
    "**Example** \n",
    "\n",
    "Let $c_t$ be the logarithm of the consumption of a _representative consumer_ or just a single consumer for whom we have consumption data.\n",
    "\n",
    "A popular model of $m$ is\n",
    "\n",
    "\n",
    "$$\n",
    "m_{t+1} = \\beta \\frac{U'(C_{t+1})}{U'(C_t)}\n",
    "$$\n",
    "\n",
    "where $C_t$ is consumption at time $t$, $\\beta = \\exp(-\\rho)$ is a discount **factor** with $\\rho$ being\n",
    "the discount **rate**, and $U(\\cdot)$ is a concave, twice-diffential utility function.\n",
    "\n",
    "For a constant relative risk aversion (CRRA) utility function $U(C) = \\frac{C^{1-\\gamma}}{1-\\gamma}$ utility\n",
    "function $U'(C) = C^{-\\gamma}$.\n",
    "\n",
    "In this case, letting $c_t = \\log(C_t)$, we can write $m_{t+1}$ as\n",
    "\n",
    "$$ \n",
    "m_{t+1} = \\exp(-\\rho) \\exp(- \\gamma(c_{t+1} - c_t)) \n",
    "$$\n",
    "\n",
    "where $ \\rho > 0$, $\\gamma > 0$.\n",
    "\n",
    "A popular model  for the growth of  log of consumption  is \n",
    "\n",
    "$$ \n",
    "c_{t+1} - c_t = \\mu + \\sigma_c \\epsilon_{t+1} \n",
    "$$\n",
    "\n",
    "where $\\epsilon_{t+1} \\sim {\\mathcal N}(0,1)$.\n",
    "\n",
    "Here $\\{c_t\\}$ is a random walk with drift $\\mu$, a good approximation to US per capital consumption growth.\n",
    "\n",
    "Again here \n",
    "\n",
    "  * $\\gamma >0$ is a coefficient of relative risk aversion\n",
    "  \n",
    "  * $\\rho >0 $ is a fixed intertemporal discount rate \n",
    "  \n",
    "So we have \n",
    "\n",
    "$$ \n",
    "m_{t+1} = \\exp(-\\rho) \\exp( - \\gamma \\mu - \\gamma \\sigma_c \\epsilon_{t+1}) \n",
    "$$\n",
    "\n",
    "In this case \n",
    "\n",
    "$$ \n",
    "E m_{t+1} = \\exp(-\\rho) \\exp \\left( - \\gamma \\mu + \\frac{\\sigma_c^2 \\gamma^2}{2} \\right) \n",
    "$$\n",
    "\n",
    "and \n",
    "\n",
    "$$ \n",
    "\\operatorname{var}(m_{t+1}) = E(m) [ \\exp(\\sigma_c^2 \\gamma^2) - 1) ] \n",
    "$$\n",
    "\n",
    "When $\\gamma >0$, it is true that  \n",
    "\n",
    " * when consumption growth is **high**, $m$ is **low**\n",
    " \n",
    " * when consumption growth is **low**, $m$ is **high**\n",
    " \n",
    "According to representation {eq}`eq:ERbetarep`, an asset with a gross return  $R^i$ that is expected to be **high** when consumption growth is **low**  has $\\beta_{i,m}$ positive and a **low** expected return.  \n",
    "\n",
    "   * because it has a high gross return when consumption growth is low, it is a good hedge against consumption risk. That justifies its low average return.\n",
    "\n",
    "An asset with an $R^i$ that is **low** when consumption growth is **low** has $\\beta_{i,m}$ negative and a **high** expected return.\n",
    "\n",
    "  * because it has a low gross return when consumption growth is low, it is a poor hedge against consumption risk. That  justifies its high average return.\n",
    "\n",
    "\n",
    " \n",
    "\n",
    "## Mean-Variance Frontier \n",
    "\n",
    "Now we'll derive the celebrated **mean-variance frontier**.\n",
    "\n",
    "We do this using a  method deployed by Lars Peter Hansen and Scott\n",
    "Richard {cite}`HansenRichard1987`. \n",
    "\n",
    "```{note}\n",
    "Methods of Hansen and Richard are described and used extensively by {cite}`Cochrane_2005`.\n",
    "```\n",
    "\n",
    "Their  idea was rearrange the key equation  {eq}`eq:EMR1`, namely,  $E m R^i = 1$, and then  to  apply a Cauchy-Schwarz inequality.\n",
    "\n",
    "A convenient way to remember the Cauchy-Schwartz inequality in our context is that it says that an  $R^2$ in any regression has to be  less than or equal to $1$.\n",
    "\n",
    "(Please note that here $R^2$ denotes the coefficient of determination in a regression, not a return on an asset!)\n",
    "\n",
    "Let's apply that idea to deduce\n",
    "\n",
    "\n",
    "$$ \n",
    "1= E\\left(m R^{i}\\right)=E(m) E\\left(R^{i}\\right)+\\rho_{m, R^{i}}\\frac{\\sigma(m)}{E(m)} \\sigma\\left(R^{i}\\right) \n",
    "$$ (eq:EMR5) \n",
    "\n",
    "where the correlation coefficient $\\rho_{m, R^i}$ is   defined as\n",
    "\n",
    "$$ \n",
    "\\rho_{m, R^i} \\equiv \\frac{\\operatorname{cov}\\left(m, R^{i}\\right)}{\\sigma(m) \\sigma\\left(R^{i}\\right)} \n",
    "$$\n",
    "\n",
    "\n",
    "and where $\\sigma(\\cdot)$ denotes the standard deviation of the variable in parentheses\n",
    "\n",
    "Equation {eq}`eq:EMR5`  implies\n",
    "\n",
    "$$\n",
    "E R^{i}=R^{f}-\\rho_{m, R^i} \\frac{\\sigma(m)}{E(m)} \\sigma\\left(R^{i}\\right)\n",
    "$$\n",
    "\n",
    "Because $\\rho_{m, R^i} \\in [-1,1]$, it follows that  $|\\rho_{m, R^i}| \\leq 1$ and that\n",
    "\n",
    "$$\n",
    "\\left|E R^i-R^{f}\\right| \\leqslant \\frac{\\sigma(m)}{E(m)} \\sigma\\left(R^{i}\\right) \n",
    "$$ (eq:ERM6)\n",
    "\n",
    "Inequality {eq}`eq:ERM6` delineates a **mean-variance frontier**\n",
    "\n",
    "(Actually, it looks more like a **mean-standard-deviation frontier**)\n",
    "\n",
    "\n",
    "Evidently, points on the frontier correspond to gross returns that are perfectly correlated\n",
    "(either positively or negatively) with the stochastic discount factor $m$.\n",
    "\n",
    "We summarize this observation  as\n",
    "\n",
    "$$\n",
    "\\rho_{m, R^{i}}=\\left\\{\\begin{array}{ll}\n",
    "+1 & \\implies R^i \\text { is on  lower frontier } \\\\\n",
    "-1 & \\implies R^i \\text { is on  an upper frontier }\n",
    "\\end{array}\\right.\n",
    "$$\n",
    "\n",
    "Now let's use matplotlib to draw a mean variance frontier.\n",
    "\n",
    "In drawing a frontier, we'll set $\\sigma(m) = .25$ and $E m = .99$, values roughly consistent with what many studies calibrate from quarterly US data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06718de8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY0AAAEbCAYAAAAmmNiPAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAABIdElEQVR4nO3deXxU9b34/9ebrCyBsAQSCfsWcNgRhSqgICSggLT9Kmqp1kpxxW62vbdobOvSe2+t9ueutV4sYntbrVQIogW17uwkJGyyBhICYUsI2d+/P84hGUKWCSQzk+T9fDzOg5k52/sMmXnPOZ/zeX9EVTHGGGN80SrQARhjjGk6LGkYY4zxmSUNY4wxPrOkYYwxxmeWNIwxxvjMkoYxxhifWdIwLZqITBKRzAbc3m0i8kk9lt8rIlMaYL/5ItL3Ate9RURWXWwMNWz7LhE57MbXuTH2UWV/L4jIosbeT0tmScMEtfp+CbdUqtpOVXfXtZyI9BYRFZFQr3WXqOrUho5JRMKAJ4Gpbny5Dbz98/42VHWBqv66IfdjzmVJw5gL5P3Fa6rVDYgEtlY3M5jev2CKJdhZ0mhh3MshPxWRLSJyWkT+KCLdRCRFRPJE5AMR6ei1/BUi8pmInBCRzSIyyWve7SKS4a63W0R+4DVvkohkisiPRSRHRLJE5PZa4rrN3UaeiOxxL5kMBl4AxrmXN064y84QkY0ickpEDohIstd2zv6S/q6I7BeRoyLyn17zW4vIayJyXETSgcuqxPFzEfnajSNdRG6oEuOnIvJ7ETkGJItIZxFZ5sbyFdCvjvf/OyKyT0RyveNy57Xy2n+uiPxVRDq581aKyL1Vlt8sInPcxyoi/et6f4CP3X9PuO/puKq/2EVkvIisFZGT7r/jveZ9KCK/dt+HPBFZJSJdqjnOgcB2r32t9orzHhHZCex0X7tTRHaJyDH3vbzEazsqIgtEZKf7f/asOGr623hNRH7jtf51IrLJ/fv9TESGec3bKyI/E5EtwGmxxOEbVbWpBU3AXuALnF+B3YEcYAMwEogAVgMPu8t2B3KB6Tg/MK51n8e482fgfEkKMBEoAEa58yYBpcCvgDB3GwVAx2piagucAga5z+OAS93HtwGfVFl+EjDUjWkYcBiY7c7rDSjwMtAaGA4UAYPd+U8A/wY6AT2ANCDTa9vfBi5xt30jcBqI84qlFLgPCHW3/ybwV/cYPMDBqvF6bXsIkA9McN/rJ93tTXHnP+D+38S7818Elrrz5gGfVtnWCSDCfa5A/3q8P6Fe26p4j9335TjwHfcY57rPO7vzPwS+Bga6x/8h8EQNx1vdvhR4391Pa+Aa4Cgwyj3m/w/4uMry7wLRQE/gCJBYy9/Ga8Bv3MejcP6+LwdCgO/i/P2ffc/2Aptw/g5aB/qz2VSmgAdgk5//w50Pyi1ez/8OPO/1/D7gH+7jnwGvV1n/PeC7NWz7H8BC9/Ek4EyVL4wc4Ipq1mvrfgF+s+qHt7ovhmrWfwr4vfv47BdVvNf8r4Cb3Me7z37puM/n45U0qtn2JmCWVyz7veaFACVAgtdrj9UUL/AQ8GaV4y6mMmlkAJO95se52w8FonASWC933qPAq17LViQNH9+fmpLGd4Cvqqz/OXCb+/hD4Jde8+4GVtaw3+r2pcA1Xs//CPyX1/N27jH39lr+Sq/5fwV+XtPfBucmjeeBX1eZvx2Y6PVZ+F5jft6a42SXp1qmw16Pz1TzvJ37uBfwbffU/oR7CeBKnC8zRCRJRL5wLyucwDmb8L5UkauqpV7PC7y2XUFVT+P8ql8AZInIchFJqCl4EblcRNaIyBEROemuV/USSXYN+70EOOA1b1+Vbc/zupxxAufswXvb3uvG4Hyh17i9Ks7Zt3vc3o3DvYC3vfadAZQB3VQ1D1gO3OQuexOwpLqd+Pj+1BZj1WPYh3PWeVZN762vvN+vc/anqvk470lD7K8X8OMqf7893H1WF4vxgSUNU5sDOGca0V5TW1V9QkQicM5S/gfnSy0aWIFzqareVPU9Vb0WJyFtw7m8BM4vzareAJYBPVS1A861bV/3m4XzxXFWz7MPRKSXu997cS7HRONcvvLetnc8R3AuL1W7vbr2LSJtAO/bUA8ASVXe70hVPejOXwrMFZFxOJd21tSwn9ren7rKWh/C+bL11hPnsltD8Y7hnP2JSFuc98SX/dV1LAeAR6u8n21UdWk9tmGqsKRhavNn4HoRmSYiISISKU4DdzwQjnMN+ghQKiJJwAXdtilOQ/xM9wujCOe6f5k7+zAQLyLhXqtEAcdUtVBExgI312N3fwV+ISId3eO4z2teW5wvkSNuXLfjnGlUS1XLgLdwGsTbiMgQnOvmNfkbcJ2IXOkez6849zP4AvCom7wQkRgRmeU1fwXOF+yvgL+oankN+6nt/TkClAM19elYAQwUkZtFJFREbsRpP3m3luO6GG8At4vICPeHyGPAl6q614d1q/vb8PYysMA98xIRaeveJBDVMKG3TJY0TI1U9QAwC/gPnC+bA8BPgVbu5ZL7cb6Ej+N8MS27wF21An6M86vzGE6j+t3uvNU4t2xmi8hR97W7gV+JSB5OO8Ff67GvR3Auh+wBVgGvn52hqunA73Cu4R/GaUz+tI7t3YtzuSQb53r6n2paUFW3AvfgfFFm4bxv3h0Ln8Z5D1e5x/YFTiPu2fWLcJLUFHcbNanx/VHVApz2kE/dSzZXVIkxF7gO5/8jF3gQuE5Vj9IIVPVfwCKcs9YsnBsrbqp1pUrV/W14b3sdcCfwDM57vQunHcRcBHEbhIwxxpg62ZmGMcYYn1nSMMYY4zNLGsYYY3xmScMYY4zPLGkYY4zxWbMu0NWlSxft3bt3oMMwxpgmZf369UdVNaa6eX5NGiLyKs494Dmqel6nKRERnHvVzxa3u01VN7jz9gJ5OJ2+SlV1TF376927N+vWrWu4AzDGmBZARGosh+Pvy1OvAYm1zE8CBrjTfJyCY96uVtURviQMY4wxDc+vSUNVP8bp8VuTWcBidXwBRItInH+iM8YYU5dgawjvzrlVJzOprHapOOUV1ovI/Jo2ICLzRWSdiKw7cuRII4ZqjDEtT7AljeoqlZ6tc/INVR2FcwnrHhGZUN0GVPUlVR2jqmNiYqptxzHGGHOBgi1pZHJumel4nCJ2qOrZf3OAt4Gxfo/OGGNauGBLGsuAeW4Z4yuAk6qa5ZY0joKKevtTccY5MMYY40f+vuV2Kc4woF1EJBN4GGf8aFT1BZxa/tNxShgXALe7q3bDGdHsbMxvqOpKf8ZujDFNgaqSdvAURaVljOndqcG379ekoapz65ivOOMNVH19NzC8seIyxpimrLxc2XjgOCmp2azcmk3m8TOM7dOJv/5gXIPvq1n3CDfGmOaqtKyctXuPk5KWxXtbszl8qojwkFZcOaAL908ewLWDuzXKfi1pGGNME1FcWs5nXx9lZVo276cfJvd0MRGhrZg0KIYkTxzXDO5K+8iwRo3BkoYxxgSxwpIy/r3zKClpWXyQfphThaW0DQ/hmsHdSPLEMnFgDG0j/PdVbknDGGOCzOmiUj7cfoSUtCzWbMvhdHEZ7SNDuXZILEmeWK4c0IXIsJCAxGZJwxhjgsCpwhJWZ+SQkpbFh9uPUFRaTue24cwccQmJnjjG9e1MeGjge0lY0jDGmAA5frqY9zMOk5Kaxae7cikuK6db+whuuqwHiZ44xvbpREir6gplBI4lDWOM8aOcvEJWbT3MyrRsPt+dS1m50j26NfPG9SJpaCwje3SkVZAlCm+WNIwxppEdOnGGlWnZrEzLZu2+Y6hC3y5t+cGEviR54vB0b4/beTnoWdIwxphGsC/3NClp2aSkZbP5wAkABnWL4v5rBpA0NJZB3aKaTKLwZknDGGMayK6cfFJSs0hJyyY96xQAQ7t34KfTBpHoiaVfTLsAR3jxLGkYY8wFUlUysvJYmeYkip05+QCM7tWRX84YzLRLY+nRqU2Ao2xYljSMMaYeVJXNmSdJSctiZVo2+3ILaCUwtk8nbr3iUqZdGktsh8hAh9loLGkYY0wdysqVDfuPsyI1i/fSsjl0spDQVsL4/l1YMLEf1w7pRpd2EYEO0y8saRhjTDVKy8r5cs8xVqRmsSr9MEfyiggPbcWEAV340dRBXDu4Gx3aNG6dp2BkScMYY1zFpeV8usup8/R++mGOF5TQOiyEqxNiSPTEcfWgGKIauSBgsLOkYYxp0QpLyvhoxxFWpmXzQcZh8gpLaRcRyuTBXUnyxDFxYAytwwNT5ykYWdIwxrQ4+UWlrNmWw8q0bNZsz6GguIzoNmEkXhpL0tBYvtG/CxGhliiq4+/hXl8FrgNyVNVTzXwBnsYZ8rUAuE1VN3jNDwHWAQdV9Tr/RG2MaQ5OFpTwQcZhUtKy+XjnEYpLy+nSLoIbRnYnyRPH5X07ERYS+IKAwc7fZxqvAc8Ai2uYnwQMcKfLgefdf89aCGQA7RsvRGNMc5GbX8SqdCdRfLbrKKXlSlyHSG65vCdJnjhG9+oYdAUBg52/xwj/WER617LILGCxO1b4FyISLSJxqpolIvHADOBR4Ed+CNcY0wTlnCrkva3ZrEjN5ss9uZQr9OzUhjuu7EOiJ5bh8dFBXRAw2AVbm0Z34IDX80z3tSzgKeBBIKq2DYjIfGA+QM+ePRslSGNMcMk8XsBKt87Thv3HUYV+MW25e1J/Ej2xXHpJ0ykIGOyCLWlU97+qInK2HWS9iEyqbQOq+hLwEsCYMWO0wSM0xgSFvUdPs8Ltlb0l8yQAg+Pa88MpA0nyxDKgW62/L80FCrakkQn08HoeDxwCvgXMFJHpQCTQXkT+rKq3BiBGY0wAqCo7c/JJSc0mJS2Lbdl5AAzvEc3PkxJIvDSW3l3aBjjK5i/YksYy4F4ReROnAfykqmYBv3An3DONn1jCMKb5U1W2HjpFilsQcPeR04jAmF4dWXTdEBI9sXSPbh3oMFsUf99yuxSYBHQRkUzgYSAMQFVfAFbg3G67C+eW29v9GZ8xJvDKy5WNB05UVI7NPH6GkFbCFX07cfs3+jBtSDe6tm++BQGDnb/vnppbx3wF7qljmQ+BDxsuKmNMoJWVK1/tOcbKtCze23qY7FOFhIUI3+jfhfuu6c+1Q2Lp1DY80GEagu/ylDGmhSgpK+fzr3NJScvm/fRsjuYXExHaiokDY/jZ0EFck9CNDq1bdp2nYGRJwxjjN4UlZXyy8ygpbp2nk2dKaBMewjUJTp2nSYNiaBthX0vBzP53jDGNqqC4lI+2HyElLZvV23LILyolKjKUawd3I9ETy4SBMUSGWZ2npsKShjGmweUVlrB6Ww4pqdl8uCOHwpJyOrUN57phcSR6YhnfrwvhoVbnqSmypGGMaRAnCopZlX6YlWnZfLLzKMVl5XSNiuDbo3uQ5IllbJ9OhFpBwCbPkoYx5oIdyStiVXo2K9Oy+fzrXErLle7RrfnOuF4keWIZ1bOj1XlqZixpGGPqJevkmYo6T+v2HqNcoXfnNnz/qr4keWIZFt/B6jw1Y5Y0jDF1OnCsoKJX9sb9JwAY2K0d914zgCRPLAmxUZYoWghLGsaYau3Kya/olb310CkAPN3b89Npg0j0xNIvpl2AIzSBYEnDGAM4dZ62ZeeRkpbNyrQsdhzOB2Bkz2j+Y3oCiZfG0bNzmwBHaQLNkoYxLZiqsiXzZEWi2JtbQCuBy3p3Ivn6IUzzxBLXwQoCmkqWNIxpYcrLlfX7j5OSms17W7M5eOIMoa2Ecf06M39CP64d0o2YqIhAh2mClCUNY1qA0rJyvtpzzDmj2JrNkbwiwkNacdWALjwwZQDXDulGdBsrCGjqZknDmGaquLScT78+ysrUbFalZ3O8oITWYSFMGhRDoieWaxK6EhVpBQFN/VjSMKYZKSwp4+MdR1iZls37GYfJKyylXUQokwd3JckTy8SBXWkdbnWezIWzpGFME3e6qJQ123NISctmzbYcCorL6NA6jGmXxpLkieXKAV2ICLVEYRqGJQ1jmqCTZ0pYve0wKanZfLTjCEWl5XRpF87skd1J8sRyRd/OhFmdJ9MI/D3c66vAdUCOqnqqmS/A0zhDvhYAt6nqBhGJBD4GInBi/puqPuy/yI0JvGOni3k/3Snf8emuo5SUKXEdIpk7tidJnljG9O5EiNV5Mo3M32carwHPAItrmJ8EDHCny4Hn3X+LgGtUNV9EwoBPRCRFVb9o/JCNCZycU4W8t9VJFF/szqVcoUen1tz+jT4kemIZER9tBQGNX/l7jPCPRaR3LYvMAha7Y4V/ISLRIhKnqllAvrtMmDtp40ZrTGAcPOEUBFyZlsW6fcdRhb4xbblrUj+SPHFcekl7q/NkAibY2jS6Awe8nme6r2WJSAiwHugPPKuqX1a3ARGZD8wH6NmzZ+NGa0wD2Xv0dEWv7M2ZJwFIiI3igckDSRoay4Cu7SxRmKAQbEmjuk+FAqhqGTBCRKKBt0XEo6pp5y2s+hLwEsCYMWPsbMQEJVVlZ04+KanZpKRlsS07D4Bh8R14MHEQSZ44+nRpG+AojTlfsCWNTKCH1/N44JD3Aqp6QkQ+BBKB85KGMcFKVdl66JQ7FkUWXx85jQiM7tmRX84YTKInlviOVhDQBLdgSxrLgHtF5E2cBvCTqpolIjFAiZswWgNTgN8GMlBjfFFermzKPOG2UWSz/5hTEPCKvp25bXxvpl0aS9f2kYEO0xif+fuW26XAJKCLiGQCD+M0aqOqLwArcG633YVzy+3t7qpxwP+67RqtgL+q6rv+jN0YX5WVK+v2unWe0rLJPlVIWIgwvl8X7rm6H9cOiaVTW6vzZJomf989NbeO+QrcU83rW4CRjRWXMRerpKycL3bnkpKWzaqt2RzNLyY8tBUTB8bwoGcQkwd3o0Nrq/Nkmr5guzxlTJNRVFrGp7uOkpLq1Hk6UVBCm/AQrh7UlaShsVw9qCttI+wjZpoX+4s2ph7OFJfx0Q6nztPqjBzyikqJigxlyuBuJHpimTgwhsgwq/Nkmi9LGsbUIa+whNXbcliZls2H249wpqSMjm3CmD40jsShsYzv19kKApoWw5KGMdU4WVDC+xmHWZmWxcc7jlJcVk5MVATfGh1PkieWsX06EWoFAU0LZEnDGNfR/CJWbT1MSloWn3+dS2m5ckmHSG69ohdJQ2MZ3bOj1XkyLZ4lDdOiZZ88WxAwi6/2HKNcoVfnNtxxVR+SPHEMj+9g5TuM8WJJw7Q4B44VVPTK3rD/BAADurbj3qv7k+iJY3BclCUKY2pgScO0CF8fya9IFGkHTwFw6SXt+cnUgSR64ujftV2AIzSmabCkYZolVWX74TxSUp1e2dsPOwUBR/SI5hdJCSR54ujZ2eo8GVNfljRMs6GqpB48WVG+Y89RpyDgZb078fD1Q0j0xBLXoXWgw2yxSkpKyMzMpLCwMNChGFdkZCTx8fGEhflercCShmnSysuVDfuPVySKgyfOENJKGNe3M3dc2Yepl3aja5QVBAwGmZmZREVF0bt3b2szCgKqSm5uLpmZmfTp08fn9SxpmCantKycr/Yeq6gcm5NXRHhIK64c0IWFUwZw7eBudLSCgEGnsLDQEkYQERE6d+7MkSNH6rWeJQ3TJBSXlvPZ10dZmZbNqvTDHDtdTGRYKyYNdOs8JXSlfaQVBAx2ljCCy4X8f1jSMEGrsKSMf+88SkpaFh+kH+ZUYSntIkK5JqErSZ5YJg6KoU24/Qkb40/2iTNB5XRRKR9uP0JKWhZrtuVwuriM9pGhXDskliRPLFcO6GIFAY0JIEsaJuBOFZbwr4zDpKRm89GOIxSVltO5bTgzR1xCoieOcX07Ex5qdZ5M07Nw4UIef/xx2rSp/vbu9evXs27dOn7wgx/4ObILZ0nDBMSx08W8n55NSlo2n+46SkmZ0q19BDdd1oNETxxj+3QixOo8mSaioKCABx54gKioKJYsWcKTTz5JYmIiIsKpU6dISkpixowZbN26lfHjx/P++++TnJzM6NGj+f3vf29JoyYi8ipwHZCjqp5q5gvwNM6QrwXAbaq6QUR6AIuBWKAceElVn/Zf5KYh5OQV8t5Wp3LsF7uPUVauxHdszW3je5PoiWNkj2grCGgC6vHHHyc3N5fvf//7JCQk+Lzec889x7e+9S2mTp3Kvn37uPnmm1m9ejVDhgxh48aNzJkzh4ULFzJ79mzuvPNOoqOj2bdvHx6Ph8jISA4fPky3bt0a9FgWLVrEr3/96wbdJjjjbfvTa0BiLfOTgAHuNB943n29FPixqg4GrgDuEZEhjRinaSCHTpzh1U/28P9e+JzLH/sXi/6RRtaJQhZM7Mu7913Jvx+8mv+cMYTRvayCrPGPF198kdjYWIYPH06/fv1YvHgxAF9++SVLly6lT58+9UoYAGlpaYwfP54zZ87QurXTgfTYsWNER0ezadMmpk2bRklJCZ07d6ZVq1akpaUxdOhQADp27MipU6d82s+ZM2eYOHEiZWVlNR4HQHZ2NqWlpRQXFzNhwgRKS0vrdTy18fcY4R+LSO9aFpkFLHbHCv9CRKJFJE5Vs4Asdxt5IpIBdAfSGz1oU2/7ck+TkuZcetp84AQACbFRLJw8gCRPHAO7tbNbL03AbNmyheTkZBYsWMBXX33F9OnTmTdvHgMHDmTSpEncc8891a734Ycf8tprr/Haa6+dN2/OnDncfffdtG3bll/+8pcADBw4kJUrV7Jr1y4GDhzIli1bGDx4MAB79+6lZ8+eABw8eLDicV1effVV5syZQ0hISI3HAbBx40ZGjBhBeHg4kydP5i9/+Qu33HJLfd+qagVbm0Z34IDX80z3tayzL7hJZyTwZXUbEJH5OGcpPv9HmIu3K8ep85SSlk16lvOraWj3DjyYOIjES2PpG2MFAU1wSE1N5Vvf+hYAffr0ITzc6Qi6adMmhg8ffkHbnDlzJjNnzjzntaFDh/Lcc8/xxz/+EYARI0YwYsQIAF5//XUA8vPzad++PRERERXrbd68mfvuu4+jR4+ybds2VJWHHnqIRx55hCVLlvDGG2/Uehxnj2XOnDkAzJ49m1/84hfNNmlU9/NTK2aKtAP+DjygqtWez6nqS8BLAGPGjNHqljEXT1VJzzrlVo7NZldOPgCje3XklzMGM+3SWHp0soKAJvikpqYyaNAgVJVnnnmGRx99FHC+rK+66qoG24+IcMstt1BQUFDj3VOHDh3ipz/9acXzwsJCbrzxRhYvXszYsWNZtGgRhYWFJCcnU1xczO7du+ndu3etxwGwa9cuBgwYAIDH42Ht2rUNdlzBljQygR5ez+OBQwAiEoaTMJao6lsBiK3FU1U2HThRkSj2HyuglcDlfTozb1wvpl0aS7f2VufJ1O2Rf24l/ZBv1/F9NeSS9jx8/aW1LnPgwAHy8vKYPn06Bw8eZNiwYSQnJwPwwAMPVLvO5ZdfTlFREfn5+Rw7dqzibOG3v/0t06ZNq3V/dSWhgQMHnvP8gw8+YNSoUYwdOxaAYcOGsXLlSkSEo0ePEh0dXedxABVnNwAhISGEh4eTl5dHVFRUrfH4ItiSxjLgXhF5E7gcOKmqWe5dVX8EMlT1yYBG2MKUlSvr9x0nJS2LlWnZZJ0sJCxEGN+vC3dP6se1Q7rRuV1E3RsyJghs2bKFCRMmsHr1ao4fP47H4+Hzzz9n/PjxNa7z5ZfOlfDa2jQaso3uscceq3i8YcMGRo0aBUDr1q0rKgTX9ziKioqIjGyYH3T+vuV2KTAJ6CIimcDDQBiAqr4ArMC53XYXzi23t7urfgP4DpAqIpvc1/5DVVf4LfgWpLSsnC92HyMlLYv3th7maH4R4aGtmDAghp9MHcSUwd3o0MbqPJkLV9cZQWNJTU1l5MiRgHPX0s0338zy5ctrTRq+cO7duXgvv/wyq1evBmDHjh289dZbfPbZZ4ATb1lZGYWFhfU6jtzcXGJiYupV/rw2/r57am4d8xU479YFVf2E6ts7TAMpKi3js125pKRlsSr9MCcKSmgdFsLVCTEkeeK4OqEr7SKC7cTUmPpJTU0lKSmp4vn111/PwoULz2kPuFCjR4/msssuA+COO+7gsssuq3eP8Llz57Js2TI8Hg9dunRh6dKldO7cuWL5qVOn8sknn9TrONasWcP06dMv+vjOsm+BFqywpIwPtx9hZVoW/8rIIa+olKiIUCYP7kqiJ46JA2NoHW51nkzzsWTJknOeT5gwgY0bN/q07qRJk5g0aVK18w4cOMBll13GCy+8UPHasWPH6t0jvF27dvzzn/+sMYZ7772XJ598sl7H8cYbb/D444/7dIy+sII+LUx+USnLNh/i7iXrGfmr91nw5/V8uOMIiZ5YXr1tDOsWTeGpm0aS6IltkgnDu/OTt/Xr1zN06FD69+/P/fffX3E54bXXXiMmJqbidshXXnml2u1+73vfo2vXrng85xUyqKCq3H///fTv359hw4axYcOGOtdPTk6me/fuFftfscK54pqamsptt912IW+BCYD169eTkZHBggULKhqkN23adE6P8AcffJCTJ09y55138u1vf5t9+/YBVPQI98XIkSO5+uqrz/v7rklxcTGzZ89m0KBBF3Rc1bEzjRbgZEEJH2QcJiUtm493HqG4tJwu7SKYM6o7SZ44Lu/bibCQ5vH7wbvzk7e77rqLl156iSuuuILp06ezcuXKitP7G2+8kWeeeabW7d52223ce++9FZ2nqpOSksLOnTvZuXMnX375JXfddVdFI2pt6//whz/kJz/5yTmvDR06lMzMTPbv32/9jZqA9evX89RTT1W0M8C5PcJvuOGG83qE33nnnUBlj3Bfy4h873vf8zmu8PDwWv9mL4QljWYqN7+IVelOovhs11FKy5W4DpHccnlPkjxxjO7VsVkWBPTu/HRWVlYWp06dYty4cQDMmzePf/zjH+dcE67LhAkT2Lt3b63LvPPOO8ybNw8R4YorruDEiRNkZWURFxfn0/pVXX/99bz55ps8+OCD9VrP+N/69evJysoiNDSUadOmccMNNzRKj/BgYEmjGTl8qtDtQ5HFV3uOUa7Qs1Mb7riyD4meWIbHN92CgMt3L+fpDU+TfTqb2LaxLBy1kBl9Z5yzTNXOT2cdPHiQ+Pj4iufx8fEcPHiw4vnf//53Pv74YwYOHMjvf/97evTowYU4ePDgOeue3U9cXFyt6z3zzDMsXryYMWPG8Lvf/Y6OHTsCMGbMGJ544glLGk3A2cuK3i60R3iws6TRxGUeL6jobLd+33EA+ndtxz1X9yfRE8uQuPZNvs7T8t3LSf4smcIy5x71rNNZJH+WDHBO4vDu/OStutshz74n119/PXPnziUiIoIXXniB7373uxW3PNZXbfupyV133cWiRYsQERYtWsSPf/xjXn31VQC6du3KoUOHLigWE3gX0iO8KbCk0QTtPpJPSlo2K9OyST14EoDBce350bUDSfLEMqDbxff6DCZPb3i6ImGcVVhWyNMbnj4naXh3fvIWHx9PZmZmxfPMzEwuueQSgHNuZ7zzzjv52c9+dsFxxsfHc+BAZek07/3UxPs69p133sl1111X8bywsLCiYqppmurbI7wpsKTRBKgqOw7nV/TK3padB8DwHtH8PCmBJE8svTq3DXCUjSf7dLZPr3t3fvLu/RoXF0dUVBRffPEFl19+OYsXL+a+++4DqGhzAFi2bFnFNWeAhIQEtm3b5nOcM2fO5JlnnuGmm27iyy+/pEOHDnVemvLe/9tvv33O3VU7duyo9W4tYwLBkkaQUlXSDp6qSBS7j55GBC7r1YmHrhtCoieWS6Jbxq/Q2LaxZJ3Oqvb1qs52fpoyZQojRoxg06ZNADz//PPcdtttnDlzhqSkpIpG8D/84Q8sW7aM0NBQOnXqVFEi4ujRo+dcbpo7dy4ffvghR48eJT4+nkceeYQ77rij4r78BQsWMH36dFasWEH//v1p06YNf/rTn+pc/8EHH2TTpk2ICL179+bFF1+sWGfNmjXMmHFuu40xgSYN1f09GI0ZM0bXrVsX6DB8Vl6ubDxwnJTUbFZuzSbz+BlCWglX9O1EoieOaZd2o2tUyysIWLVNAyAyJJLk8cnnNYZv3LiRJ598sqKh8UK9++677N69m/vvv/+itnOhioqKmDhxIp988gmhoc3jt11GRsY5Z3ImOFT3/yIi61V1THXLX9Bfo4i0BQpV1bceJqZGpWXlfLX3GCvTsnlvazaHTxURFiJc2b8L918zgGuHdKNj2/C6N9SMnU0Mdd09Bed2fqraV6M+vNsWAmH//v088cQTzSZhmObDp79IEWkF3ATcAlwGFAERInIEp8jgS6q6s9GibGZKysr57OtcVqZlsWrrYXJPFxMR2oqJA2NIGhrLNQnd6NDaCgJ6m9F3RrVJojr16fwUrAYMGFAxHoIxwcTXnzFrgA+AXwBpqloOICKdgKuBJ0TkbVX9c+OE2fQVlpTxyc6jpKRl8356NqcKS2kbHsLVCV1J8sQxaVAMba0goDEmyPn6LTVFVUuqvqiqx3AGRvq7O0iS8VJQXMqH24+QkpbN6ozDnC4uo31kKFOGdCPJE8dVA7oQGdb06jsZY1oun5JGdQnjQpZpCfIKS1i9LYeU1Gw+3JFDYUk5ndqGM3PEJSR64hjXtzPhoc2jzpMxpuWpM2mIyK+AEGATsMnaLs53/HQx72ccZmVaNp/sPEpxWTldoyL4f2N6kOiJZWzvToQ2k4KAxhjf1Xc8jaagzqShqg+JSDdgJPBNEemnqnc2fmjB7UheEe9tdXplf747l7JypXt0a+aN60XS0FhG9ujYZOs8GWPqp6CggAceeICoqCiWLFnCk08+SWJiYr3H02gKfL08dRhY6U4XTEReBa4DclT1vK6u7ljgT+MM+VoA3KaqG3xZ1x+yTp6pqPO0du8xVKFPl7bMn9CX6Z44PN2bfp0nY1qyxx9/nNzcXL7//e+TkJDg83rPPfcc3/rWt5g6dSr79u3j5ptvZvXq1eeMp7Fw4UJmz57NnXfeSXR0NPv27cPj8VSMp+FraXRfLVq0iF//+tcNuk3wcRAmEfmOiBwRkUwRmee+doWI/EZE1tdjf68BibXMTwIGuNN84Pl6rNso9ucW8OJHXzP72U8Z9/hqHvlnOicLSrj/mgGsfOAqVv94Ij9LTGBofAdLGMY0AS+++CKxsbEMHz6cfv36sXjxYgC+/PJLli5dSp8+feqVMADS0tIYP348Z86cqagX5j2exrRp084bT2Po0KFA5XgavvAeZKym4wDIzs6mtLSU4uJiJkyYQGlpab2Opza+3j31EM6v/73APSLyPpAALAUe8HVnqvqxiPSuZZFZwGJ3rPAvRCRaROJUNcuHdRvM0ZP57PnbL3njhIe3j8QCwtDuHfjptEEkeWLpG9POH2EYYxrBli1bSE5OZsGCBXz11VdMnz6defPmMXDgQCZNmsQ999xT723OmTOHu+++m7Zt2/LLX/4SoFHG0/AeZKym4wCnMsKIESMIDw9n8uTJ/OUvf+GWW26p93FVS1XrnICNXo8FyAGifVm3mm31xunrUd28d4ErvZ7/Cxjjy7rVTaNHj9YLkZXxuRY91FH14faa99gAPfXWD1X3fKJaVnpB2zPGqKanpwc6BFVVveqqq3T16tWqqpqTk6NxcXGqqrp69Wp95ZVXGmw/5eXl+oMf/KDWZfLy8s5bZtOmTXrVVVfp4MGDVUQU0IceekhVVceNG6d79uyp9ThUVR977DHdtm1bxfaSkpJqjKG6/xdgndbwverrmUasiMwHtrtTpqqeaICcVVV113fqVRzLjXM+cMGjYcUmXMHRe7fR5dBq2qUvg7Q/w+Y/QtuukDADhsyE3ldBiHVNMaapSU1NZdCgQagqzzzzDI8++igAmzdvrrOUeX1cyHgahYWF3HjjjSxevJixY8eyaNEiCgsLSU5OPm+QsZqOA2DXrl0VFQU8Hg9r165tsOPyNWk8DAzDKSMyFIgSkQ+AjThnIW/UtnI9ZALew6bFA/UahUZVXwJeAqdg4YUG0iWmK8TcBMNvgqJ82LkKMpbBlr/C+j9B644waDoMngn9robQpjPyljEBl/JzyE5t2G3GDoWkJ2pd5MCBA+Tl5TF9+nQOHjzIsGHDSE5OBuCBBx6odp0pU6aQnX1+ef5HH32UWbNm1bq/+o6n8cEHHzBq1CjGjh0LwLBhw1i5ciUics4gY7UdB1AxWiBASEgI4eHh5OXlERV18WPt+Hr31Evez0UkHieJDMVpvG6opLEMuFdE3gQuB06q6vk1sf0toh145jhTyRn4ejWkL4OMd2HTEohoDwOnOQmk/xQIr/5XhTEmsLZs2cKECRNYvXo1x48fx+Px8PnnnzN+/Pga1/nggw/q3G5D3gTz2GOPVTzesGEDo0aNAs4dZKy+x1FUVHTOGDMXw9eCheJe5wJAVTNxzgpW1LRMDdtZCkwCuohIJs4ZTJi7zRfc7U0HduHccnt7beuq6h/xt7DWziWqhBlQWgx7PoL0d2Dbckj9PwhrAwOudRLIwGkQ0bxG0TOmQdRxRtBYUlNTGTlyJODctXTzzTezfPnyWpOGL+r46vPZyy+/XDHc8I4dO3jrrbf47LPPgHMHGavPceTm5hITE0NYWMNcTve1m/IaEblPRM5pJBCRcBG5RkT+F/huXRtR1bmqGqeqYaoar6p/VNUX3ISB2wZzj6r2U9WhqrqutnXrc6CNIjTcSRCznoGf7IR578DwubD/C/j7HfBf/eCNG2HjEig4FuhojWnxvL9swRkjfsWKFbWs4bvRo0ezYMECFixYUNGGsHDhQgoKCmpcZ/369ecMvDV37lzy8/PxeDzMnz+fpUuXnjMk8dlBxupzHGvWrGH69OkXe3iVamoh956ASOBu4FOcNoZ0YA+wD3gZGOHLdvw9XejdUxetrFR172eqKT9X/d0Q1Yfbqz7SSXXxbNW1r6rm5QQmLmMCKFjunmoM+/fvP+8uqNzcXF24cKFmZWXphAkT9Le//a3OmzdPX3jhBf3mN7+pqampqqp6yy23+LyfDRs26K233lqv2G644YaKO6mq01h3T/VT1eeA59xqtl2AM9o4d1A1fa1CoNc4Z5r2GBza4LaBLIN3H4DlP4Ke4527sAZfD+0vCXTExpiLsH79ejIyMliwYAGxsbEkJyezadOmBu8RXt9BxoqLi5k9ezaDBg1qiMMEfL976nVglPv4u6r6ytkZItJGVWs+/2rpRKD7aGeakgyHtzrJI/0dSHnQmeLHuglkJnTsFeiIjTH1tH79ep566qlzLhl59wi/4YYbzusRfuedTgm/sz3CfS0jUp9BxsLDwys6/DUUX5OG960BdwOveD3/NzC6wSJqzkQg1uNMV/8HHNkBGe84ZyGrfulMcSPcBDILuvQPdMTGGB+sX7+erKwsQkNDmTZtGjfccEOj9AgPBr4mDe9bA6reW2Y1vy9UzECI+SlM+Ckc2+OegSyDf/3KmboOcS5fDZnlPLbaVsYEpeoaoYcOHcpzzz1X0WdixIgRjBgxAoDXX38dgPz8fNq3b09ERNPp51WfHuG3AZs5P2k0zL1mLV2nPvCNhc50MtPpA5KxDD76L/jot9CpX+UlrEtGWgIxJshdSI/wpsDXpJEMjMHpNxEvIluBbe7UpXFCa8E6xMMVC5wp7zBscxPIp3+AT34PHXpWnoHEXwat7GTPmGBU3x7hTUFD9Aj/uBHiMmdFdYPL7nCmgmOwfYVzCWvty/DFsxAVBwnXOWchPcdDiK+/A4wxpv4u6BtGq+kRbvygTScYeaszFZ6EHauchvSNf3aSSJvObkHFWdB7gtP50BhjGpD9LG2qIjvAsG87U/Fp2PWBcxtv2luwYbEzv6Kg4jUQ1jB1Z4wxLZsljeYgvK1zdjFkFpQUwu41ziWs7cth81IIb+eUOxkyC/pf6xRgNMaYC2BJo7kJi4RBSc5UWgx7P4aMfzp3Y219G0IjnUq8g2fCoETnjMQYY3xkSaM5Cw13EkT/KTDjSdj3mXMXVsY/nTuyWoVB30nOGUjCDKfNxBhjamFJo6VoFQJ9rnKmxN/CwXVOG0jGMlh2L/xzIfS+0rkLK+F6564tY4ypwpJGS9SqFfQY60xTfwNZmyoLKi7/MSz/CfQcV1lQsUN8oCM2xgQJSxotnYjTw/ySkTD5IcjJqCxnsvLnztR9tNMGMmQmdOob6IiNMQFkXYlNJRHoNgQm/Rzu/gzuXQ+THwYthw8ehj+MhOevdEqbHNke6GiNCRoPPfRQs9pPbfyaNETkVRHJEZG0GuaLiPxBRHaJyBYRGeU1L1FEtrvzfu6/qFuwLv3hqh/B/A9h4RaY+qgz/vmaR+HZsfDMWFj9G8jaAg003KUxje3MmTNMnDiRsrKyei334osvEhsby/Dhw+nXrx+LFy8GICcnh+LiYsAZv2LChAmUlpbWuu0XX3yRuLi4iiKGI0aMIDU1tcZ9eO/H1300Fn+fabwGJNYyPwkY4E7zgecBRCQEeNadPwSYKyJDGjVSc66OvWD8vXDHKvhRBkz/H2jXFf79O3jxKucsZNUiyFxnCcQ0iOW7lzP1b1MZ9r/DmPq3qSzfvbxBtvvqq68yZ86cOgcxqrrcli1bSE5OZvPmzSxdupQf/ehHAKxdu5bRo53RIcLDw5k8eTJ/+ctfat32li1b+M1vfsOmTZsqpqFDh9a4D+/9+LqPxuLXpKGqHwO1DZY9C1jsjjj4BRAtInHAWGCXqu5W1WLgTXdZEwjtL4Gxd8Jt7zpjo1//tNPW8cVz8Mpk+L0HUn7u3OJbXvuvOWOqs3z3cpI/SybrdBaKknU6i+TPkhskcSxZsoRZs5yvj82bNzNhwgSGDBlCq1atEBEefvjh85YDZ3zxsyPg9enTh/Bwp0zP2rVrGTNmTMVys2fPZsmSJbXGkJqaWlEmverr1e2j6n582UdjCbaG8O7AAa/nme5r1b1+uR/jMjVp2wVG3+ZMZ47D9pVOQ/q6V+HL56FtVxh8ndOQ3vsqK6hofPL0hqcpLCs857XCskKe3vA0M/rOuODtFhcXs3v3bnr37k1hYSE33ngjixcvZuzYsSxatIjCwkKSk5PPWe6ss1/oqsozzzzDo48+CsCePXvo06dPxXIej4e1a9fWGsfWrVu5/fbbaeVWqL777ruZP39+jfuouh9f9tFYgu0TXN0gEVrL6+dvQGQ+zqWtJjUaVrPQuiOMmOtMRXmwc5VzF9bmN50k0rqj04lw8CzoOxFCm87AM8a/sk9n1+t1Xx09epTo6GgAPvjgA0aNGsXYsWMBGDZsGCtXrkREzlkO4MCBA+Tl5TF9+nQOHjzIsGHDSE5O5tlnn6V//3NH2AwJCSE8PJy8vDyioqLOi+HAgQN07dqVLVu2nPd6dfsAzttPXftoTMGWNDKBHl7P44FDQHgNr5/HLeP+EsCYMWPs4nqgRESB55vOVFwAX//LSSDpy5yqvBHtYWCicxtv/ykQ1jrQEZsgEts2lqzTWdW+fjFat25NYaFzBpOWlsbQoUMr5m3YsIFRo0adtxw4bRATJkxg9erVHD9+HI/Hw+eff84999xT7X6KioqIjKy+SOiWLVtISEio9vXq9jF+/Phq91PbPhpTsN1yuwyY595FdQVwUlWzgLXAABHpIyLhwE3usqYpCG/jdBL85svw011w8/85yWLX+/CXW+G/+sJf50Hq35wzFNPiLRy1kMiQc78QI0MiWThq4UVtt2PHjpSVlVFYWEjnzp0rfu3v2LGDt956i5tuuum85cC5NDVy5MiKeTfffDPLl1ffvpKbm0tMTAxhYWEATJ48mYMHD1bMT01NrTZpXMw+/Mnft9wuBT4HBolIpojcISILRGSBu8gKYDewC3gZuBtAVUuBe4H3gAzgr6q61Z+xmwYSGgEDp8KsZ51G9O/8A4bfBPs+h7/fAf/VD5bOhU1LnTYS0yLN6DuD5PHJxLWNQxDi2saRPD75otozzpo6dSqffPIJc+fOJT8/H4/Hw/z581m6dCmdO3c+bzk49wsd4Prrr692XHCANWvWMH36dADKy8vZtWsXnTpV1nVLTU3l9ddfr7jVduTIkeTn51/wPvxOVZvtNHr0aDVNRFmp6t5PVVf8TPV3g1Ufbq/6SCfVxTeorvuTav6RQEdoLlJ6enqgQ1BV1Q0bNuitt97aYMtVdcMNN+i2bdtUVTU1NVV/+MMf1nsb9dnHxaru/wVYpzV8rwZbm4ZpqVqFQK/xzjTtMTi0obKg4j8Xwrs/hF7fcO7CGnw9tI8LdMSmiRo5ciRXX301ZWVltfbV8HU5b8XFxcyePbvitlmPx8OTTz7ZIHHXtA9/E23GHbHGjBmj69atC3QY5mKoQnZqZT2so275kh6XV9bDira75JqCjIwMBg8eHOgwTBXV/b+IyHpVHVPd8namYYKbCMQNc6ZrfunUvEpf5pyFrPpPZ4obUTlyYed+gY7YmGbNkoZpWmIGwcSfOtOx3ZUl3f/1iDN1vdS5fDVkFnQd7CQdY0yDsaRhmq5OfeHKB5zpZKYzImH6Mvjot/DRE9C5f+UlrLgRlkCCgKoi9v8QNC6kecLaNEzzk3fYGc42/R3Y+wlomdPuMXimcwbSfYwzEJXxqz179hAVFUXnzp0tcQQBVSU3N5e8vLxzyqBA7W0aljRM83Y6F7avcC5hfb0Gyksg6pLKeli9xjt3bplGV1JSQmZm5jk9rU1gRUZGEh8ff14nQUsaxgCcOQE73nMSyK4PoLQQ2nRx6mENmQl9JkKI/3vYGhNsLGkYU1VRvlPGJH2ZU1ixOB8io2HQdCeB9L0awvxf18eYYGC33BpTVUQ7uPQGZyophK9XO2cg25fD5jcgPMopdzJ4Jgy4FsLbBjpiY4KCJQ1jwiIhYbozlRbDno8h4x3YthzS/g6hraH/ZKcRfeA0iOwQ6IiNCRi7PGVMTcpKYf9nbl+Qf0J+NoSEQ99JTgIZNB3adKpzM8Y0NdamYczFKi+HzK8qOxOePAASAn2uqqyH1a5roKM0pkFY0jCmIanCoY2V9bCOfQ2Ic/vu2QTSoXugozTmglnSMKaxqEJOeuUZSE6683r3Mc5dWINnQqc+tW/DmCBjScMYfzm6y2lET38HsjY7r8UOcxPILIgZGNj4jPGBJQ1jAuH43sp6WJlfOa/FJFSWM+l2qdXDMkEpqJKGiCQCTwMhwCuq+kSV+R2BV4F+QCHwPVVNc+ctBO4EBHhZVZ+qbV+WNEzQOHUIMt51LmHt+xS03Cm4eLag4iWjLIGYoBE0SUNEQoAdwLVAJrAWmKuq6V7L/DeQr6qPiEgC8KyqThYRD/AmMBYoBlYCd6nqzpr2Z0nDBKX8I05BxYxlTp+Q8lJoH19Z0r3H5VZQ0QRUMPUIHwvsUtXdACLyJjALSPdaZgjwOICqbhOR3iLSDRgMfKGqBe66HwE3AP/lx/iNuXjtYmDM7c5UcAy2pzgJZN0f4cvnoV03SLjOOQPpdSWEWB9cEzz8/dfYHTjg9TwTuLzKMpuBOcAnIjIW6AXEA2nAoyLSGTgDTAfsNMI0bW06wchbnKnwlFMHK2MZbF7qJJHWnZye6kNmOwUVQ8MDHbFp4fydNKq7aFv1+tgTwNMisglIBTYCpaqaISK/Bd4H8nGSS+l5OxCZD8wH6NnTxo42TUhkexj6LWcqLnAq8WYsg63vwMY/Q0QHGJTotIP0nwxhrQMdsWmB/N2mMQ5IVtVp7vNfAKjq4zUsL8AeYJiqnqoy7zEgU1Wfq2l/1qZhmoXSItj9oXMX1rZ3ofAEhLX1Kqg41SnAaEwDCaY2jbXAABHpAxwEbgJu9l5ARKKBAlUtBr4PfHw2YYhIV1XNEZGeOJewxvkzeGMCIjTCKZQ4cBqUPQV7/12ZQLa+DaGR0G+y0wYyMBFaRwc6YtOM+TVpqGqpiNwLvIdzy+2rqrpVRBa481/AafBeLCJlOA3kd3ht4u9um0YJcI+qHvdn/MYEXEgY9LvGmWb8DvZ/UVnOZPtyaBXmFlScCYNmQNvOgY7YNDPWuc+Y5qC8HA6ud3ujL4MT+5yCir2/UVkPKyo20FGaJiJo+mn4myUN0yKpQvaWynpYR3cA4vT/GOImkGi7ScTUzJKGMS1ZzrbKS1iHU53XLhlZWc6kc7/AxmeCjiUNY4wj92u3HtY7cGiD81o3T2U5k5gEK2diLGkYY6px4kBlAjnwJaDQeUBlSfe44ZZAWihLGsaY2uVlOwkkYxns/RS0DKJ7ufWwZkP30VYPqwWxpGGM8d3pXOf23fRlTqfC8hKIusRNIDOh5zhoFRLoKE0jsqRhjLkwZ07AjvecM5BdH0BpIbSNgYQZziWsPhOcviOmWbGkYYy5eEX5lQUVd6yCktMQGV2ZQPpd7fReN01eMJURMcY0VRHtwDPHmUrOwNer3b4g78KmJRAe5ZQ6GTIL+k+B8DaBjtg0Aksaxpj6C2vtnGEkzIDSYmcwqfR/wLblkPY3CG0NA6Y4jegDpjoVfE2zYJenjDENp6zUGc42Y5lzN1b+YQgJd2plDZ4Jg5KcMURMULM2DWOM/5WXwYGvKm/lPXkAWoVC76ucu7ASroN2XQMdpamGJQ1jTGCpOj3Qz9bDOrYbpJVz++7Zgoodugc6SuOypGGMCR6qcHirWw/rHTiyzXk9/rLKciYdewc0xJbOkoYxJngd2VFZ0j17i/Na3PDKgopdBgQ2vhbIkoYxpmk4tqeyHtZB97MbM7iyHla3S60elh9Y0jDGND0nM50+IBnLYN9ngEKnvs7Zx+CZTnl3SyCNIqiShogkAk/jDPf6iqo+UWV+R+BVoB9QCHxPVdPceT/EGTdcgVTgdlUtrGlfljSMaSbyc5wx0dOXOX1CtAw69HTrYc1y2kOsoGKDCZqkISIhwA7gWiATWAvMVdV0r2X+G8hX1UdEJAF4VlUni0h34BNgiKqeEZG/AitU9bWa9mdJw5hmqOAYbE9xLmHtXgNlxdAuFgZf5ySQnuMhxPotX4xgKiMyFtilqrsBRORNYBaQ7rXMEOBxAFXdJiK9RaSbOy8UaC0iJUAb4JDfIjfGBIc2nWDkLc5UeMotqPgObFwCa1+BNp3deliznIKKoeGBjrhZ8XfS6A4c8HqeCVxeZZnNwBzgExEZC/QC4lV1vYj8D7AfOAOsUtVVfojZGBOsItvDsG87U/FppxJv+jJIews2LIbIDjAwyTkD6XcNhEUGOuImz99Jo7pWq6rXx54AnhaRTTjtFhuBUretYxbQBzgB/J+I3Kqqfz5nByLzgfkAPXv2bNDgjTFBLLytkxyGzIKSQufSVfoy2L4CtrwJ4e1gwLVuQcVrnQKMpt78nTQygR5ez+OpcolJVU8BtwOIiAB73GkasEdVj7jz3gLGA3+usv5LwEvgtGk0ylEYY4JbWKRT52pQEpSVOI3nGcucgopb34bQSKcS7+CZMCjROSMxPvF30lgLDBCRPsBB4CbgZu8FRCQaKFDVYpw7pT5W1VMish+4QkTa4FyemgxYK7cxpnYhYdB/sjPNeBL2f15ZzmTbu9AqDPpOcs5AEmZYQcU6BOKW2+nAUzi33L6qqo+KyAIAVX1BRMYBi4EynAbyO1T1uLvuI8CNQCnOZavvq2pRTfuyu6eMMTUqL3c6EKa/4ySQE/tBQqD3lW5Bxeshqlvd22mGguaWW3+zpGGM8YkqZG1262Etg9ydgEDPKyoLKkb3qHMzzYUlDWOM8ZWqU0Tx7CWsw2nO65eMqixn0rlfYGNsZJY0jDHmQuV+XXkJ69BG57VuQysTSNeEwMbXCCxpGGNMQzixv7Kg4oEvnde6DKws6R47rFnUw7KkYYwxDe1UllsP6x1niFstd8YBOVvSvfvoJptALGkYY0xjOn3U6QOS/g7s+QjKS6F9d6cBffBMp0G9VUigo/SZJQ1jjPGXM8edeljpy5yyJmVF0LarU1Bx8Eznlt6QsEBHWStLGsYYEwhFebBzlZNAdq6CkgJo3REGzXDaQPpOgtCIQEd5nmCqcmuMMS1HRBR4vulMJWdg178q78Ta9GeIaA8DpzlnIP2nQHibQEdcJ0saxhjjD2Gt3UtU10FpEez+yCnpvm05pP4fhLVxCioOnukkkoioQEdcLbs8ZYwxgVRWCvs+cTsT/hNO50BIhFPKfchMp+hi645+DcnaNIwxpikoL3P6f5ztjX7qILQKdQaTGjILEq6Dtl0aPQxLGsYY09SowsENziWs9Hfg+F6QVtDrG5X1sNrHNcquLWkYY0xTpurUwEpf5iSQo9ud1+PHOmcgg6+Hjr0abHeWNIwxpjk5st29hPUOZKc6r8WNcOthzYIu/S9q85Y0jDGmuTq2p7Kk+0H3+67rEBh5K4y754I2af00jDGmuerUB76x0JlOZroFFZdBTkaj7M6ShjHGNBcd4uGKu5ypvLxRdtGqUbZqjDEmsFo1zte735OGiCSKyHYR2SUiP69mfkcReVtEtojIVyLicV8fJCKbvKZTIvKAv+M3xpiWzK+Xp0QkBHgWuBbIBNaKyDJVTfda7D+ATap6g4gkuMtPVtXtwAiv7RwE3vZn/MYY09L5+0xjLLBLVXerajHwJjCryjJDgH8BqOo2oLeIdKuyzGTga1Xd19gBG2OMqeTvpNEdOOD1PNN9zdtmYA6AiIwFegHxVZa5CVha3Q5EZL6IrBORdUeOHGmQoI0xxjj8nTSqG/uwakeRJ4COIrIJuA/YCJRWbEAkHJgJ/F91O1DVl1R1jKqOiYmJaZCgjTHGOPx9y20m0MPreTxwyHsBVT0F3A4gIgLscaezkoANqnq4cUM1xhhTlb/PNNYCA0Skj3vGcBOwzHsBEYl25wF8H/jYTSRnzaWGS1PGGGMal9/LiIjIdOApIAR4VVUfFZEFAKr6goiMAxYDZUA6cIeqHnfXbYPTJtJXVU/6sK8jwMU0lncBjl7E+o0t2OOD4I8x2OMDi7EhBHt8EFwx9lLVaq/vN+vaUxdLRNbVVH8lGAR7fBD8MQZ7fGAxNoRgjw+aRoxgPcKNMcbUgyUNY4wxPrOkUbuXAh1AHYI9Pgj+GIM9PrAYG0KwxwdNI0Zr0zDGGOM7O9MwxhjjM0saxhhjfNYik4YP5dlFRP7gzt8iIqN8XTfQMYpIDxFZIyIZIrJVRBYGU3xe80NEZKOIvNsY8V1sjG4n07+JyDb3vRwXZPH90P3/TRORpSIS2dDx+Rhjgoh8LiJFIvKT+qwb6BiD6LNS43vozm/0z0q9qGqLmnA6FX4N9AXCcQokDqmyzHQgBadW1hXAl76uGwQxxgGj3MdRwI6GjvFi4vOa/yPgDeDdYPt/duf9L/B993E4EB0s8eEU+dwDtHaf/xW4LUDvYVfgMuBR4Cf1WTcIYgyWz0q18fnrs1LfqSWeafhSnn0WsFgdXwDRIhLn47oBjVFVs1R1A4Cq5gEZnF9JOGDxAYhIPDADeKWB42qQGEWkPTAB+COAqhar6olgic+dFwq0FpFQoA1Varj5K0ZVzVHVtUBJfdcNdIzB8lmp5T3012elXlpi0vClPHtNy/iybqBjrCAivYGRwJdBFt9TwINA4wxiXPf+61qmL3AE+JN7WeAVEWkbLPGp6kHgf4D9QBZwUlVXNXB8vsbYGOvWR4PsJ8Cfldo8ReN/VuqlJSYNX8qz17SML+s2hIuJ0Zkp0g74O/CAnlvwsSFccHwich2Qo6rrGzimqi7mPQwFRgHPq+pI4DTQ0NfkL+Y97Ijza7UPcAnQVkRubeD4aty/H9atj4veTxB8Vqpf0X+flXppiUmjzvLstSzjy7qBjhERCcP5ECxR1beCLL5vADNFZC/Oqfo1IvLnIIsxE8hU1bO/Ov+Gk0SCJb4pwB5VPaKqJcBbwPgGjs/XGBtj3fq4qP0EyWelJv76rNRPoBtV/D3h/IrcjfMr7WzD1KVVlpnBuQ2QX/m6bhDEKDhVgp8KxvewyjKTaLyG8IuKEfg3MMh9nAz8d7DEB1wObMVpyxCcRvv7AvEeei2bzLmNzEHzWaklxqD4rNQUX5V5jfZZqfcxBTqAgBy0c1fKDpy7Gv7TfW0BsMDrj+lZd34qMKa2dYMpRuBKnNPfLcAmd5oeLPFV2UajfhAu8v95BLDOfR//AXQMsvgeAbYBacDrQESA3sNYnF/Tp4AT7uP2QfZZqTbGIPqs1Pge+uuzUp/JyogYY4zxWUts0zDGGHOBLGkYY4zxmSUNY4wxPrOkYYwxxmeWNIwxxvjMkoYxxhifWdIwJsiIyK8DHYMxNbGkYYwfiEhrEflIRELc5z8QkWwR2SwiX4vIPPf1WJxexIhIuIh87FayNSYoWNIwxj++B7ylqmXu82FAsqoOB+YCT7qvj8TpmYw6pbT/Bdzo31CNqZklDWMakIgMd88O0kWkXERURB4BbgHe8Vp0KLDdfbwHKHYfj8BNGq5/uOsaExTstNeYBuIOufoXYJ6qfuW2TUQCjwE/UNW9XosPBbaLiAD3Av/pvt4f2Om1XBrOqG7GBAU70zCm4UwBNqjqV+7zLUAnoDNOITrAGZsaZ3jRFUAOTuG81wBU9Q5VrRhwx72cVSwiUX6I35g6WdIwpuF4cKrRnjUK2ACcwTnjOGsY8LGqjgAGAgnAuFq2GwEUNmikxlwgSxrGNJxcnISAiAwE5gBvqupxIMS9fAXOpamNAO68N3DGzjiPiHQGzg62ZEzAWdIwpuEsBdqJSBrwEjBXVXPdeatwLkOBV9Jw/RNnzIXqXI1zGcuYoGDjaRjjByIyEviRqn6nnuu9BfxCVbfXubAxfmBnGsb4gapuBNac7dznCxEJB/5hCcMEEzvTMMYY4zM70zDGGOMzSxrGGGN8ZknDGGOMzyxpGGOM8ZklDWOMMT6zpGGMMcZnljSMMcb4zJKGMcYYn/3/O+WH6zpR9FoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "filenames": {
       "image/png": "/home/runner/work/lecture-python-advanced.myst/lecture-python-advanced.myst/_build/jupyter_execute/asset_pricing_lph_1_0.png"
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "\n",
    "# Define the function to plot\n",
    "def y(x, alpha, beta):\n",
    "    return alpha + beta*x\n",
    "def z(x, alpha, beta):\n",
    "    return alpha - beta*x\n",
    "\n",
    "sigmam = .25\n",
    "Em = .99\n",
    "\n",
    "# Set the values of alpha and beta\n",
    "alpha = 1/Em\n",
    "beta = sigmam/Em\n",
    "\n",
    "# Create a range of values for x\n",
    "x = np.linspace(0, .15, 100)\n",
    "\n",
    "# Calculate the values of y and z\n",
    "y_values = y(x, alpha, beta)\n",
    "z_values = z(x, alpha, beta)\n",
    "\n",
    "# Create a figure and axes object\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "# Plot y\n",
    "ax.plot(x, y_values, label=r'$R^f + \\frac{\\sigma(m)}{E(m)} \\sigma(R^i)$')\n",
    "ax.plot(x, z_values, label=r'$R^f - \\frac{\\sigma(m)}{E(m)} \\sigma(R^i)$')\n",
    "\n",
    "plt.title('mean standard deviation frontier')\n",
    "plt.xlabel(r\"$\\sigma(R^i)$\")\n",
    "plt.ylabel(r\"$E (R^i) $\")\n",
    "plt.text(.053, 1.015, \"(.05,1.015)\")  \n",
    "ax.plot(.05, 1.015, 'o', label=\"$(\\sigma(R^j), E R^j)$\")\n",
    "# Add a legend and show the plot\n",
    "ax.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "713fe265",
   "metadata": {},
   "source": [
    "The figure shows two straight lines, the blue upper one being the locus of $( \\sigma(R^i), E(R^i)$ pairs that are on \n",
    "the **mean-variance frontier** or **mean-standard-deviation frontier**.  \n",
    "\n",
    "The green dot refers to a return  $R^j$ that is **not** on the frontier and that has moments\n",
    "$(\\sigma(R^j), E R^j) =  (.05, 1.015)$.  \n",
    "\n",
    "It is described by the statistical model\n",
    "\n",
    "$$ \n",
    " R^j = R^i +  \\epsilon^j\n",
    "$$\n",
    "\n",
    "where $R^i$ is a return that is on the frontier and  $\\epsilon^j$ is a random variable that has mean zero and that is orthogonal to $R^i$.\n",
    "\n",
    "Then $ E R^j = E R^i$ and, as a consequence of $R^j$ not being on the frontier, \n",
    "\n",
    "$$\n",
    "\\sigma^2(R^j) = \\sigma^2(R^i) + \\sigma^2(\\epsilon^j)\n",
    "$$\n",
    "\n",
    "The length of a horizontal line from the point $\\sigma(R^j), E (R^j) = .05, 1.015$ to\n",
    "the frontier   equals\n",
    "\n",
    "$$\n",
    "\\sqrt{ \\sigma^2(R^i) + \\sigma^2( \\epsilon^j)} - \\sigma(R^i)\n",
    "$$\n",
    "\n",
    "This is a measure of the part of the risk in $R^j$ that is not priced because it is  uncorrelated with the stochastic discount factor and so can be diversified away (i.e., averaged out to zero by holding a diversified portfolio).\n",
    "\n",
    "\n",
    "## Sharpe Ratios and the Price of Risk\n",
    "\n",
    "An asset's **Sharpe ratio** is defined as\n",
    "\n",
    "$$\n",
    " \\frac{E(R^i) - R^f}{\\sigma(R^i)} \n",
    "$$\n",
    "\n",
    "The above figure reminds us that all assets $R^i$ whose returns are on the mean-standard deviation frontier\n",
    "satisfy\n",
    "\n",
    "$$\n",
    "\\frac{E(R^i) - R^f}{\\sigma(R^i)}  = \\frac{\\sigma(m)}{E m} \n",
    "$$\n",
    "\n",
    "The ratio $\\frac{\\sigma(m)}{E m} $ is often called the **market price of risk**.\n",
    "\n",
    "Evidently it equals the maximum Sharpe ratio for any asset or portfolio of assets.\n",
    "\n",
    "\n",
    "## Mathematical Structure of Frontier\n",
    "\n",
    "The mathematical  structure of the mean-variance frontier described by inequality {eq}`eq:ERM6` implies \n",
    "that\n",
    "\n",
    "\n",
    "- all returns on the frontier are perfectly correlated.\n",
    "\n",
    "  Thus,\n",
    "   \n",
    "   * Let $R^m, R^{mv}$ be two returns on the frontier. \n",
    "   \n",
    "   * Then for some scalar $a$, a return $R^{m v}$ on the mean-variance frontier satisfies the affine equation\n",
    "       $R^{m v}=R^{f}+a\\left(R^{m}-R^{f}\\right)$ .  This is an **exact** equation with no **residual**.\n",
    " \n",
    " \n",
    "- each return $R^{mv}$ that is on the mean-variance frontier is perfectly (negatively) correlated with $m$ \n",
    "  \n",
    "   *  $\\left(\\rho_{m, R^{mv}}=-1\\right) \\Rightarrow \\begin{cases} m=a+b R^{m v} \\\\ R^{m v}=e+d  m  \\end{cases}$ for some scalars $a, b, e, d$, \n",
    "   \n",
    "   Therefore, **any return on the mean-variance frontier is a legitimate stochastic discount factor**\n",
    "\n",
    "\n",
    "- for any mean-variance-efficient return $R^{m v}$ that is on the frontier but that is  **not** $R^{f}$, there exists  a **single-beta representation** for any return $R^i$ that takes the form:\n",
    "\n",
    "$$ \n",
    "E R^{i}=R^{f}+\\beta_{i, R^{m v}}\\left[E\\left(R^{m v}\\right)-R^{f}\\right] \n",
    "$$ (eq:EMR7) \n",
    "\n",
    "- the regression coefficient $\\beta_{i, R^{m v}}$ is often called asset $i$'s **beta**\n",
    "   \n",
    "- The special case of a single-beta representation {eq}`eq:EMR7` with $ R^{i}=R^{m v}$   is \n",
    "  \n",
    "  $E R^{m v}=R^{f}+1 \\cdot\\left[E\\left(R^{m v}\\right)-R^{f}\\right] $"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6847c015",
   "metadata": {},
   "source": [
    "## Multi-factor Models\n",
    "\n",
    "The single-beta representation  {eq}`eq:EMR7` is a special case of the multi-factor model \n",
    "\n",
    "\n",
    "$$\n",
    "E R^{i}   =\\gamma+\\beta_{i, a} \\lambda_{a}+\\beta_{i, b} \\lambda_{b}+\\cdots\n",
    "$$\n",
    "\n",
    "\n",
    "where $\\lambda_j$ is the price of being exposed to risk factor $f_t^j$  and $\\beta_{i,j}$ is asset $i$'s exposure to that\n",
    "risk factor.  \n",
    "\n",
    "To uncover the $\\beta_{i,j}$'s, one  takes data on time series of the risk factors $f_t^j$ that are being priced\n",
    "and specifies the following least squares regression\n",
    "\n",
    "\n",
    "$$\n",
    "R_{t}^{i}=a_{i}+\\beta_{i, a} f_{t}^{a}+\\beta_{i, b} f_{t}^{b}+\\ldots+\\epsilon_{t}^{i}, \\quad t=1,2, \\ldots, T\\\\\n",
    "\\epsilon_{t}^{i} \\perp f_{t}^{j}, i=1,2, \\ldots, I; j = a, b, \\ldots \n",
    "$$ (eq:timeseriesrep)\n",
    "\n",
    "Special cases are:\n",
    "\n",
    "   * a popular **single-factor** model specifies the single factor  $f_t$ to be the return on the market portfolio \n",
    "   \n",
    "   * another popular **single-factor** model called the **consumption-based model** specifies the factor to be  $ m_{t+1} = \\beta \\frac{u^{\\prime}\\left(c_{t+1}\\right)}{u^{\\prime}\\left(c_{t}\\right)}$, where $c_t$ is a representative consumer's time $t$ consumption.\n",
    "   \n",
    "\n",
    "As a reminder, model objects are interpreted as follows:   \n",
    " \n",
    "   * $\\beta_{i,a}$ is the  exposure of return $R^i$ to risk factor $f_a$ \n",
    "   \n",
    "   * $\\lambda_{a}$ is the  price of exposure to risk factor $f_a$ \n",
    "   \n",
    "## Empirical Implementations\n",
    "\n",
    "We briefly describe empirical implementations of multi-factor generalizations of the single-factor model described above.  \n",
    "\n",
    "Two representations of a multi-factor model play importnt roles in empirical applications.\n",
    "\n",
    "One is the time series regression {eq}`eq:timeseriesrep`\n",
    "\n",
    "The other representation entails  a **cross-section regression**  of **average returns** $E R^i$ for  assets\n",
    "$i =1, 2, \\ldots, I$ on **prices of risk** $\\lambda_j$ for $j =a, b, c, \\ldots$ \n",
    "\n",
    "Here is the cross-section regression specification for a multi-factor model:\n",
    "\n",
    "\n",
    "$$\n",
    "E R^{i}   =\\gamma+\\beta_{i, a} \\lambda_{a}+\\beta_{i, b} \\lambda_{b}+\\cdots\n",
    " $$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f12486b",
   "metadata": {},
   "source": [
    "**Testing strategies:**\n",
    "\n",
    "Time-series and cross-section regressions play roles in both  **estimating** and **testing** beta representation\n",
    "models.\n",
    "\n",
    "The basic idea is to implement the following two steps.\n",
    "\n",
    "**Step 1:**\n",
    "\n",
    "- Estimate $a_{i}, \\beta_{i, a}, \\beta_{i, b}, \\cdots$ by running a **time series regression:** $R_{t}^{i}$ on a constant and $f_{t}^{a}, f_{t}^{b}, \\ldots$\n",
    "\n",
    "\n",
    "**Step 2:**\n",
    "\n",
    "- take the $\\beta_{i, j}$'s estimated in step one as regressors together with data on average returns\n",
    "$E R^i$ over some period and then  estimate the  **cross-section regression**\n",
    "\n",
    "\n",
    "$$\n",
    "\\underbrace{E\\left(R^{i}\\right)}_{\\text{average return over time series}}=\\gamma+\\underbrace{\\beta_{i, a}}_{\\text{regressor}\\quad} \\underbrace{\\lambda_{a}}_{\\text{regression}\\text{coefficient}}+\\underbrace{\\beta_{i, b}}_{\\text{regressor}\\quad} \\underbrace{\\lambda_{b}}_{\\text{regression}\\text{coefficient}}+\\cdots+\\underbrace{\\alpha_{i}}_{\\text{pricing errors}}, i=1, \\ldots, I; \\quad \\underbrace{\\alpha_i \\perp \\beta_{i,j},j = a, b, \\ldots}_{\\text{least squares orthogonality condition}}\n",
    "$$\n",
    "\n",
    "- Here $\\perp$ means **orthogonal to**\n",
    "\n",
    "- estimate $\\gamma, \\lambda_{a}, \\lambda_{b}, \\ldots$ by an appropriate regression technique,  recognizing that the regressors have been generated by a step 1 regression.\n",
    "\n",
    "Note that presumably  the risk-free return $E R^{f}=\\gamma$.\n",
    "\n",
    "For excess returns $R^{ei} = R^i - R^f$ we have\n",
    "\n",
    "$$\n",
    "E R^{e i}=\\beta_{i, a} \\lambda_{a}+\\beta_{i, b} \\lambda_{b}+\\cdots+\\alpha_{i}, i=1, \\ldots, I\n",
    "$$\n",
    "\n",
    "\n",
    "In the  following exercises, we illustrate aspects of these empirical strategies on artificial data. \n",
    "\n",
    "Our basic tools are random number generator that we shall use to create artificial samples that conform to the theory and\n",
    "least squares regressions that let us watch aspects of the theory at work.\n",
    "\n",
    "These exercises will further convince us that asset pricing theory is mostly about covariances and least squares regressions.\n",
    "\n",
    "## Exercises \n",
    "\n",
    "Let's start with some imports."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f0f06a50",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.stats import stats\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.sandbox.regression.gmm import GMM\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "243fff23",
   "metadata": {},
   "source": [
    "Lots of our calculations will involve computing population and sample OLS regressions.\n",
    "\n",
    "So we define a function for simple univariate OLS regression that calls the `OLS` routine from `statsmodels`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3ca1d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_ols(X, Y, constant=False):\n",
    "\n",
    "    if constant:\n",
    "        X = sm.add_constant(X)\n",
    "\n",
    "    model = sm.OLS(Y, X)\n",
    "    res = model.fit()\n",
    "\n",
    "    _hat = res.params[-1]\n",
    "    _hat = np.sqrt(res.resid @ res.resid / res.df_resid)\n",
    "\n",
    "    return _hat, _hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8616ac",
   "metadata": {},
   "source": [
    "```{exercise-start}\n",
    ":label: apl_ex1\n",
    "```\n",
    "\n",
    "Look at the equation, \n",
    "\n",
    "$$\n",
    "R^i_t - R^f = \\beta_{i, R^m} (R^m_t - R^f) + \\sigma_i \\varepsilon_{i, t}.\n",
    "$$\n",
    "\n",
    "Verify that this equation is a regression equation.\n",
    "\n",
    "```{exercise-end}\n",
    "```\n",
    "\n",
    "```{solution-start} apl_ex1\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "To verify that it is a **regression equation** we must show that the residual is orthogonal to the regressor.\n",
    "\n",
    "Our assumptions about mutual orthogonality imply that\n",
    "\n",
    "$$\n",
    "E\\left[\\epsilon_{i,t}\\right]=0,\\quad E\\left[\\epsilon_{i,t}u_{t}\\right]=0\n",
    "$$\n",
    "\n",
    "It follows that\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "E\\left[\\sigma_{i}\\epsilon_{i,t}\\left(R_{t}^{m}-R^{f}\\right)\\right]&=E\\left[\\sigma_{i}\\epsilon_{i,t}\\left(\\xi+\\lambda u_{t}\\right)\\right] \\\\\n",
    "\t&=\\sigma_{i}\\xi E\\left[\\epsilon_{i,t}\\right]+\\sigma_{i}\\lambda E\\left[\\epsilon_{i,t}u_{t}\\right] \\\\\n",
    "\t&=0\n",
    "\\end{aligned}\n",
    "$$\n",
    "\n",
    "```{solution-end}\n",
    "```\n",
    "\n",
    "\n",
    "```{exercise-start}\n",
    ":label: apl_ex2\n",
    "```\n",
    "\n",
    "Give a formula for the regression coefficient $\\beta_{i, R^m}$.\n",
    "\n",
    "```{exercise-end}\n",
    "```\n",
    "\n",
    "```{solution-start} apl_ex2\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "The regression coefficient $\\beta_{i, R^m}$ is\n",
    "\n",
    "$$\n",
    "\\beta_{i,R^{m}}=\\frac{Cov\\left(R_{t}^{i}-R^{f},R_{t}^{m}-R^{f}\\right)}{Var\\left(R_{t}^{m}-R^{f}\\right)}\n",
    "$$\n",
    "\n",
    "```{solution-end}\n",
    "```\n",
    "\n",
    "```{exercise-start}\n",
    ":label: apl_ex3\n",
    "```\n",
    "\n",
    "As in many sciences, it is useful to distinguish a  **direct problem** from  an **inverse problem**.\n",
    "\n",
    "* A direct problem involves simulating a particular model with known parameter values.\n",
    "* An inverse problem involves using data to **estimate** or **choose** a particular  parameter vector  from a manifold of models indexed by a set of parameter vectors.\n",
    "\n",
    "Please assume the parameter values provided below and then simulate 2000 observations from the theory specified\n",
    "above for 5 assets, $i = 1, \\ldots, 5$.\n",
    "\n",
    "\\begin{align*}\n",
    "E\\left[R^f\\right] &= 0.02 \\\\\n",
    "\\sigma_f &= 0.00 \\\\\n",
    "\\xi &= 0.06 \\\\\n",
    "\\lambda &= 0.04 \\\\\n",
    "\\beta_{1, R^m} &= 0.2 \\\\\n",
    "\\sigma_1 &= 0.04 \\\\\n",
    "\\beta_{2, R^m} &= .4 \\\\\n",
    "\\sigma_2 &= 0.04 \\\\\n",
    "\\beta_{3, R^m} &= .6 \\\\\n",
    "\\sigma_3 &= 0.04 \\\\\n",
    "\\beta_{4, R^m} &= .8 \\\\\n",
    "\\sigma_4 &= 0.04 \\\\\n",
    "\\beta_{5, R^m} &= 1.0 \\\\\n",
    "\\sigma_5 &= 0.04\n",
    "\\end{align*}\n",
    "\n",
    "**More Exercises**\n",
    "\n",
    "Now come some even more fun parts!\n",
    "\n",
    "Our theory implies that there exist values of  two scalars, $a$ and $b$, such that  a legitimate stochastic discount factor is:\n",
    "\n",
    "$$\n",
    "m_t = a + b R^m_t\n",
    "$$\n",
    "\n",
    "The parameters $a, b$ must satisfy the following equations:\n",
    "\n",
    "\\begin{align*}\n",
    "E[(a + b R_t^m) R^m_t)] &= 1 \\\\\n",
    "E[(a + b R_t^m) R^f_t)] &= 1\n",
    "\\end{align*}\n",
    "\n",
    "```{exercise-end}\n",
    "```\n",
    "\n",
    "```{solution-start} apl_ex3\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "**Direct Problem:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c4242274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for the direct problem\n",
    "\n",
    "# assign the parameter values\n",
    "ERf = 0.02\n",
    "f = 0.00 # Zejin: Hi tom, here is where you manipulate f\n",
    " = 0.06\n",
    " = 0.08\n",
    "i = np.array([0.2, .4, .6, .8, 1.0])\n",
    "i = np.array([0.04, 0.04, 0.04, 0.04, 0.04])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cbc64ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# in this cell we set the number of assets and number of observations\n",
    "# we first set T to a large number to verify our computation results\n",
    "T = 2000\n",
    "N = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "23b157d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate i.i.d. random shocks\n",
    "e = np.random.normal(size=T)\n",
    "u = np.random.normal(size=T)\n",
    " = np.random.normal(size=(N, T))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4bb7bead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simulate the return on a risk-free asset\n",
    "Rf = ERf + f * e\n",
    "\n",
    "# simulate the return on the market portfolio\n",
    "excess_Rm =  +  * u\n",
    "Rm = Rf + excess_Rm\n",
    "\n",
    "# simulate the return on asset i\n",
    "Ri = np.empty((N, T))\n",
    "for i in range(N):\n",
    "    Ri[i, :] = Rf + i[i] * excess_Rm + i[i] * [i, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf5f6dd",
   "metadata": {},
   "source": [
    "Now that we have a panel of data, we'd like to solve the inverse problem by assuming the theory specified above and estimating the coefficients given above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b41dd7c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for the inverse problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f1c482",
   "metadata": {},
   "source": [
    "**Inverse Problem:**\n",
    "\n",
    "We will solve the inverse problem by simple OLS regressions.\n",
    "\n",
    "1. estimate $E\\left[R^f\\right]$ and $\\sigma_f$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9165352a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ERf_hat, f_hat = simple_ols(np.ones(T), Rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bca79c4a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02000000000000003, 3.123283175179055e-17)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERf_hat, f_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef31898",
   "metadata": {},
   "source": [
    "Let's  compare these with the _true_ population parameter values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "06566dce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.02, 0.0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ERf, f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7a170c1",
   "metadata": {},
   "source": [
    "2. $\\xi$ and $\\lambda$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "772462d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "_hat, _hat = simple_ols(np.ones(T), Rm - Rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "63e89a70",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06302287024648721, 0.08178445686921211)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_hat, _hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "887792ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.06, 0.08)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    ", "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03bef379",
   "metadata": {},
   "source": [
    "3. $\\beta_{i, R^m}$ and $\\sigma_i$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c19ab280",
   "metadata": {},
   "outputs": [],
   "source": [
    "i_hat = np.empty(N)\n",
    "i_hat = np.empty(N)\n",
    "\n",
    "for i in range(N):\n",
    "    i_hat[i], i_hat[i] = simple_ols(Rm - Rf, Ri[i, :] - Rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38b7cde3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.19226266, 0.39805875, 0.59939641, 0.7994372 , 1.00406981]),\n",
       " array([0.03913062, 0.04060062, 0.0394525 , 0.04049393, 0.04026443]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i_hat, i_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "263cf08f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.2, 0.4, 0.6, 0.8, 1. ]), array([0.04, 0.04, 0.04, 0.04, 0.04]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "i, i"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8cb0897",
   "metadata": {},
   "source": [
    "Q: How close did your estimates come to the parameters we specified?\n",
    "\n",
    "```{solution-end}\n",
    "```\n",
    "\n",
    "```{exercise-start}\n",
    ":label: apl_ex4\n",
    "```\n",
    "\n",
    "Using the equations above, find a system of two **linear** equations that you can solve for $a$ and $b$ as functions of the parameters $(\\lambda, \\xi, E[R_f])$.\n",
    "\n",
    "Write a function that can solve these equations.\n",
    "\n",
    "Please check the **condition number** of a key matrix that must be inverted to determine a, b\n",
    "\n",
    "```{exercise-end}\n",
    "```\n",
    "\n",
    "```{solution-start} apl_ex4\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "The system of two linear equations is shown below:\n",
    "\n",
    "\n",
    "$$\n",
    "\\begin{aligned}\n",
    "a ((E(R^f) + \\xi) + b ((E(R^f) + \\xi)^2 + \\lambda^2 + \\sigma_f^2) & =1 \\cr\n",
    "a E(R^f) + b (E(R^f)^2 + \\xi E(R^f) + \\sigma_f ^ 2) & = 1 \n",
    "\\end{aligned}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "28500cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code here\n",
    "def solve_ab(ERf, f, , ):\n",
    "\n",
    "    M = np.empty((2, 2))\n",
    "    M[0, 0] = ERf + \n",
    "    M[0, 1] = (ERf + ) ** 2 +  ** 2 + f ** 2\n",
    "    M[1, 0] = ERf\n",
    "    M[1, 1] = ERf ** 2 +  * ERf + f ** 2\n",
    "\n",
    "    a, b = np.linalg.solve(M, np.ones(2))\n",
    "    condM = np.linalg.cond(M)\n",
    "\n",
    "    return a, b, condM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "008c71ee",
   "metadata": {},
   "source": [
    "Let's try to solve $a$ and $b$ using the actual model parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc8f5a82",
   "metadata": {},
   "outputs": [],
   "source": [
    "a, b, condM = solve_ab(ERf, f, , )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3c2cdfb7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(87.49999999999999, -468.7499999999999, 54.406619883717504)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a, b, condM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c717c03e",
   "metadata": {},
   "source": [
    "```{solution-end}\n",
    "```\n",
    "\n",
    "```{exercise-start}\n",
    ":label: apl_ex5\n",
    "```\n",
    "\n",
    "Using the estimates of the parameters that you generated above, compute the implied stochastic discount factor.\n",
    "\n",
    "```{exercise-end}\n",
    "```\n",
    "\n",
    "```{solution-start} apl_ex5\n",
    ":class: dropdown\n",
    "```\n",
    "\n",
    "Now let's pass $\\hat{E}(R^f), \\hat{\\sigma}^f, \\hat{\\lambda}, \\hat{\\xi}$ to the function `solve_ab`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "282a6f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "a_hat, b_hat, M_hat = solve_ab(ERf_hat, f_hat, _hat, _hat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9f311ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(89.11329275011468, -471.11467760619456, 55.89741512191402)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a_hat, b_hat, M_hat"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "223eb24c",
   "metadata": {},
   "source": [
    "```{solution-end}\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "text_representation": {
    "extension": ".md",
    "format_name": "myst",
    "format_version": 0.13,
    "jupytext_version": "1.11.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "source_map": [
   12,
   356,
   396,
   485,
   541,
   589,
   596,
   602,
   615,
   735,
   747,
   754,
   761,
   773,
   777,
   779,
   787,
   791,
   793,
   797,
   799,
   803,
   807,
   811,
   813,
   817,
   825,
   829,
   831,
   866,
   880,
   884,
   888,
   890,
   910,
   914,
   916
  ]
 },
 "nbformat": 4,
 "nbformat_minor": 5
}