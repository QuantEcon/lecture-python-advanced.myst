

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>4. Discrete State Dynamic Programming &#8212; Advanced Quantitative Economics with Python</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/quantecon-book-theme.css?digest=bd0785fbb14d8d2bd4d9ae501d79ed8d3bc089ec" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-design.5ea377869091fd0449014c60fc090103.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>


    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/scripts/quantecon-book-theme.js?digest=d6d86bce9979111653c4c495e33499e1796e172a"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-KZLV7PM9LL"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-KZLV7PM9LL');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "arg\\,max", "argmin": "arg\\,min", "col": "col", "Span": "span", "epsilon": "\\varepsilon", "EE": "\\mathbb{E}", "PP": "\\mathbb{P}", "RR": "\\mathbb{R}", "NN": "\\mathbb{N}", "ZZ": "\\mathbb{Z}", "aA": "\\mathcal{A}", "bB": "\\mathcal{B}", "cC": "\\mathcal{C}", "dD": "\\mathcal{D}", "eE": "\\mathcal{E}", "fF": "\\mathcal{F}", "gG": "\\mathcal{G}", "hH": "\\mathcal{H}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'discrete_dp';</script>
    <link rel="canonical" href="https://python-advanced.quantecon.org/discrete_dp.html" />
    <link rel="shortcut icon" href="_static/lectures-favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="5. Information and Consumption Smoothing" href="cons_news.html" />
    <link rel="prev" title="3. Reverse Engineering a la Muth" href="muth_kalman.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Thomas J. Sargent &amp; John Stachurski" />
<meta name="keywords" content="Python, QuantEcon, Quantitative Economics, Economics, Sloan, Alfred P. Sloan Foundation, Tom J. Sargent, John Stachurski" />
<meta name="description" content=This website presents a set of lectures on advanced quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="Discrete State Dynamic Programming"/>
<meta name="twitter:description" content="This website presents a set of lectures on advanced quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="Discrete State Dynamic Programming" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://python-advanced.quantecon.org/discrete_dp.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents a set of lectures on advanced quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski." />
<meta property="og:site_name" content="Advanced Quantitative Economics with Python" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="qe-wrapper">

        <div class="qe-main">

            <div class="qe-page" id=discrete_dp>

                <div class="qe-page__toc">

                    <div class="inner">

                        
                        <div class="qe-page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="qe-page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">4.1. Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#how-to-read-this-lecture">4.1.1. How to Read this Lecture</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#code">4.1.2. Code</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#references">4.1.3. References</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-dps">4.2. Discrete DPs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#policies">4.2.1. Policies</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#formal-definition">4.2.2. Formal Definition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#value-and-optimality">4.2.3. Value and Optimality</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#two-operators">4.2.4. Two Operators</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-bellman-equation-and-the-principle-of-optimality">4.2.5. The Bellman Equation and the Principle of Optimality</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-discrete-dps">4.3. Solving Discrete DPs</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#value-function-iteration">4.3.1. Value Function Iteration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#policy-function-iteration">4.3.2. Policy Function Iteration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#modified-policy-function-iteration">4.3.3. Modified Policy Function Iteration</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#example-a-growth-model">4.4. Example: A Growth Model</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#discrete-dp-representation">4.4.1. Discrete DP Representation</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#defining-a-discretedp-instance">4.4.2. Defining a DiscreteDP Instance</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#state-action-pair-formulation">4.4.3. State-Action Pair Formulation</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">4.5. Exercises</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#solutions">4.6. Solutions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#setup">4.6.1. Setup</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solving-the-model">4.6.2. Solving the Model</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#comparison-of-the-solution-methods">4.6.3. Comparison of the Solution Methods</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#value-iteration">4.6.3.1. Value Iteration</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#modified-policy-iteration">4.6.3.2. Modified Policy Iteration</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#speed-comparison">4.6.3.3. Speed Comparison</a></li>
</ul>
</li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#replication-of-the-figures">4.6.4. Replication of the Figures</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#convergence-of-value-iteration">4.6.4.1. Convergence of Value Iteration</a></li>
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#dynamics-of-the-capital-stock">4.6.4.2. Dynamics of the Capital Stock</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#appendix-algorithms">4.7. Appendix: Algorithms</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id9">4.7.1. Value Iteration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#policy-iteration">4.7.2. Policy Iteration</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#id10">4.7.3. Modified Policy Iteration</a></li>
</ul>
</li>
</ul>
                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="_static/qe-logo-large.png" class="logo logo-img" alt="logo"></a>
                                    
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="qe-page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="qe-page__header">

                    <div class="qe-page__header-copy">

                        <p class="qe-page__header-heading"><a href="intro.html">Advanced Quantitative Economics with Python</a></p>

                        <p class="qe-page__header-subheading">Discrete State Dynamic Programming</p>

                    </div>
                    <!-- length 2, since its a string and empty dict has length 2 - {} -->
                        <p class="qe-page__header-authors" font-size="18">
                            
                                
                                    <a href="http://www.tomsargent.com/" target="_blank"><span>Thomas J. Sargent</span></a>
                                
                            
                                
                                    and <a href="https://johnstachurski.net/" target="_blank"><span>John Stachurski</span></a>
                                
                            
                        </p>


                </div> <!-- .page__header -->



                
                <main class="qe-page__content" role="main">
                    
                    <div>
                        
  <div id="qe-notebook-header" align="right" style="text-align:right;">
        <a href="https://quantecon.org/" title="quantecon.org">
                <img style="width:250px;display:inline;" width="250px" src="https://assets.quantecon.org/img/qe-menubar-logo.svg" alt="QuantEcon">
        </a>
</div><section class="tex2jax_ignore mathjax_ignore" id="discrete-state-dynamic-programming">
<h1><span class="section-number">4. </span><span class="target" id="index-0"></span>Discrete State Dynamic Programming<a class="headerlink" href="#discrete-state-dynamic-programming" title="Permalink to this heading">#</a></h1>
<p>In addition to what’s in Anaconda, this lecture will need the following libraries:</p>
<div class="cell tag_hide-output docutils container">
<div class="cell_input above-output-prompt docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">!</span>pip<span class="w"> </span>install<span class="w"> </span>--upgrade<span class="w"> </span>quantecon
</pre></div>
</div>
</div>
<details class="hide below-input">
<summary aria-label="Toggle hidden content">
<span class="collapsed">Show code cell output</span>
<span class="expanded">Hide code cell output</span>
</summary>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: quantecon in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (0.8.0)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Requirement already satisfied: numba&gt;=0.49.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from quantecon) (0.60.0)
Requirement already satisfied: numpy&gt;=1.17.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from quantecon) (1.26.4)
Requirement already satisfied: requests in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from quantecon) (2.32.3)
Requirement already satisfied: scipy&gt;=1.5.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from quantecon) (1.13.1)
Requirement already satisfied: sympy in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from quantecon) (1.13.2)
Requirement already satisfied: llvmlite&lt;0.44,&gt;=0.43.0dev0 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from numba&gt;=0.49.0-&gt;quantecon) (0.43.0)
Requirement already satisfied: charset-normalizer&lt;4,&gt;=2 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from requests-&gt;quantecon) (3.3.2)
Requirement already satisfied: idna&lt;4,&gt;=2.5 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from requests-&gt;quantecon) (3.7)
Requirement already satisfied: urllib3&lt;3,&gt;=1.21.1 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from requests-&gt;quantecon) (2.2.3)
Requirement already satisfied: certifi&gt;=2017.4.17 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from requests-&gt;quantecon) (2024.8.30)
Requirement already satisfied: mpmath&lt;1.4,&gt;=1.1.0 in /home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages (from sympy-&gt;quantecon) (1.3.0)
</pre></div>
</div>
</div>
</details>
</div>
<section id="overview">
<h2><span class="section-number">4.1. </span>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>In this lecture we discuss a family of dynamic programming problems with the following features:</p>
<ol class="arabic simple">
<li><p>a discrete state space and discrete choices (actions)</p></li>
<li><p>an infinite horizon</p></li>
<li><p>discounted rewards</p></li>
<li><p>Markov state transitions</p></li>
</ol>
<p>We call such problems discrete dynamic programs or discrete DPs.</p>
<p>Discrete DPs are the workhorses in much of modern quantitative economics, including</p>
<ul class="simple">
<li><p>monetary economics</p></li>
<li><p>search and labor economics</p></li>
<li><p>household savings and consumption theory</p></li>
<li><p>investment theory</p></li>
<li><p>asset pricing</p></li>
<li><p>industrial organization, etc.</p></li>
</ul>
<p>When a given model is not inherently discrete, it is common to replace it with a discretized version in order to use discrete DP techniques.</p>
<p>This lecture covers</p>
<ul class="simple">
<li><p>the theory of dynamic programming in a discrete setting, plus examples and
applications</p></li>
<li><p>a powerful set of routines for solving discrete DPs from the <a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon code library</a></p></li>
</ul>
<p>Let’s start with some imports:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">quantecon</span> <span class="k">as</span> <span class="nn">qe</span>
<span class="kn">import</span> <span class="nn">scipy.sparse</span> <span class="k">as</span> <span class="nn">sparse</span>
<span class="kn">from</span> <span class="nn">quantecon</span> <span class="kn">import</span> <span class="n">compute_fixed_point</span>
<span class="kn">from</span> <span class="nn">quantecon.markov</span> <span class="kn">import</span> <span class="n">DiscreteDP</span>
</pre></div>
</div>
</div>
</div>
<section id="how-to-read-this-lecture">
<h3><span class="section-number">4.1.1. </span>How to Read this Lecture<a class="headerlink" href="#how-to-read-this-lecture" title="Permalink to this heading">#</a></h3>
<p>We use dynamic programming many applied lectures, such as</p>
<ul class="simple">
<li><p>The <a class="reference external" href="https://python-intro.quantecon.org/short_path.html">shortest path lecture</a></p></li>
<li><p>The <a class="reference external" href="https://python-intro.quantecon.org/mccall_model.html">McCall search model lecture</a></p></li>
</ul>
<p>The objective of this lecture is to provide a more systematic and theoretical treatment, including algorithms and implementation while focusing on the discrete case.</p>
</section>
<section id="code">
<h3><span class="section-number">4.1.2. </span>Code<a class="headerlink" href="#code" title="Permalink to this heading">#</a></h3>
<p>Among other things, it offers</p>
<ul class="simple">
<li><p>a flexible, well-designed interface</p></li>
<li><p>multiple solution methods, including value function and policy function iteration</p></li>
<li><p>high-speed operations via carefully optimized JIT-compiled functions</p></li>
<li><p>the ability to scale to large problems by minimizing vectorized operators and allowing operations on sparse matrices</p></li>
</ul>
<p>JIT compilation relies on <a class="reference external" href="http://numba.pydata.org/">Numba</a>, which should work
seamlessly if you are using <a class="reference external" href="https://www.anaconda.com/download/">Anaconda</a> as <a class="reference external" href="https://python-programming.quantecon.org/getting_started.html">suggested</a>.</p>
</section>
<section id="references">
<h3><span class="section-number">4.1.3. </span>References<a class="headerlink" href="#references" title="Permalink to this heading">#</a></h3>
<p>For background reading on dynamic programming and additional applications, see, for example,</p>
<ul class="simple">
<li><p><span id="id1">[<a class="reference internal" href="zreferences.html#id176" title="L Ljungqvist and T J Sargent. Recursive Macroeconomic Theory. MIT Press, 4 edition, 2018.">Ljungqvist and Sargent, 2018</a>]</span></p></li>
<li><p><span id="id2">[<a class="reference internal" href="zreferences.html#id162" title="O Hernandez-Lerma and J B Lasserre. Discrete-Time Markov Control Processes: Basic Optimality Criteria. Number Vol 1 in Applications of Mathematics Stochastic Modelling and Applied Probability. Springer, 1996.">Hernandez-Lerma and Lasserre, 1996</a>]</span>, section 3.5</p></li>
<li><p><span id="id3">[<a class="reference internal" href="zreferences.html#id125" title="Martin L Puterman. Markov decision processes: discrete stochastic dynamic programming. John Wiley &amp; Sons, 2005.">Puterman, 2005</a>]</span></p></li>
<li><p><span id="id4">[<a class="reference internal" href="zreferences.html#id212" title="N L Stokey, R E Lucas, and E C Prescott. Recursive Methods in Economic Dynamics. Harvard University Press, 1989.">Stokey <em>et al.</em>, 1989</a>]</span></p></li>
<li><p><span id="id5">[<a class="reference internal" href="zreferences.html#id134" title="John Rust. Numerical dynamic programming in economics. Handbook of computational economics, 1:619–729, 1996.">Rust, 1996</a>]</span></p></li>
<li><p><span id="id6">[<a class="reference internal" href="zreferences.html#id188" title="Mario J Miranda and P L Fackler. Applied Computational Economics and Finance. Cambridge: MIT Press, 2002.">Miranda and Fackler, 2002</a>]</span></p></li>
<li><p><a class="reference external" href="http://johnstachurski.net/edtc.html">EDTC</a>, chapter 5</p></li>
</ul>
</section>
</section>
<section id="discrete-dps">
<span id="id7"></span><h2><span class="section-number">4.2. </span>Discrete DPs<a class="headerlink" href="#discrete-dps" title="Permalink to this heading">#</a></h2>
<p>Loosely speaking, a discrete DP is a maximization problem with an objective
function of the form</p>
<div class="math notranslate nohighlight" id="equation-dp-objective">
<span class="eqno">(4.1)<a class="headerlink" href="#equation-dp-objective" title="Permalink to this equation">#</a></span>\[\mathbb{E}
\sum_{t = 0}^{\infty} \beta^t r(s_t, a_t)\]</div>
<p>where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(s_t\)</span> is the state variable</p></li>
<li><p><span class="math notranslate nohighlight">\(a_t\)</span> is the action</p></li>
<li><p><span class="math notranslate nohighlight">\(\beta\)</span> is a discount factor</p></li>
<li><p><span class="math notranslate nohighlight">\(r(s_t, a_t)\)</span> is interpreted as a current reward when the state is <span class="math notranslate nohighlight">\(s_t\)</span> and the action chosen is <span class="math notranslate nohighlight">\(a_t\)</span></p></li>
</ul>
<p>Each pair <span class="math notranslate nohighlight">\((s_t, a_t)\)</span> pins down transition probabilities <span class="math notranslate nohighlight">\(Q(s_t, a_t, s_{t+1})\)</span> for the next period state <span class="math notranslate nohighlight">\(s_{t+1}\)</span>.</p>
<p>Thus, actions influence not only current rewards but also the future time path of the state.</p>
<p>The essence of dynamic programming problems is to trade off current rewards
vs favorable positioning of the future state (modulo randomness).</p>
<p>Examples:</p>
<ul class="simple">
<li><p>consuming today vs saving and accumulating assets</p></li>
<li><p>accepting a job offer today vs seeking a better one in the future</p></li>
<li><p>exercising an option now vs waiting</p></li>
</ul>
<section id="policies">
<h3><span class="section-number">4.2.1. </span>Policies<a class="headerlink" href="#policies" title="Permalink to this heading">#</a></h3>
<p>The most fruitful way to think about solutions to discrete DP problems is to compare <em>policies</em>.</p>
<p>In general, a policy is a randomized map from past actions and states to
current action.</p>
<p>In the setting formalized below, it suffices to consider so-called <em>stationary Markov policies</em>, which consider only the current state.</p>
<p>In particular, a stationary Markov policy is a map <span class="math notranslate nohighlight">\(\sigma\)</span> from states to actions</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(a_t = \sigma(s_t)\)</span> indicates that <span class="math notranslate nohighlight">\(a_t\)</span> is the action to be taken in state <span class="math notranslate nohighlight">\(s_t\)</span></p></li>
</ul>
<p>It is known that, for any arbitrary policy, there exists a stationary Markov policy that dominates it at least weakly.</p>
<ul class="simple">
<li><p>See section 5.5 of <span id="id8">[<a class="reference internal" href="zreferences.html#id125" title="Martin L Puterman. Markov decision processes: discrete stochastic dynamic programming. John Wiley &amp; Sons, 2005.">Puterman, 2005</a>]</span> for discussion and proofs.</p></li>
</ul>
<p>In what follows, stationary Markov policies are referred to simply as policies.</p>
<p>The aim is to find an optimal policy, in the sense of one that maximizes <a class="reference internal" href="#equation-dp-objective">(4.1)</a>.</p>
<p>Let’s now step through these ideas more carefully.</p>
</section>
<section id="formal-definition">
<h3><span class="section-number">4.2.2. </span>Formal Definition<a class="headerlink" href="#formal-definition" title="Permalink to this heading">#</a></h3>
<p>Formally, a discrete dynamic program consists of the following components:</p>
<ol class="arabic">
<li><p>A finite set of <em>states</em> <span class="math notranslate nohighlight">\(S = \{0, \ldots, n-1\}\)</span>.</p></li>
<li><p>A finite set of <em>feasible actions</em> <span class="math notranslate nohighlight">\(A(s)\)</span> for each state <span class="math notranslate nohighlight">\(s \in S\)</span>, and a corresponding set of <em>feasible state-action pairs</em>.</p>
<div class="math notranslate nohighlight">
\[
   \mathit{SA} := \{(s, a) \mid s \in S, \; a \in A(s)\}
   \]</div>
</li>
<li><p>A <em>reward function</em> <span class="math notranslate nohighlight">\(r\colon \mathit{SA} \to \mathbb{R}\)</span>.</p></li>
<li><p>A <em>transition probability function</em> <span class="math notranslate nohighlight">\(Q\colon \mathit{SA} \to \Delta(S)\)</span>, where <span class="math notranslate nohighlight">\(\Delta(S)\)</span> is the set of probability distributions over <span class="math notranslate nohighlight">\(S\)</span>.</p></li>
<li><p>A <em>discount factor</em> <span class="math notranslate nohighlight">\(\beta \in [0, 1)\)</span>.</p></li>
</ol>
<p>We also use the notation <span class="math notranslate nohighlight">\(A := \bigcup_{s \in S} A(s) = \{0, \ldots, m-1\}\)</span> and call this set the <em>action space</em>.</p>
<p>A <em>policy</em> is a function <span class="math notranslate nohighlight">\(\sigma\colon S \to A\)</span>.</p>
<p>A policy is called <em>feasible</em> if it satisfies <span class="math notranslate nohighlight">\(\sigma(s) \in A(s)\)</span> for all <span class="math notranslate nohighlight">\(s \in S\)</span>.</p>
<p>Denote the set of all feasible policies by <span class="math notranslate nohighlight">\(\Sigma\)</span>.</p>
<p>If a decision-maker uses  a policy <span class="math notranslate nohighlight">\(\sigma \in \Sigma\)</span>, then</p>
<ul class="simple">
<li><p>the current reward at time <span class="math notranslate nohighlight">\(t\)</span> is <span class="math notranslate nohighlight">\(r(s_t, \sigma(s_t))\)</span></p></li>
<li><p>the probability that <span class="math notranslate nohighlight">\(s_{t+1} = s'\)</span> is <span class="math notranslate nohighlight">\(Q(s_t, \sigma(s_t), s')\)</span></p></li>
</ul>
<p>For each <span class="math notranslate nohighlight">\(\sigma \in \Sigma\)</span>, define</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(r_{\sigma}\)</span> by <span class="math notranslate nohighlight">\(r_{\sigma}(s) := r(s, \sigma(s))\)</span>)</p></li>
<li><p><span class="math notranslate nohighlight">\(Q_{\sigma}\)</span> by <span class="math notranslate nohighlight">\(Q_{\sigma}(s, s') := Q(s, \sigma(s), s')\)</span></p></li>
</ul>
<p>Notice that <span class="math notranslate nohighlight">\(Q_\sigma\)</span> is a <a class="reference external" href="https://python.quantecon.org/finite_markov.html#stochastic-matrices">stochastic matrix</a> on <span class="math notranslate nohighlight">\(S\)</span>.</p>
<p>It gives transition probabilities of the <em>controlled chain</em> when we follow policy <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>If we think of <span class="math notranslate nohighlight">\(r_\sigma\)</span> as a column vector, then so is <span class="math notranslate nohighlight">\(Q_\sigma^t r_\sigma\)</span>, and the <span class="math notranslate nohighlight">\(s\)</span>-th row of the latter has the interpretation</p>
<div class="math notranslate nohighlight" id="equation-ddp-expec">
<span class="eqno">(4.2)<a class="headerlink" href="#equation-ddp-expec" title="Permalink to this equation">#</a></span>\[(Q_\sigma^t r_\sigma)(s) = \mathbb E [ r(s_t, \sigma(s_t)) \mid s_0 = s ]
\quad \text{when } \{s_t\} \sim Q_\sigma\]</div>
<p>Comments</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\{s_t\} \sim Q_\sigma\)</span> means that the state is generated by stochastic matrix <span class="math notranslate nohighlight">\(Q_\sigma\)</span>.</p></li>
<li><p>See <a class="reference external" href="https://python.quantecon.org/finite_markov.html#multiple-step-transition-probabilities">this discussion</a> on computing expectations of Markov chains for an explanation of the expression in <a class="reference internal" href="#equation-ddp-expec">(4.2)</a>.</p></li>
</ul>
<p>Notice that we’re not really distinguishing between functions from <span class="math notranslate nohighlight">\(S\)</span> to <span class="math notranslate nohighlight">\(\mathbb R\)</span> and vectors in <span class="math notranslate nohighlight">\(\mathbb R^n\)</span>.</p>
<p>This is natural because they are in one to one correspondence.</p>
</section>
<section id="value-and-optimality">
<h3><span class="section-number">4.2.3. </span>Value and Optimality<a class="headerlink" href="#value-and-optimality" title="Permalink to this heading">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(v_{\sigma}(s)\)</span> denote the discounted sum of expected reward flows from policy <span class="math notranslate nohighlight">\(\sigma\)</span>
when the initial state is <span class="math notranslate nohighlight">\(s\)</span>.</p>
<p>To calculate this quantity we pass the expectation through the sum in
<a class="reference internal" href="#equation-dp-objective">(4.1)</a> and use <a class="reference internal" href="#equation-ddp-expec">(4.2)</a> to get</p>
<div class="math notranslate nohighlight">
\[
v_{\sigma}(s) = \sum_{t=0}^{\infty} \beta^t (Q_{\sigma}^t r_{\sigma})(s)
\qquad (s \in S)
\]</div>
<p>This function is called the <em>policy value function</em> for the policy <span class="math notranslate nohighlight">\(\sigma\)</span>.</p>
<p>The <em>optimal value function</em>, or simply <em>value function</em>, is the function <span class="math notranslate nohighlight">\(v^*\colon S \to \mathbb{R}\)</span> defined by</p>
<div class="math notranslate nohighlight">
\[
v^*(s) = \max_{\sigma \in \Sigma} v_{\sigma}(s)
\qquad (s \in S)
\]</div>
<p>(We can use max rather than sup here because the domain is a finite set)</p>
<p>A policy <span class="math notranslate nohighlight">\(\sigma \in \Sigma\)</span> is called <em>optimal</em> if <span class="math notranslate nohighlight">\(v_{\sigma}(s) = v^*(s)\)</span> for all <span class="math notranslate nohighlight">\(s \in S\)</span>.</p>
<p>Given any <span class="math notranslate nohighlight">\(w \colon S \to \mathbb R\)</span>, a policy <span class="math notranslate nohighlight">\(\sigma \in \Sigma\)</span> is called <span class="math notranslate nohighlight">\(w\)</span>-greedy if</p>
<div class="math notranslate nohighlight">
\[
\sigma(s) \in \operatorname*{arg\,max}_{a \in A(s)}
\left\{
    r(s, a) +
    \beta \sum_{s' \in S} w(s') Q(s, a, s')
\right\}
\qquad (s \in S)
\]</div>
<p>As discussed in detail below, optimal policies are precisely those that are <span class="math notranslate nohighlight">\(v^*\)</span>-greedy.</p>
</section>
<section id="two-operators">
<h3><span class="section-number">4.2.4. </span>Two Operators<a class="headerlink" href="#two-operators" title="Permalink to this heading">#</a></h3>
<p>It is useful to define the following operators:</p>
<ul class="simple">
<li><p>The <em>Bellman operator</em> <span class="math notranslate nohighlight">\(T\colon \mathbb{R}^S \to \mathbb{R}^S\)</span>
is defined by</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
(T v)(s) = \max_{a \in A(s)}
\left\{
    r(s, a) + \beta \sum_{s' \in S} v(s') Q(s, a, s')
\right\}
\qquad (s \in S)
\]</div>
<ul class="simple">
<li><p>For any policy function <span class="math notranslate nohighlight">\(\sigma \in \Sigma\)</span>, the operator <span class="math notranslate nohighlight">\(T_{\sigma}\colon \mathbb{R}^S \to \mathbb{R}^S\)</span> is defined by</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
(T_{\sigma} v)(s) = r(s, \sigma(s)) +
    \beta \sum_{s' \in S} v(s') Q(s, \sigma(s), s')
\qquad (s \in S)
\]</div>
<p>This can be written more succinctly in operator notation as</p>
<div class="math notranslate nohighlight">
\[
T_{\sigma} v = r_{\sigma} + \beta Q_{\sigma} v
\]</div>
<p>The two operators are both monotone</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(v \leq w\)</span>  implies <span class="math notranslate nohighlight">\(Tv \leq Tw\)</span> pointwise on <span class="math notranslate nohighlight">\(S\)</span>, and
similarly for <span class="math notranslate nohighlight">\(T_\sigma\)</span></p></li>
</ul>
<p>They are also contraction mappings with modulus <span class="math notranslate nohighlight">\(\beta\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\lVert Tv - Tw \rVert \leq \beta \lVert v - w \rVert\)</span> and similarly for <span class="math notranslate nohighlight">\(T_\sigma\)</span>, where <span class="math notranslate nohighlight">\(\lVert \cdot\rVert\)</span> is the max norm</p></li>
</ul>
<p>For any policy <span class="math notranslate nohighlight">\(\sigma\)</span>, its value <span class="math notranslate nohighlight">\(v_{\sigma}\)</span> is the unique fixed point of <span class="math notranslate nohighlight">\(T_{\sigma}\)</span>.</p>
<p>For proofs of these results and those in the next section, see, for example, <a class="reference external" href="http://johnstachurski.net/edtc.html">EDTC</a>, chapter 10.</p>
</section>
<section id="the-bellman-equation-and-the-principle-of-optimality">
<h3><span class="section-number">4.2.5. </span>The Bellman Equation and the Principle of Optimality<a class="headerlink" href="#the-bellman-equation-and-the-principle-of-optimality" title="Permalink to this heading">#</a></h3>
<p>The main principle of the theory of dynamic programming is that</p>
<ul class="simple">
<li><p>the optimal value function <span class="math notranslate nohighlight">\(v^*\)</span> is a unique solution to the <em>Bellman equation</em></p></li>
</ul>
<div class="math notranslate nohighlight">
\[
v(s) = \max_{a \in A(s)}
    \left\{
        r(s, a) + \beta \sum_{s' \in S} v(s') Q(s, a, s')
    \right\}
\qquad (s \in S)
\]</div>
<p>or in other words, <span class="math notranslate nohighlight">\(v^*\)</span> is the unique fixed point of <span class="math notranslate nohighlight">\(T\)</span>, and</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\sigma^*\)</span> is an optimal policy function if and only if it is <span class="math notranslate nohighlight">\(v^*\)</span>-greedy</p></li>
</ul>
<p>By the definition of greedy policies given above, this means that</p>
<div class="math notranslate nohighlight">
\[
\sigma^*(s) \in \operatorname*{arg\,max}_{a \in A(s)}
    \left\{
    r(s, a) + \beta \sum_{s' \in S} v^*(s') Q(s, a, s')
    \right\}
\qquad (s \in S)
\]</div>
</section>
</section>
<section id="solving-discrete-dps">
<h2><span class="section-number">4.3. </span>Solving Discrete DPs<a class="headerlink" href="#solving-discrete-dps" title="Permalink to this heading">#</a></h2>
<p>Now that the theory has been set out, let’s turn to solution methods.</p>
<p>The code for solving discrete DPs is available in <a class="reference external" href="https://github.com/QuantEcon/QuantEcon.py/blob/master/quantecon/markov/ddp.py">ddp.py</a> from the <a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon.py</a> code library.</p>
<p>It implements the three most important solution methods for discrete dynamic programs, namely</p>
<ul class="simple">
<li><p>value function iteration</p></li>
<li><p>policy function iteration</p></li>
<li><p>modified policy function iteration</p></li>
</ul>
<p>Let’s briefly review these algorithms and their implementation.</p>
<section id="value-function-iteration">
<h3><span class="section-number">4.3.1. </span>Value Function Iteration<a class="headerlink" href="#value-function-iteration" title="Permalink to this heading">#</a></h3>
<p>Perhaps the most familiar method for solving all manner of dynamic programs is value function iteration.</p>
<p>This algorithm uses the fact that the Bellman operator <span class="math notranslate nohighlight">\(T\)</span> is a contraction mapping with fixed point <span class="math notranslate nohighlight">\(v^*\)</span>.</p>
<p>Hence, iterative application of <span class="math notranslate nohighlight">\(T\)</span> to any initial function <span class="math notranslate nohighlight">\(v^0 \colon S \to \mathbb R\)</span> converges to <span class="math notranslate nohighlight">\(v^*\)</span>.</p>
<p>The details of the algorithm can be found in <a class="reference internal" href="#ddp-algorithms"><span class="std std-ref">the appendix</span></a>.</p>
</section>
<section id="policy-function-iteration">
<h3><span class="section-number">4.3.2. </span>Policy Function Iteration<a class="headerlink" href="#policy-function-iteration" title="Permalink to this heading">#</a></h3>
<p>This routine, also known as Howard’s policy improvement algorithm, exploits more closely the particular structure of a discrete DP problem.</p>
<p>Each iteration consists of</p>
<ol class="arabic simple">
<li><p>A policy evaluation step that computes the value <span class="math notranslate nohighlight">\(v_{\sigma}\)</span> of a policy <span class="math notranslate nohighlight">\(\sigma\)</span> by solving the linear equation <span class="math notranslate nohighlight">\(v = T_{\sigma} v\)</span>.</p></li>
<li><p>A policy improvement step that computes a <span class="math notranslate nohighlight">\(v_{\sigma}\)</span>-greedy policy.</p></li>
</ol>
<p>In the current setting, policy iteration computes an exact optimal policy in finitely many iterations.</p>
<ul class="simple">
<li><p>See theorem 10.2.6 of <a class="reference external" href="http://johnstachurski.net/edtc.html">EDTC</a> for a proof.</p></li>
</ul>
<p>The details of the algorithm can be found in <a class="reference internal" href="#ddp-algorithms"><span class="std std-ref">the appendix</span></a>.</p>
</section>
<section id="modified-policy-function-iteration">
<h3><span class="section-number">4.3.3. </span>Modified Policy Function Iteration<a class="headerlink" href="#modified-policy-function-iteration" title="Permalink to this heading">#</a></h3>
<p>Modified policy iteration replaces the policy evaluation step in policy iteration with “partial policy evaluation”.</p>
<p>The latter computes an approximation to the value of a policy <span class="math notranslate nohighlight">\(\sigma\)</span> by iterating <span class="math notranslate nohighlight">\(T_{\sigma}\)</span> for a specified number of times.</p>
<p>This approach can be useful when the state space is very large and the linear system in the policy evaluation step of policy iteration is correspondingly difficult to solve.</p>
<p>The details of the algorithm can be found in <a class="reference internal" href="#ddp-algorithms"><span class="std std-ref">the appendix</span></a>.</p>
</section>
</section>
<section id="example-a-growth-model">
<span id="ddp-eg-gm"></span><h2><span class="section-number">4.4. </span>Example: A Growth Model<a class="headerlink" href="#example-a-growth-model" title="Permalink to this heading">#</a></h2>
<p>Let’s consider a simple consumption-saving model.</p>
<p>A single household either consumes or stores its own output of a single consumption good.</p>
<p>The household starts each period with current stock <span class="math notranslate nohighlight">\(s\)</span>.</p>
<p>Next, the household chooses a quantity <span class="math notranslate nohighlight">\(a\)</span> to store and consumes <span class="math notranslate nohighlight">\(c = s - a\)</span></p>
<ul class="simple">
<li><p>Storage is limited by a global upper bound <span class="math notranslate nohighlight">\(M\)</span>.</p></li>
<li><p>Flow utility is <span class="math notranslate nohighlight">\(u(c) = c^{\alpha}\)</span>.</p></li>
</ul>
<p>Output is drawn from a discrete uniform distribution on <span class="math notranslate nohighlight">\(\{0, \ldots, B\}\)</span>.</p>
<p>The next period stock is therefore</p>
<div class="math notranslate nohighlight">
\[
s' = a + U
\quad \text{where} \quad
U \sim U[0, \ldots, B]
\]</div>
<p>The discount factor is <span class="math notranslate nohighlight">\(\beta \in [0, 1)\)</span>.</p>
<section id="discrete-dp-representation">
<h3><span class="section-number">4.4.1. </span>Discrete DP Representation<a class="headerlink" href="#discrete-dp-representation" title="Permalink to this heading">#</a></h3>
<p>We want to represent this model in the format of a discrete dynamic program.</p>
<p>To this end, we take</p>
<ul class="simple">
<li><p>the state variable to be the stock <span class="math notranslate nohighlight">\(s\)</span></p></li>
<li><p>the state space to be <span class="math notranslate nohighlight">\(S = \{0, \ldots, M + B\}\)</span></p>
<ul>
<li><p>hence <span class="math notranslate nohighlight">\(n = M + B + 1\)</span></p></li>
</ul>
</li>
<li><p>the action to be the storage quantity <span class="math notranslate nohighlight">\(a\)</span></p></li>
<li><p>the set of feasible actions at <span class="math notranslate nohighlight">\(s\)</span> to be <span class="math notranslate nohighlight">\(A(s) = \{0, \ldots, \min\{s, M\}\}\)</span></p>
<ul>
<li><p>hence <span class="math notranslate nohighlight">\(A = \{0, \ldots, M\}\)</span> and <span class="math notranslate nohighlight">\(m = M + 1\)</span></p></li>
</ul>
</li>
<li><p>the reward function to be <span class="math notranslate nohighlight">\(r(s, a) = u(s - a)\)</span></p></li>
<li><p>the transition probabilities to be</p></li>
</ul>
<div class="math notranslate nohighlight" id="equation-ddp-def-ogq">
<span class="eqno">(4.3)<a class="headerlink" href="#equation-ddp-def-ogq" title="Permalink to this equation">#</a></span>\[\begin{split}Q(s, a, s') :=
\begin{cases}
    \frac{1}{B + 1} &amp; \text{if } a \leq s' \leq a + B
    \\
     0 &amp; \text{ otherwise}
\end{cases}\end{split}\]</div>
</section>
<section id="defining-a-discretedp-instance">
<h3><span class="section-number">4.4.2. </span>Defining a DiscreteDP Instance<a class="headerlink" href="#defining-a-discretedp-instance" title="Permalink to this heading">#</a></h3>
<p>This information will be used to create an instance of DiscreteDP by passing
the following information</p>
<ol class="arabic simple">
<li><p>An <span class="math notranslate nohighlight">\(n \times m\)</span> reward array <span class="math notranslate nohighlight">\(R\)</span>.</p></li>
<li><p>An <span class="math notranslate nohighlight">\(n \times m \times n\)</span> transition probability array <span class="math notranslate nohighlight">\(Q\)</span>.</p></li>
<li><p>A discount factor <span class="math notranslate nohighlight">\(\beta\)</span>.</p></li>
</ol>
<p>For <span class="math notranslate nohighlight">\(R\)</span> we set <span class="math notranslate nohighlight">\(R[s, a] = u(s - a)\)</span> if <span class="math notranslate nohighlight">\(a \leq s\)</span> and <span class="math notranslate nohighlight">\(-\infty\)</span> otherwise.</p>
<p>For <span class="math notranslate nohighlight">\(Q\)</span> we follow the rule in <a class="reference internal" href="#equation-ddp-def-ogq">(4.3)</a>.</p>
<div class="admonition note">
<p class="admonition-title">Note</p>
<ul class="simple">
<li><p>The feasibility constraint is embedded into <span class="math notranslate nohighlight">\(R\)</span> by setting <span class="math notranslate nohighlight">\(R[s, a] = -\infty\)</span> for <span class="math notranslate nohighlight">\(a \notin A(s)\)</span>.</p></li>
<li><p>Probability distributions for <span class="math notranslate nohighlight">\((s, a)\)</span> with <span class="math notranslate nohighlight">\(a \notin A(s)\)</span> can be arbitrary.</p></li>
</ul>
</div>
<p>The following code sets up these objects for us</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">class</span> <span class="nc">SimpleOG</span><span class="p">:</span>

    <span class="k">def</span> <span class="fm">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">B</span><span class="o">=</span><span class="mi">10</span><span class="p">,</span> <span class="n">M</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">α</span><span class="o">=</span><span class="mf">0.5</span><span class="p">,</span> <span class="n">β</span><span class="o">=</span><span class="mf">0.9</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Set up R, Q and β, the three elements that define an instance of</span>
<span class="sd">        the DiscreteDP class.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">B</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">M</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">α</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">β</span>  <span class="o">=</span> <span class="n">B</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">α</span><span class="p">,</span> <span class="n">β</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">n</span> <span class="o">=</span> <span class="n">B</span> <span class="o">+</span> <span class="n">M</span> <span class="o">+</span> <span class="mi">1</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">m</span> <span class="o">=</span> <span class="n">M</span> <span class="o">+</span> <span class="mi">1</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">R</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">))</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">Q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">((</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">,</span> <span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">))</span>

        <span class="bp">self</span><span class="o">.</span><span class="n">populate_Q</span><span class="p">()</span>
        <span class="bp">self</span><span class="o">.</span><span class="n">populate_R</span><span class="p">()</span>

    <span class="k">def</span> <span class="nf">u</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">c</span><span class="p">):</span>
        <span class="k">return</span> <span class="n">c</span><span class="o">**</span><span class="bp">self</span><span class="o">.</span><span class="n">α</span>

    <span class="k">def</span> <span class="nf">populate_R</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Populate the R matrix, with R[s, a] = -np.inf for infeasible</span>
<span class="sd">        state-action pairs.</span>
<span class="sd">        &quot;&quot;&quot;</span>
        <span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">n</span><span class="p">):</span>
            <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">):</span>
                <span class="bp">self</span><span class="o">.</span><span class="n">R</span><span class="p">[</span><span class="n">s</span><span class="p">,</span> <span class="n">a</span><span class="p">]</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">u</span><span class="p">(</span><span class="n">s</span> <span class="o">-</span> <span class="n">a</span><span class="p">)</span> <span class="k">if</span> <span class="n">a</span> <span class="o">&lt;=</span> <span class="n">s</span> <span class="k">else</span> <span class="o">-</span><span class="n">np</span><span class="o">.</span><span class="n">inf</span>

    <span class="k">def</span> <span class="nf">populate_Q</span><span class="p">(</span><span class="bp">self</span><span class="p">):</span>
<span class="w">        </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">        Populate the Q matrix by setting</span>

<span class="sd">            Q[s, a, s&#39;] = 1 / (1 + B) if a &lt;= s&#39; &lt;= a + B</span>

<span class="sd">        and zero otherwise.</span>
<span class="sd">        &quot;&quot;&quot;</span>

        <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">m</span><span class="p">):</span>
            <span class="bp">self</span><span class="o">.</span><span class="n">Q</span><span class="p">[:,</span> <span class="n">a</span><span class="p">,</span> <span class="n">a</span><span class="p">:(</span><span class="n">a</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s run this code and create an instance of <code class="docutils literal notranslate"><span class="pre">SimpleOG</span></code>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">g</span> <span class="o">=</span> <span class="n">SimpleOG</span><span class="p">()</span>  <span class="c1"># Use default parameters</span>
</pre></div>
</div>
</div>
</div>
<p>Instances of <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code> are created using the signature <code class="docutils literal notranslate"><span class="pre">DiscreteDP(R,</span> <span class="pre">Q,</span> <span class="pre">β)</span></code>.</p>
<p>Let’s create an instance using the objects stored in <code class="docutils literal notranslate"><span class="pre">g</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ddp</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">markov</span><span class="o">.</span><span class="n">DiscreteDP</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">R</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">Q</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">β</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Now that we have an instance <code class="docutils literal notranslate"><span class="pre">ddp</span></code> of <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code> we can solve it as follows</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span> <span class="o">=</span> <span class="n">ddp</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;policy_iteration&#39;</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Let’s see what we’ve got here</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="nb">dir</span><span class="p">(</span><span class="n">results</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[&#39;max_iter&#39;, &#39;mc&#39;, &#39;method&#39;, &#39;num_iter&#39;, &#39;sigma&#39;, &#39;v&#39;]
</pre></div>
</div>
</div>
</div>
<p>(In IPython version 4.0 and above you can also type <code class="docutils literal notranslate"><span class="pre">results.</span></code> and hit the tab key)</p>
<p>The most important attributes are <code class="docutils literal notranslate"><span class="pre">v</span></code>, the value function, and <code class="docutils literal notranslate"><span class="pre">σ</span></code>, the optimal policy</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">v</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([19.01740222, 20.01740222, 20.43161578, 20.74945302, 21.04078099,
       21.30873018, 21.54479816, 21.76928181, 21.98270358, 22.18824323,
       22.3845048 , 22.57807736, 22.76109127, 22.94376708, 23.11533996,
       23.27761762])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">sigma</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0, 0, 0, 0, 1, 1, 1, 2, 2, 3, 3, 4, 5, 5, 5, 5])
</pre></div>
</div>
</div>
</div>
<p>Since we’ve used policy iteration, these results will be exact unless we hit the iteration bound <code class="docutils literal notranslate"><span class="pre">max_iter</span></code>.</p>
<p>Let’s make sure this didn’t happen</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">max_iter</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>250
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">num_iter</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3
</pre></div>
</div>
</div>
</div>
<p>Another interesting object is <code class="docutils literal notranslate"><span class="pre">results.mc</span></code>, which is the controlled chain defined by <span class="math notranslate nohighlight">\(Q_{\sigma^*}\)</span>, where <span class="math notranslate nohighlight">\(\sigma^*\)</span> is the optimal policy.</p>
<p>In other words, it gives the dynamics of the state when the agent follows the optimal policy.</p>
<p>Since this object is an instance of MarkovChain from  <a class="reference external" href="http://quantecon.org/quantecon-py">QuantEcon.py</a> (see <a class="reference external" href="https://python-intro.quantecon.org/finite_markov.html">this lecture</a> for more discussion), we
can easily simulate it, compute its stationary distribution and so on.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">results</span><span class="o">.</span><span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.01732187, 0.04121063, 0.05773956, 0.07426848, 0.08095823,
        0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,
        0.09090909, 0.07358722, 0.04969846, 0.03316953, 0.01664061,
        0.00995086]])
</pre></div>
</div>
</div>
</div>
<p>Here’s the same information in a bar graph</p>
<figure class="align-default">
<a class="reference internal image-reference" href="_images/finite_dp_simple_og.png"><img alt="_images/finite_dp_simple_og.png" src="_images/finite_dp_simple_og.png" style="width: 637.6999999999999px; height: 338.09999999999997px;" /></a>
</figure>
<p>What happens if the agent is more patient?</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ddp</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">markov</span><span class="o">.</span><span class="n">DiscreteDP</span><span class="p">(</span><span class="n">g</span><span class="o">.</span><span class="n">R</span><span class="p">,</span> <span class="n">g</span><span class="o">.</span><span class="n">Q</span><span class="p">,</span> <span class="mf">0.99</span><span class="p">)</span>  <span class="c1"># Increase β to 0.99</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">ddp</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;policy_iteration&#39;</span><span class="p">)</span>
<span class="n">results</span><span class="o">.</span><span class="n">mc</span><span class="o">.</span><span class="n">stationary_distributions</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[0.00546913, 0.02321342, 0.03147788, 0.04800681, 0.05627127,
        0.09090909, 0.09090909, 0.09090909, 0.09090909, 0.09090909,
        0.09090909, 0.08543996, 0.06769567, 0.05943121, 0.04290228,
        0.03463782]])
</pre></div>
</div>
</div>
</div>
<p>If we look at the bar graph we can see the rightward shift in probability mass</p>
<figure class="align-default">
<a class="reference internal image-reference" href="_images/finite_dp_simple_og2.png"><img alt="_images/finite_dp_simple_og2.png" src="_images/finite_dp_simple_og2.png" style="width: 631.4px; height: 361.2px;" /></a>
</figure>
</section>
<section id="state-action-pair-formulation">
<h3><span class="section-number">4.4.3. </span>State-Action Pair Formulation<a class="headerlink" href="#state-action-pair-formulation" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code> class in fact, provides a second interface to set up an instance.</p>
<p>One of the advantages of this alternative set up is that it permits the use of a sparse matrix for <code class="docutils literal notranslate"><span class="pre">Q</span></code>.</p>
<p>(An example of using sparse matrices is given in the exercises below)</p>
<p>The call signature of the second formulation is <code class="docutils literal notranslate"><span class="pre">DiscreteDP(R,</span> <span class="pre">Q,</span> <span class="pre">β,</span> <span class="pre">s_indices,</span> <span class="pre">a_indices)</span></code> where</p>
<ul class="simple">
<li><p><code class="docutils literal notranslate"><span class="pre">s_indices</span></code> and <code class="docutils literal notranslate"><span class="pre">a_indices</span></code> are arrays of equal length <code class="docutils literal notranslate"><span class="pre">L</span></code> enumerating all feasible state-action pairs</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">R</span></code> is an array of length <code class="docutils literal notranslate"><span class="pre">L</span></code> giving corresponding rewards</p></li>
<li><p><code class="docutils literal notranslate"><span class="pre">Q</span></code> is an <code class="docutils literal notranslate"><span class="pre">L</span> <span class="pre">x</span> <span class="pre">n</span></code> transition probability array</p></li>
</ul>
<p>Here’s how we could set up these objects for the preceding example</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">B</span><span class="p">,</span> <span class="n">M</span><span class="p">,</span> <span class="n">α</span><span class="p">,</span> <span class="n">β</span> <span class="o">=</span> <span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">,</span> <span class="mf">0.5</span><span class="p">,</span> <span class="mf">0.9</span>
<span class="n">n</span> <span class="o">=</span> <span class="n">B</span> <span class="o">+</span> <span class="n">M</span> <span class="o">+</span> <span class="mi">1</span>
<span class="n">m</span> <span class="o">=</span> <span class="n">M</span> <span class="o">+</span> <span class="mi">1</span>

<span class="k">def</span> <span class="nf">u</span><span class="p">(</span><span class="n">c</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">c</span><span class="o">**</span><span class="n">α</span>

<span class="n">s_indices</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">a_indices</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">Q</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">R</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">b</span> <span class="o">=</span> <span class="mf">1.0</span> <span class="o">/</span> <span class="p">(</span><span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)</span>

<span class="k">for</span> <span class="n">s</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="k">for</span> <span class="n">a</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">min</span><span class="p">(</span><span class="n">M</span><span class="p">,</span> <span class="n">s</span><span class="p">)</span> <span class="o">+</span> <span class="mi">1</span><span class="p">):</span>  <span class="c1"># All feasible a at this s</span>
        <span class="n">s_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">s</span><span class="p">)</span>
        <span class="n">a_indices</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">a</span><span class="p">)</span>
        <span class="n">q</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
        <span class="n">q</span><span class="p">[</span><span class="n">a</span><span class="p">:(</span><span class="n">a</span> <span class="o">+</span> <span class="n">B</span> <span class="o">+</span> <span class="mi">1</span><span class="p">)]</span> <span class="o">=</span> <span class="n">b</span>        <span class="c1"># b on these values, otherwise 0</span>
        <span class="n">Q</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">q</span><span class="p">)</span>
        <span class="n">R</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">u</span><span class="p">(</span><span class="n">s</span> <span class="o">-</span> <span class="n">a</span><span class="p">))</span>

<span class="n">ddp</span> <span class="o">=</span> <span class="n">qe</span><span class="o">.</span><span class="n">markov</span><span class="o">.</span><span class="n">DiscreteDP</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">β</span><span class="p">,</span> <span class="n">s_indices</span><span class="p">,</span> <span class="n">a_indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>For larger problems, you might need to write this code more efficiently by vectorizing or using Numba.</p>
</section>
</section>
<section id="exercises">
<h2><span class="section-number">4.5. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this heading">#</a></h2>
<p>In the <a class="reference external" href="https://python-intro.quantecon.org/optgrowth.html">stochastic optimal growth lecture</a> from our introductory lecture series, we solve a benchmark model that has an analytical solution.</p>
<p>The exercise is to replicate this solution using <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code>.</p>
</section>
<section id="solutions">
<h2><span class="section-number">4.6. </span>Solutions<a class="headerlink" href="#solutions" title="Permalink to this heading">#</a></h2>
<section id="setup">
<h3><span class="section-number">4.6.1. </span>Setup<a class="headerlink" href="#setup" title="Permalink to this heading">#</a></h3>
<p>Details of the model can be found in <a class="reference external" href="https://python-intro.quantecon.org/optgrowth.html">the lecture on optimal growth</a>.</p>
<p>We let <span class="math notranslate nohighlight">\(f(k) = k^{\alpha}\)</span> with <span class="math notranslate nohighlight">\(\alpha = 0.65\)</span>, <span class="math notranslate nohighlight">\(u(c) =
\log c\)</span>, and <span class="math notranslate nohighlight">\(\beta = 0.95\)</span></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">α</span> <span class="o">=</span> <span class="mf">0.65</span>
<span class="n">f</span> <span class="o">=</span> <span class="k">lambda</span> <span class="n">k</span><span class="p">:</span> <span class="n">k</span><span class="o">**</span><span class="n">α</span>
<span class="n">u</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span>
<span class="n">β</span> <span class="o">=</span> <span class="mf">0.95</span>
</pre></div>
</div>
</div>
</div>
<p>Here we want to solve a finite state version of the continuous state model above.</p>
<p>We discretize the state space into a grid of size <code class="docutils literal notranslate"><span class="pre">grid_size=500</span></code>, from <span class="math notranslate nohighlight">\(10^{-6}\)</span> to <code class="docutils literal notranslate"><span class="pre">grid_max=2</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">grid_max</span> <span class="o">=</span> <span class="mi">2</span>
<span class="n">grid_size</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">grid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mf">1e-6</span><span class="p">,</span> <span class="n">grid_max</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We choose the action to be the amount of capital to save for the next
period (the state is the capital stock at the beginning of the period).</p>
<p>Thus the state indices and the action indices are both <code class="docutils literal notranslate"><span class="pre">0</span></code>, …, <code class="docutils literal notranslate"><span class="pre">grid_size-1</span></code>.</p>
<p>Action (indexed by) <code class="docutils literal notranslate"><span class="pre">a</span></code> is feasible at state (indexed by) <code class="docutils literal notranslate"><span class="pre">s</span></code> if and only if <code class="docutils literal notranslate"><span class="pre">grid[a]</span> <span class="pre">&lt;</span> <span class="pre">f([grid[s])</span></code> (zero consumption is not allowed because of the log utility).</p>
<p>Thus the Bellman equation is:</p>
<div class="math notranslate nohighlight">
\[
v(k) = \max_{0 &lt; k' &lt; f(k)} u(f(k) - k') + \beta v(k'),
\]</div>
<p>where <span class="math notranslate nohighlight">\(k'\)</span> is the capital stock in the next period.</p>
<p>The transition probability array <code class="docutils literal notranslate"><span class="pre">Q</span></code> will be highly sparse (in fact it
is degenerate as the model is deterministic), so we formulate the
problem with state-action pairs, to represent <code class="docutils literal notranslate"><span class="pre">Q</span></code> in <a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/sparse.html">scipy sparse matrix
format</a>.</p>
<p>We first construct indices for state-action pairs:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Consumption matrix, with nonpositive consumption included</span>
<span class="n">C</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="n">grid_size</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span> <span class="o">-</span> <span class="n">grid</span><span class="o">.</span><span class="n">reshape</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">)</span>

<span class="c1"># State-action indices</span>
<span class="n">s_indices</span><span class="p">,</span> <span class="n">a_indices</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">C</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span>

<span class="c1"># Number of state-action pairs</span>
<span class="n">L</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">s_indices</span><span class="p">)</span>

<span class="nb">print</span><span class="p">(</span><span class="n">L</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">s_indices</span><span class="p">)</span>
<span class="nb">print</span><span class="p">(</span><span class="n">a_indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>118841
[  0   1   1 ... 499 499 499]
[  0   0   1 ... 389 390 391]
</pre></div>
</div>
</div>
</div>
<p>Reward vector <code class="docutils literal notranslate"><span class="pre">R</span></code> (of length <code class="docutils literal notranslate"><span class="pre">L</span></code>):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">R</span> <span class="o">=</span> <span class="n">u</span><span class="p">(</span><span class="n">C</span><span class="p">[</span><span class="n">s_indices</span><span class="p">,</span> <span class="n">a_indices</span><span class="p">])</span>
</pre></div>
</div>
</div>
</div>
<p>(Degenerate) transition probability matrix <code class="docutils literal notranslate"><span class="pre">Q</span></code> (of shape <code class="docutils literal notranslate"><span class="pre">(L,</span> <span class="pre">grid_size)</span></code>), where we choose the <a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.lil_matrix.html">scipy.sparse.lil_matrix</a> format, while any format will do (internally it will be converted to the csr format):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Q</span> <span class="o">=</span> <span class="n">sparse</span><span class="o">.</span><span class="n">lil_matrix</span><span class="p">((</span><span class="n">L</span><span class="p">,</span> <span class="n">grid_size</span><span class="p">))</span>
<span class="n">Q</span><span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">arange</span><span class="p">(</span><span class="n">L</span><span class="p">),</span> <span class="n">a_indices</span><span class="p">]</span> <span class="o">=</span> <span class="mi">1</span>
</pre></div>
</div>
</div>
</div>
<p>(If you are familiar with the data structure of <a class="reference external" href="http://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html">scipy.sparse.csr_matrix</a>, the following is the most efficient way to create the <code class="docutils literal notranslate"><span class="pre">Q</span></code> matrix in
the current case)</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># data = np.ones(L)</span>
<span class="c1"># indptr = np.arange(L+1)</span>
<span class="c1"># Q = sparse.csr_matrix((data, a_indices, indptr), shape=(L, grid_size))</span>
</pre></div>
</div>
</div>
</div>
<p>Discrete growth model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ddp</span> <span class="o">=</span> <span class="n">DiscreteDP</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">β</span><span class="p">,</span> <span class="n">s_indices</span><span class="p">,</span> <span class="n">a_indices</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p><strong>Notes</strong></p>
<p>Here we intensively vectorized the operations on arrays to simplify the code.</p>
<p>As <a class="reference external" href="https://python-programming.quantecon.org/need_for_speed.html#numba-p-c-vectorization">noted</a>, however, vectorization is memory consumptive, and it can be prohibitively so for grids with large size.</p>
</section>
<section id="solving-the-model">
<h3><span class="section-number">4.6.2. </span>Solving the Model<a class="headerlink" href="#solving-the-model" title="Permalink to this heading">#</a></h3>
<p>Solve the dynamic optimization problem:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res</span> <span class="o">=</span> <span class="n">ddp</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;policy_iteration&#39;</span><span class="p">)</span>
<span class="n">v</span><span class="p">,</span> <span class="n">σ</span><span class="p">,</span> <span class="n">num_iter</span> <span class="o">=</span> <span class="n">res</span><span class="o">.</span><span class="n">v</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">sigma</span><span class="p">,</span> <span class="n">res</span><span class="o">.</span><span class="n">num_iter</span>
<span class="n">num_iter</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>10
</pre></div>
</div>
</div>
</div>
<p>Note that <code class="docutils literal notranslate"><span class="pre">sigma</span></code> contains the <em>indices</em> of the optimal <em>capital
stocks</em> to save for the next period. The following translates <code class="docutils literal notranslate"><span class="pre">sigma</span></code>
to the corresponding consumption vector.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Optimal consumption in the discrete version</span>
<span class="n">c</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span> <span class="o">-</span> <span class="n">grid</span><span class="p">[</span><span class="n">σ</span><span class="p">]</span>

<span class="c1"># Exact solution of the continuous version</span>
<span class="n">ab</span> <span class="o">=</span> <span class="n">α</span> <span class="o">*</span> <span class="n">β</span>
<span class="n">c1</span> <span class="o">=</span> <span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ab</span><span class="p">)</span> <span class="o">+</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">ab</span><span class="p">)</span> <span class="o">*</span> <span class="n">ab</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ab</span><span class="p">))</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">β</span><span class="p">)</span>
<span class="n">c2</span> <span class="o">=</span> <span class="n">α</span> <span class="o">/</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ab</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">v_star</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="n">c1</span> <span class="o">+</span> <span class="n">c2</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">k</span><span class="p">)</span>

<span class="k">def</span> <span class="nf">c_star</span><span class="p">(</span><span class="n">k</span><span class="p">):</span>
    <span class="k">return</span> <span class="p">(</span><span class="mi">1</span> <span class="o">-</span> <span class="n">ab</span><span class="p">)</span> <span class="o">*</span> <span class="n">k</span><span class="o">**</span><span class="n">α</span>
</pre></div>
</div>
</div>
</div>
<p>Let us compare the solution of the discrete model with that of the
original continuous model</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">14</span><span class="p">,</span> <span class="mi">4</span><span class="p">))</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">40</span><span class="p">,</span> <span class="o">-</span><span class="mi">32</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">grid</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">grid</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

<span class="n">lb0</span> <span class="o">=</span> <span class="s1">&#39;discrete value function&#39;</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">v</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lb0</span><span class="p">)</span>

<span class="n">lb0</span> <span class="o">=</span> <span class="s1">&#39;continuous value function&#39;</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">v_star</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lb0</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>

<span class="n">lb1</span> <span class="o">=</span> <span class="s1">&#39;discrete optimal consumption&#39;</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">c</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lb1</span><span class="p">)</span>

<span class="n">lb1</span> <span class="o">=</span> <span class="s1">&#39;continuous optimal consumption&#39;</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">c_star</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mf">1.5</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lb1</span><span class="p">)</span>
<span class="n">ax</span><span class="p">[</span><span class="mi">1</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/c0f488a294841541ec5d2ad33bd750bd0b5f2a9b1f2de5144804e02d1031d6b6.png" src="_images/c0f488a294841541ec5d2ad33bd750bd0b5f2a9b1f2de5144804e02d1031d6b6.png" />
</div>
</div>
<p>The outcomes appear very close to those of the continuous version.</p>
<p>Except for the “boundary” point, the value functions are very close:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_star</span><span class="p">(</span><span class="n">grid</span><span class="p">))</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>121.49819147053378
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">v</span> <span class="o">-</span> <span class="n">v_star</span><span class="p">(</span><span class="n">grid</span><span class="p">))[</span><span class="mi">1</span><span class="p">:]</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.012681735127500815
</pre></div>
</div>
</div>
</div>
<p>The optimal consumption functions are close as well:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">c</span> <span class="o">-</span> <span class="n">c_star</span><span class="p">(</span><span class="n">grid</span><span class="p">))</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.003826523100010082
</pre></div>
</div>
</div>
</div>
<p>In fact, the optimal consumption obtained in the discrete version is not
really monotone, but the decrements are quite small:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">diff</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">c</span><span class="p">)</span>
<span class="p">(</span><span class="n">diff</span> <span class="o">&gt;=</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>False
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">dec_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">where</span><span class="p">(</span><span class="n">diff</span> <span class="o">&lt;</span> <span class="mi">0</span><span class="p">)[</span><span class="mi">0</span><span class="p">]</span>
<span class="nb">len</span><span class="p">(</span><span class="n">dec_ind</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>174
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">diff</span><span class="p">[</span><span class="n">dec_ind</span><span class="p">])</span><span class="o">.</span><span class="n">max</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.001961853339766839
</pre></div>
</div>
</div>
</div>
<p>The value function is monotone:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">diff</span><span class="p">(</span><span class="n">v</span><span class="p">)</span> <span class="o">&gt;</span> <span class="mi">0</span><span class="p">)</span><span class="o">.</span><span class="n">all</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</section>
<section id="comparison-of-the-solution-methods">
<h3><span class="section-number">4.6.3. </span>Comparison of the Solution Methods<a class="headerlink" href="#comparison-of-the-solution-methods" title="Permalink to this heading">#</a></h3>
<p>Let us solve the problem with the other two methods.</p>
<section id="value-iteration">
<h4><span class="section-number">4.6.3.1. </span>Value Iteration<a class="headerlink" href="#value-iteration" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ddp</span><span class="o">.</span><span class="n">epsilon</span> <span class="o">=</span> <span class="mf">1e-4</span>
<span class="n">ddp</span><span class="o">.</span><span class="n">max_iter</span> <span class="o">=</span> <span class="mi">500</span>
<span class="n">res1</span> <span class="o">=</span> <span class="n">ddp</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;value_iteration&#39;</span><span class="p">)</span>
<span class="n">res1</span><span class="o">.</span><span class="n">num_iter</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>294
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">σ</span><span class="p">,</span> <span class="n">res1</span><span class="o">.</span><span class="n">sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</section>
<section id="modified-policy-iteration">
<h4><span class="section-number">4.6.3.2. </span>Modified Policy Iteration<a class="headerlink" href="#modified-policy-iteration" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res2</span> <span class="o">=</span> <span class="n">ddp</span><span class="o">.</span><span class="n">solve</span><span class="p">(</span><span class="n">method</span><span class="o">=</span><span class="s1">&#39;modified_policy_iteration&#39;</span><span class="p">)</span>
<span class="n">res2</span><span class="o">.</span><span class="n">num_iter</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>16
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">array_equal</span><span class="p">(</span><span class="n">σ</span><span class="p">,</span> <span class="n">res2</span><span class="o">.</span><span class="n">sigma</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>True
</pre></div>
</div>
</div>
</div>
</section>
<section id="speed-comparison">
<h4><span class="section-number">4.6.3.3. </span>Speed Comparison<a class="headerlink" href="#speed-comparison" title="Permalink to this heading">#</a></h4>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="o">%</span><span class="k">timeit</span> ddp.solve(method=&#39;value_iteration&#39;)
<span class="o">%</span><span class="k">timeit</span> ddp.solve(method=&#39;policy_iteration&#39;)
<span class="o">%</span><span class="k">timeit</span> ddp.solve(method=&#39;modified_policy_iteration&#39;)
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>94.9 ms ± 360 μs per loop (mean ± std. dev. of 7 runs, 10 loops each)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>9.34 ms ± 16.9 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</pre></div>
</div>
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>11.3 ms ± 59.9 μs per loop (mean ± std. dev. of 7 runs, 100 loops each)
</pre></div>
</div>
</div>
</div>
<p>As is often the case, policy iteration and modified policy iteration are
much faster than value iteration.</p>
</section>
</section>
<section id="replication-of-the-figures">
<h3><span class="section-number">4.6.4. </span>Replication of the Figures<a class="headerlink" href="#replication-of-the-figures" title="Permalink to this heading">#</a></h3>
<p>Using <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code> we replicate the figures shown in the lecture.</p>
<section id="convergence-of-value-iteration">
<h4><span class="section-number">4.6.4.1. </span>Convergence of Value Iteration<a class="headerlink" href="#convergence-of-value-iteration" title="Permalink to this heading">#</a></h4>
<p>Let us first visualize the convergence of the value iteration algorithm
as in the lecture, where we use <code class="docutils literal notranslate"><span class="pre">ddp.bellman_operator</span></code> implemented as
a method of <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code></p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span> <span class="o">-</span> <span class="mi">25</span>  <span class="c1"># Initial condition</span>
<span class="n">n</span> <span class="o">=</span> <span class="mi">35</span>
<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="o">-</span><span class="mi">40</span><span class="p">,</span> <span class="o">-</span><span class="mi">20</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">min</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span> <span class="n">np</span><span class="o">.</span><span class="n">max</span><span class="p">(</span><span class="n">grid</span><span class="p">))</span>
<span class="n">lb</span> <span class="o">=</span> <span class="s1">&#39;initial condition&#39;</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">jet</span><span class="p">(</span><span class="mi">0</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lb</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="n">n</span><span class="p">):</span>
    <span class="n">w</span> <span class="o">=</span> <span class="n">ddp</span><span class="o">.</span><span class="n">bellman_operator</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="n">plt</span><span class="o">.</span><span class="n">cm</span><span class="o">.</span><span class="n">jet</span><span class="p">(</span><span class="n">i</span> <span class="o">/</span> <span class="n">n</span><span class="p">),</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.6</span><span class="p">)</span>
<span class="n">lb</span> <span class="o">=</span> <span class="s1">&#39;true value function&#39;</span>
<span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">v_star</span><span class="p">(</span><span class="n">grid</span><span class="p">),</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="n">lb</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/0e19b0181ee5218e7ea71fe11eb65a1fe00894eb2a96c208e1340a0b84d945c6.png" src="_images/0e19b0181ee5218e7ea71fe11eb65a1fe00894eb2a96c208e1340a0b84d945c6.png" />
</div>
</div>
<p>We next plot the consumption policies along with the value iteration</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">w</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">u</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span> <span class="o">-</span> <span class="mi">25</span>           <span class="c1"># Initial condition</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="mi">3</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span> <span class="mi">10</span><span class="p">))</span>
<span class="n">true_c</span> <span class="o">=</span> <span class="n">c_star</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span>

<span class="k">for</span> <span class="n">i</span><span class="p">,</span> <span class="n">n</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">((</span><span class="mi">2</span><span class="p">,</span> <span class="mi">4</span><span class="p">,</span> <span class="mi">6</span><span class="p">)):</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xlim</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_yticks</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">))</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_xticks</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="mi">2</span><span class="p">))</span>

    <span class="n">w</span> <span class="o">=</span> <span class="mi">5</span> <span class="o">*</span> <span class="n">u</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span> <span class="o">-</span> <span class="mi">25</span>       <span class="c1"># Initial condition</span>
    <span class="n">compute_fixed_point</span><span class="p">(</span><span class="n">ddp</span><span class="o">.</span><span class="n">bellman_operator</span><span class="p">,</span> <span class="n">w</span><span class="p">,</span> <span class="n">max_iter</span><span class="o">=</span><span class="n">n</span><span class="p">,</span> <span class="n">print_skip</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>
    <span class="n">σ</span> <span class="o">=</span> <span class="n">ddp</span><span class="o">.</span><span class="n">compute_greedy</span><span class="p">(</span><span class="n">w</span><span class="p">)</span>  <span class="c1"># Policy indices</span>
    <span class="n">c_policy</span> <span class="o">=</span> <span class="n">f</span><span class="p">(</span><span class="n">grid</span><span class="p">)</span> <span class="o">-</span> <span class="n">grid</span><span class="p">[</span><span class="n">σ</span><span class="p">]</span>

    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">c_policy</span><span class="p">,</span> <span class="s1">&#39;b-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="s1">&#39;approximate optimal consumption policy&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">true_c</span><span class="p">,</span> <span class="s1">&#39;k-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.8</span><span class="p">,</span>
               <span class="n">label</span><span class="o">=</span><span class="s1">&#39;true optimal consumption policy&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;upper left&#39;</span><span class="p">)</span>
    <span class="n">ax</span><span class="p">[</span><span class="n">i</span><span class="p">]</span><span class="o">.</span><span class="n">set_title</span><span class="p">(</span><span class="sa">f</span><span class="s1">&#39;</span><span class="si">{</span><span class="n">n</span><span class="si">}</span><span class="s1"> value function iterations&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output stream highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Iteration    Distance       Elapsed (seconds)
---------------------------------------------
1            5.518e+00      6.032e-04         
2            4.070e+00      9.885e-04         
Iteration    Distance       Elapsed (seconds)
---------------------------------------------
1            5.518e+00      3.893e-04         
2            4.070e+00      7.424e-04         
3            3.866e+00      1.085e-03         
4            3.673e+00      1.462e-03         
Iteration    Distance       Elapsed (seconds)
---------------------------------------------
1            5.518e+00      3.693e-04         
2            4.070e+00      7.381e-04         
3            3.866e+00      1.083e-03         
4            3.673e+00      1.423e-03         
5            3.489e+00      1.779e-03         
6            3.315e+00      2.120e-03         
</pre></div>
</div>
<div class="output stderr highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>/home/runner/miniconda3/envs/quantecon/lib/python3.12/site-packages/quantecon/_compute_fp.py:152: RuntimeWarning: max_iter attained before convergence in compute_fixed_point
  warnings.warn(_non_convergence_msg, RuntimeWarning)
</pre></div>
</div>
<img alt="_images/303ee2e9d6113375192906121cd16857c759b41e330a014e634c9e1a5bab269a.png" src="_images/303ee2e9d6113375192906121cd16857c759b41e330a014e634c9e1a5bab269a.png" />
</div>
</div>
</section>
<section id="dynamics-of-the-capital-stock">
<h4><span class="section-number">4.6.4.2. </span>Dynamics of the Capital Stock<a class="headerlink" href="#dynamics-of-the-capital-stock" title="Permalink to this heading">#</a></h4>
<p>Finally, let us work on <a class="reference external" href="https://python.quantecon.org/optgrowth.html#exercises">Exercise
2</a>, where we plot
the trajectories of the capital stock for three different discount
factors, <span class="math notranslate nohighlight">\(0.9\)</span>, <span class="math notranslate nohighlight">\(0.94\)</span>, and <span class="math notranslate nohighlight">\(0.98\)</span>, with initial
condition <span class="math notranslate nohighlight">\(k_0 = 0.1\)</span>.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">discount_factors</span> <span class="o">=</span> <span class="p">(</span><span class="mf">0.9</span><span class="p">,</span> <span class="mf">0.94</span><span class="p">,</span> <span class="mf">0.98</span><span class="p">)</span>
<span class="n">k_init</span> <span class="o">=</span> <span class="mf">0.1</span>

<span class="c1"># Search for the index corresponding to k_init</span>
<span class="n">k_init_ind</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">searchsorted</span><span class="p">(</span><span class="n">grid</span><span class="p">,</span> <span class="n">k_init</span><span class="p">)</span>

<span class="n">sample_size</span> <span class="o">=</span> <span class="mi">25</span>

<span class="n">fig</span><span class="p">,</span> <span class="n">ax</span> <span class="o">=</span> <span class="n">plt</span><span class="o">.</span><span class="n">subplots</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">8</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_xlabel</span><span class="p">(</span><span class="s2">&quot;time&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylabel</span><span class="p">(</span><span class="s2">&quot;capital&quot;</span><span class="p">)</span>
<span class="n">ax</span><span class="o">.</span><span class="n">set_ylim</span><span class="p">(</span><span class="mf">0.10</span><span class="p">,</span> <span class="mf">0.30</span><span class="p">)</span>

<span class="c1"># Create a new instance, not to modify the one used above</span>
<span class="n">ddp0</span> <span class="o">=</span> <span class="n">DiscreteDP</span><span class="p">(</span><span class="n">R</span><span class="p">,</span> <span class="n">Q</span><span class="p">,</span> <span class="n">β</span><span class="p">,</span> <span class="n">s_indices</span><span class="p">,</span> <span class="n">a_indices</span><span class="p">)</span>

<span class="k">for</span> <span class="n">beta</span> <span class="ow">in</span> <span class="n">discount_factors</span><span class="p">:</span>
    <span class="n">ddp0</span><span class="o">.</span><span class="n">beta</span> <span class="o">=</span> <span class="n">beta</span>
    <span class="n">res0</span> <span class="o">=</span> <span class="n">ddp0</span><span class="o">.</span><span class="n">solve</span><span class="p">()</span>
    <span class="n">k_path_ind</span> <span class="o">=</span> <span class="n">res0</span><span class="o">.</span><span class="n">mc</span><span class="o">.</span><span class="n">simulate</span><span class="p">(</span><span class="n">init</span><span class="o">=</span><span class="n">k_init_ind</span><span class="p">,</span> <span class="n">ts_length</span><span class="o">=</span><span class="n">sample_size</span><span class="p">)</span>
    <span class="n">k_path</span> <span class="o">=</span> <span class="n">grid</span><span class="p">[</span><span class="n">k_path_ind</span><span class="p">]</span>
    <span class="n">ax</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">k_path</span><span class="p">,</span> <span class="s1">&#39;o-&#39;</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">2</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.75</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="sa">fr</span><span class="s1">&#39;$\beta = </span><span class="si">{</span><span class="n">beta</span><span class="si">}</span><span class="s1">$&#39;</span><span class="p">)</span>

<span class="n">ax</span><span class="o">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s1">&#39;lower right&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<img alt="_images/31d83baf6d3585f28f7e08d4f78c1b7360f65f10efa00ee108585b7d1daa67cd.png" src="_images/31d83baf6d3585f28f7e08d4f78c1b7360f65f10efa00ee108585b7d1daa67cd.png" />
</div>
</div>
</section>
</section>
</section>
<section id="appendix-algorithms">
<span id="ddp-algorithms"></span><h2><span class="section-number">4.7. </span>Appendix: Algorithms<a class="headerlink" href="#appendix-algorithms" title="Permalink to this heading">#</a></h2>
<p>This appendix covers the details of the solution algorithms implemented for <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code>.</p>
<p>We will make use of the following notions of approximate optimality:</p>
<ul class="simple">
<li><p>For <span class="math notranslate nohighlight">\(\varepsilon &gt; 0\)</span>, <span class="math notranslate nohighlight">\(v\)</span> is called an  <span class="math notranslate nohighlight">\(\varepsilon\)</span>-approximation of <span class="math notranslate nohighlight">\(v^*\)</span> if <span class="math notranslate nohighlight">\(\lVert v - v^*\rVert &lt; \varepsilon\)</span>.</p></li>
<li><p>A policy <span class="math notranslate nohighlight">\(\sigma \in \Sigma\)</span> is called <span class="math notranslate nohighlight">\(\varepsilon\)</span>-optimal if <span class="math notranslate nohighlight">\(v_{\sigma}\)</span> is an <span class="math notranslate nohighlight">\(\varepsilon\)</span>-approximation of <span class="math notranslate nohighlight">\(v^*\)</span>.</p></li>
</ul>
<section id="id9">
<h3><span class="section-number">4.7.1. </span>Value Iteration<a class="headerlink" href="#id9" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code> value iteration method implements value function iteration as
follows</p>
<ol class="arabic simple">
<li><p>Choose any <span class="math notranslate nohighlight">\(v^0 \in \mathbb{R}^n\)</span>, and specify <span class="math notranslate nohighlight">\(\varepsilon &gt; 0\)</span>; set <span class="math notranslate nohighlight">\(i = 0\)</span>.</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(v^{i+1} = T v^i\)</span>.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(\lVert v^{i+1} - v^i\rVert &lt;  [(1 - \beta) / (2\beta)] \varepsilon\)</span>,
then go to step 4; otherwise, set <span class="math notranslate nohighlight">\(i = i + 1\)</span> and go to step 2.</p></li>
<li><p>Compute a <span class="math notranslate nohighlight">\(v^{i+1}\)</span>-greedy policy <span class="math notranslate nohighlight">\(\sigma\)</span>, and return <span class="math notranslate nohighlight">\(v^{i+1}\)</span> and <span class="math notranslate nohighlight">\(\sigma\)</span>.</p></li>
</ol>
<p>Given <span class="math notranslate nohighlight">\(\varepsilon &gt; 0\)</span>, the value iteration algorithm</p>
<ul class="simple">
<li><p>terminates in a finite number of iterations</p></li>
<li><p>returns an <span class="math notranslate nohighlight">\(\varepsilon/2\)</span>-approximation of the optimal value function and an <span class="math notranslate nohighlight">\(\varepsilon\)</span>-optimal policy function (unless <code class="docutils literal notranslate"><span class="pre">iter_max</span></code> is reached)</p></li>
</ul>
<p>(While not explicit, in the actual implementation each algorithm is
terminated if the number of iterations reaches <code class="docutils literal notranslate"><span class="pre">iter_max</span></code>)</p>
</section>
<section id="policy-iteration">
<h3><span class="section-number">4.7.2. </span>Policy Iteration<a class="headerlink" href="#policy-iteration" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code> policy iteration method runs as follows</p>
<ol class="arabic simple">
<li><p>Choose any <span class="math notranslate nohighlight">\(v^0 \in \mathbb{R}^n\)</span> and compute a <span class="math notranslate nohighlight">\(v^0\)</span>-greedy policy <span class="math notranslate nohighlight">\(\sigma^0\)</span>; set <span class="math notranslate nohighlight">\(i = 0\)</span>.</p></li>
<li><p>Compute the value <span class="math notranslate nohighlight">\(v_{\sigma^i}\)</span> by solving
the equation <span class="math notranslate nohighlight">\(v = T_{\sigma^i} v\)</span>.</p></li>
<li><p>Compute a <span class="math notranslate nohighlight">\(v_{\sigma^i}\)</span>-greedy policy
<span class="math notranslate nohighlight">\(\sigma^{i+1}\)</span>; let <span class="math notranslate nohighlight">\(\sigma^{i+1} = \sigma^i\)</span> if
possible.</p></li>
<li><p>If <span class="math notranslate nohighlight">\(\sigma^{i+1} = \sigma^i\)</span>, then return <span class="math notranslate nohighlight">\(v_{\sigma^i}\)</span>
and <span class="math notranslate nohighlight">\(\sigma^{i+1}\)</span>; otherwise, set <span class="math notranslate nohighlight">\(i = i + 1\)</span> and go to
step 2.</p></li>
</ol>
<p>The policy iteration algorithm terminates in a finite number of
iterations.</p>
<p>It returns an optimal value function and an optimal policy function (unless <code class="docutils literal notranslate"><span class="pre">iter_max</span></code> is reached).</p>
</section>
<section id="id10">
<h3><span class="section-number">4.7.3. </span>Modified Policy Iteration<a class="headerlink" href="#id10" title="Permalink to this heading">#</a></h3>
<p>The <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code> modified policy iteration method runs as follows:</p>
<ol class="arabic simple">
<li><p>Choose any <span class="math notranslate nohighlight">\(v^0 \in \mathbb{R}^n\)</span>, and specify <span class="math notranslate nohighlight">\(\varepsilon &gt; 0\)</span> and <span class="math notranslate nohighlight">\(k \geq 0\)</span>; set <span class="math notranslate nohighlight">\(i = 0\)</span>.</p></li>
<li><p>Compute a <span class="math notranslate nohighlight">\(v^i\)</span>-greedy policy <span class="math notranslate nohighlight">\(\sigma^{i+1}\)</span>; let <span class="math notranslate nohighlight">\(\sigma^{i+1} = \sigma^i\)</span> if possible (for <span class="math notranslate nohighlight">\(i \geq 1\)</span>).</p></li>
<li><p>Compute <span class="math notranslate nohighlight">\(u = T v^i\)</span> (<span class="math notranslate nohighlight">\(= T_{\sigma^{i+1}} v^i\)</span>). If <span class="math notranslate nohighlight">\(\mathrm{span}(u - v^i) &lt; [(1 - \beta) / \beta] \varepsilon\)</span>, then go to step 5; otherwise go to step 4.</p>
<ul class="simple">
<li><p>Span is defined by <span class="math notranslate nohighlight">\(\mathrm{span}(z) = \max(z) - \min(z)\)</span>.</p></li>
</ul>
</li>
<li><p>Compute <span class="math notranslate nohighlight">\(v^{i+1} = (T_{\sigma^{i+1}})^k u\)</span> (<span class="math notranslate nohighlight">\(= (T_{\sigma^{i+1}})^{k+1} v^i\)</span>); set <span class="math notranslate nohighlight">\(i = i + 1\)</span> and go to step 2.</p></li>
<li><p>Return <span class="math notranslate nohighlight">\(v = u + [\beta / (1 - \beta)] [(\min(u - v^i) + \max(u - v^i)) / 2] \mathbf{1}\)</span> and <span class="math notranslate nohighlight">\(\sigma_{i+1}\)</span>.</p></li>
</ol>
<p>Given <span class="math notranslate nohighlight">\(\varepsilon &gt; 0\)</span>, provided that <span class="math notranslate nohighlight">\(v^0\)</span> is such that
<span class="math notranslate nohighlight">\(T v^0 \geq v^0\)</span>, the modified policy iteration algorithm
terminates in a finite number of iterations.</p>
<p>It returns an <span class="math notranslate nohighlight">\(\varepsilon/2\)</span>-approximation of the optimal value function and an <span class="math notranslate nohighlight">\(\varepsilon\)</span>-optimal policy function (unless <code class="docutils literal notranslate"><span class="pre">iter_max</span></code> is reached).</p>
<p>See also the documentation for <code class="docutils literal notranslate"><span class="pre">DiscreteDP</span></code>.</p>
</section>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="qe-page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="qe-sidebar bd-sidebar inactive" id="site-navigation">

                <div class="qe-sidebar__header">


                    Contents

                </div>

                <nav class="qe-sidebar__nav" id="qe-sidebar-nav" aria-label="Main navigation">
                    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tools and Techniques
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="orth_proj.html">
   1. Orthogonal Projections and Their Applications
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="stationary_densities.html">
   2. Continuous State Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="muth_kalman.html">
   3. Reverse Engineering a la Muth
  </a>
 </li>
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   4. Discrete State Dynamic Programming
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  LQ Control
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="cons_news.html">
   5. Information and Consumption Smoothing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="smoothing.html">
   6. Consumption Smoothing with Complete and Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="smoothing_tax.html">
   7. Tax Smoothing with Complete and Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markov_jump_lq.html">
   8. Markov Jump Linear Quadratic Dynamic Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tax_smoothing_1.html">
   9. How to Pay for a War: Part 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tax_smoothing_2.html">
   10. How to Pay for a War: Part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tax_smoothing_3.html">
   11. How to Pay for a War: Part 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lqramsey.html">
   12. Optimal Taxation in an LQ Economy
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Multiple Agent Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="arellano.html">
   13. Default Risk and Income Fluctuations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="matsuyama.html">
   14. Globalization and Cycles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="coase.html">
   15. Coase’s Theory of the Firm
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="match_transport.html">
   16. Composite Sorting
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dynamic Linear Economies
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="hs_recursive_models.html">
   17. Recursive Models of Dynamic Linear Economies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="growth_in_dles.html">
   18. Growth in Dynamic Linear Economies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lucas_asset_pricing_dles.html">
   19. Lucas Asset Pricing Using DLE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="irfs_in_hall_model.html">
   20. IRFs in Hall Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="permanent_income_dles.html">
   21. Permanent Income Model using the DLE Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rosen_schooling_model.html">
   22. Rosen Schooling Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cattle_cycles.html">
   23. Cattle Cycles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hs_invertibility_example.html">
   24. Shock Non Invertibility
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Risk, Model Uncertainty, and Robustness
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="five_preferences.html">
   25. Risk and Model Uncertainty
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="entropy.html">
   26. Etymology of Entropy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="robustness.html">
   27. Robustness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rob_markov_perf.html">
   28. Robust Markov Perfect Equilibrium
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Time Series Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="arma.html">
   29. Covariance Stationary Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="estspec.html">
   30. Estimation of Spectra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="additive_functionals.html">
   31. Additive and Multiplicative Functionals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lu_tricks.html">
   32. Classical Control with Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classical_filtering.html">
   33. Classical Prediction and Filtering With Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="knowing_forecasts_of_others.html">
   34. Knowing the Forecasts of Others
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Asset Pricing and Finance
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="lucas_model.html">
   35. Asset Pricing II: The Lucas Asset Pricing Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="asset_pricing_lph.html">
   36. Elementary Asset Pricing Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="black_litterman.html">
   37. Two Modifications of Mean-Variance Portfolio Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="BCG_complete_mkts.html">
   38. Irrelevance of Capital Structures with Complete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="BCG_incomplete_mkts.html">
   39. Equilibrium Capital Structures with Incomplete Markets
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dynamic Programming Squared
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="un_insure.html">
   40. Optimal Unemployment Insurance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dyn_stack.html">
   41. Stackelberg Plans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calvo_machine_learn.html">
   42. Machine Learning a Ramsey Plan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calvo.html">
   43. Time Inconsistency of Ramsey Plans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calvo_abreu.html">
   44. Sustainable Plans for a Calvo Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="opt_tax_recur.html">
   45. Optimal Taxation with State-Contingent Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="amss.html">
   46. Optimal Taxation without State-Contingent Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="amss2.html">
   47. Fluctuating Interest Rates Deliver Fiscal Insurance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="amss3.html">
   48. Fiscal Risk and Government Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chang_ramsey.html">
   49. Competitive Equilibria of a Model of Chang
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chang_credible.html">
   50. Credible Government Policies in a Model of Chang
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="troubleshooting.html">
   51. Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   52. References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="status.html">
   53. Execution Statistics
  </a>
 </li>
</ul>

                </nav>

                <div class="qe-sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="qe-toolbar">

            <div class="qe-toolbar__inner">

                <ul class="qe-toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="intro.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                </ul>

                <ul class="qe-toolbar__links">
                    <li class="btn__search">
                        <form action="search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off" accesskey="k">
                            <i data-feather="search" id="search-icon"></i>
                        </form>
                    </li>
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="/_notebooks/discrete_dp.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li class="download-pdf" id="downloadButton"><i data-feather="file"></i></li>
                    <!--
                    # Enable if looking for link to specific document hosted on GitHub
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-python-advanced.myst/blob/main/lectures/discrete_dp.md" download><i data-feather="github"></i></a></li>
                    -->
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-python-advanced.myst" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="/_pdf/quantecon-python-advanced.pdf" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://colab.research.google.com/github/QuantEcon/lecture-python-advanced.notebooks/blob/main/discrete_dp.ipynb">Colab</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/QuantEcon/lecture-python-advanced.notebooks" data-urlpath="tree/lecture-python-advanced.notebooks/discrete_dp.ipynb" data-branch=main>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://colab.research.google.com/github/QuantEcon/lecture-python-advanced.notebooks/blob/main/discrete_dp.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "discrete_dp";
                const repoURL = "https://github.com/QuantEcon/lecture-python-advanced.notebooks";
                const urlPath = "tree/lecture-python-advanced.notebooks/discrete_dp.ipynb";
                const branch = "main"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
  </body>
</html>