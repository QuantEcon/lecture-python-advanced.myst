

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>1. Orthogonal Projections and Their Applications &#8212; Advanced Quantitative Economics with Python</title>
    <script src="https://unpkg.com/@popperjs/core@2.9.2/dist/umd/popper.min.js"></script>
    <script src="https://unpkg.com/tippy.js@6.3.1/dist/tippy-bundle.umd.js"></script>
    <script src="https://cdn.jsdelivr.net/npm/feather-icons/dist/feather.min.js"></script>
    
        <script>
            MathJax = {
            loader: {load: ['[tex]/boldsymbol', '[tex]/textmacros']},
            tex: {
                packages: {'[+]': ['boldsymbol', 'textmacros']},
                inlineMath: [['$', '$'], ['\\(', '\\)']],
                processEscapes: true,
                macros: {
                    "argmax" : "arg\\,max",
                    "argmin" : "arg\\,min",
                    "col"    : "col",
                    "Span"   :  "span",
                    "epsilon": "\\varepsilon",
                    "EE": "\\mathbb{E}",
                    "PP": "\\mathbb{P}",
                    "RR": "\\mathbb{R}",
                    "NN": "\\mathbb{N}",
                    "ZZ": "\\mathbb{Z}",
                    "aA": "\\mathcal{A}",
                    "bB": "\\mathcal{B}",
                    "cC": "\\mathcal{C}",
                    "dD": "\\mathcal{D}",
                    "eE": "\\mathcal{E}",
                    "fF": "\\mathcal{F}",
                    "gG": "\\mathcal{G}",
                    "hH": "\\mathcal{H}",
                }
            },
            svg: {
                fontCache: 'global',
                scale: 0.92,
                displayAlign: "center",
            },
            };
        </script>
    
    
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.2/css/all.min.css?digest=dfe6caa3a7d634c4db9b" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.2/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" href="_static/styles/quantecon-book-theme.css?digest=f77998adf44a3f900caaca31caf410c810f6f245" type="text/css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/exercise.css" />
    <link rel="stylesheet" type="text/css" href="_static/proof.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.4045f2051d55cab465a707391d5b2007.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=dfe6caa3a7d634c4db9b" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=dfe6caa3a7d634c4db9b" />
  <script src="_static/vendor/fontawesome/6.5.2/js/all.min.js?digest=dfe6caa3a7d634c4db9b"></script>


    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js?digest=5a5c038af52cf7bc1a1ec88eea08e6366ee68824"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script src="_static/scripts/quantecon-book-theme.js?digest=eed9c059a3ee152aae2353ec732f0a6d12e6aa07"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script async="async" src="https://www.googletagmanager.com/gtag/js?id=G-KZLV7PM9LL"></script>
    <script>
                window.dataLayer = window.dataLayer || [];
                function gtag(){ dataLayer.push(arguments); }
                gtag('js', new Date());
                gtag('config', 'G-KZLV7PM9LL');
            </script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"
const thebe_selector = ".thebe,.cell"
const thebe_selector_input = "pre"
const thebe_selector_output = ".output, .cell_output"
</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"tex": {"macros": {"argmax": "arg\\,max", "argmin": "arg\\,min", "col": "col", "Span": "span", "epsilon": "\\varepsilon", "EE": "\\mathbb{E}", "PP": "\\mathbb{P}", "RR": "\\mathbb{R}", "NN": "\\mathbb{N}", "ZZ": "\\mathbb{Z}", "aA": "\\mathcal{A}", "bB": "\\mathcal{B}", "cC": "\\mathcal{C}", "dD": "\\mathcal{D}", "eE": "\\mathcal{E}", "fF": "\\mathcal{F}", "gG": "\\mathcal{G}", "hH": "\\mathcal{H}"}}, "options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'orth_proj';</script>
    <link rel="canonical" href="https://python-advanced.quantecon.org/orth_proj.html" />
    <link rel="shortcut icon" href="_static/lectures-favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="2. Continuous State Markov Chains" href="stationary_densities.html" />
    <link rel="prev" title="Advanced Quantitative Economics with Python" href="intro.html" />

<!-- Normal Meta Tags -->
<meta name="author" context="Thomas J. Sargent &amp; John Stachurski" />
<meta name="keywords" content="Python, QuantEcon, Quantitative Economics, Economics, Sloan, Alfred P. Sloan Foundation, Tom J. Sargent, John Stachurski" />
<meta name="description" content=This website presents a set of lectures on advanced quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski. />

<!-- Twitter tags -->
<meta name="twitter:card" content="summary" />
<meta name="twitter:site" content="@quantecon" />
<meta name="twitter:title" content="Orthogonal Projections and Their Applications"/>
<meta name="twitter:description" content="This website presents a set of lectures on advanced quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski.">
<meta name="twitter:creator" content="@quantecon">
<meta name="twitter:image" content="https://assets.quantecon.org/img/qe-twitter-logo.png">

<!-- Opengraph tags -->
<meta property="og:title" content="Orthogonal Projections and Their Applications" />
<meta property="og:type" content="website" />
<meta property="og:url" content="https://python-advanced.quantecon.org/orth_proj.html" />
<meta property="og:image" content="https://assets.quantecon.org/img/qe-og-logo.png" />
<meta property="og:description" content="This website presents a set of lectures on advanced quantitative economic modeling, designed and written by Thomas J. Sargent and John Stachurski." />
<meta property="og:site_name" content="Advanced Quantitative Economics with Python" />
<meta name="theme-color" content="#ffffff" />

  </head>
<body>


    <span id="top"></span>

    <div class="qe-wrapper">

        <div class="qe-main">

            <div class="qe-page" id=orth_proj>

                <div class="qe-page__toc">

                    <div class="inner">

                        
                        <div class="qe-page__toc-header">
                            On this page
                        </div>


                        <nav id="bd-toc-nav" class="qe-page__toc-nav">
                            <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#overview">1.1. Overview</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#further-reading">1.1.1. Further Reading</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#key-definitions">1.2. Key Definitions</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-independence-vs-orthogonality">1.2.1. Linear Independence vs Orthogonality</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-orthogonal-projection-theorem">1.3. The Orthogonal Projection Theorem</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#proof-of-sufficiency">1.3.1. Proof of Sufficiency</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#orthogonal-projection-as-a-mapping">1.3.2. Orthogonal Projection as a Mapping</a><ul class="nav section-nav flex-column">
<li class="toc-h4 nav-item toc-entry"><a class="reference internal nav-link" href="#orthogonal-complement">1.3.2.1. Orthogonal Complement</a></li>
</ul>
</li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#orthonormal-basis">1.4. Orthonormal Basis</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#projection-onto-an-orthonormal-basis">1.4.1. Projection onto an Orthonormal Basis</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#projection-via-matrix-algebra">1.5. Projection Via Matrix Algebra</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#starting-with-the-basis">1.5.1. Starting with the Basis</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#the-orthonormal-case">1.5.2. The Orthonormal Case</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#application-overdetermined-systems-of-equations">1.5.3. Application: Overdetermined Systems of Equations</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#least-squares-regression">1.6. Least Squares Regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#squared-risk-measures">1.6.1. Squared Risk Measures</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#solution">1.6.2. Solution</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#orthogonalization-and-decomposition">1.7. Orthogonalization and Decomposition</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#gram-schmidt-orthogonalization">1.7.1. Gram-Schmidt Orthogonalization</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#qr-decomposition">1.7.2. QR Decomposition</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#linear-regression-via-qr-decomposition">1.7.3. Linear Regression via QR Decomposition</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#exercises">1.8. Exercises</a></li>
</ul>
                            <p class="logo">
                                
                                    
                                    <a href=https://quantecon.org><img src="_static/qe-logo-large.png" class="logo logo-img" alt="logo"></a>
                                    
                                    
                                
                            </p>

                            <p class="powered">Powered by <a href="https://jupyterbook.org/">Jupyter Book</a></p>

                        </nav>

                        <div class="qe-page__toc-footer">
                            
                            
                            <p><a href="#top"><strong>Back to top</strong></a></p>
                        </div>

                    </div>

                </div>

                <div class="qe-page__header">

                    <div class="qe-page__header-copy">

                        <p class="qe-page__header-heading"><a href="intro.html">Advanced Quantitative Economics with Python</a></p>

                        <p class="qe-page__header-subheading">Orthogonal Projections and Their Applications</p>

                    </div>
                    <!-- length 2, since its a string and empty dict has length 2 - {} -->
                        <p class="qe-page__header-authors" font-size="18">
                            
                                
                                    <a href="http://www.tomsargent.com/" target="_blank"><span>Thomas J. Sargent</span></a>
                                
                            
                                
                                    and <a href="https://johnstachurski.net/" target="_blank"><span>John Stachurski</span></a>
                                
                            
                        </p>


                </div> <!-- .page__header -->



                
                <main class="qe-page__content" role="main">
                    
                    <div>
                        
  <div id="qe-notebook-header" align="right" style="text-align:right;">
        <a href="https://quantecon.org/" title="quantecon.org">
                <img style="width:250px;display:inline;" width="250px" src="https://assets.quantecon.org/img/qe-menubar-logo.svg" alt="QuantEcon">
        </a>
</div><section class="tex2jax_ignore mathjax_ignore" id="orthogonal-projections-and-their-applications">
<h1><span class="section-number">1. </span>Orthogonal Projections and Their Applications<a class="headerlink" href="#orthogonal-projections-and-their-applications" title="Permalink to this heading">#</a></h1>
<section id="overview">
<span id="index-0"></span><h2><span class="section-number">1.1. </span>Overview<a class="headerlink" href="#overview" title="Permalink to this heading">#</a></h2>
<p>Orthogonal projection is a cornerstone of vector space methods, with many diverse applications.</p>
<p>These include</p>
<ul class="simple">
<li><p>Least squares projection, also known as linear regression</p></li>
<li><p>Conditional expectations for multivariate normal (Gaussian) distributions</p></li>
<li><p>Gram–Schmidt orthogonalization</p></li>
<li><p>QR decomposition</p></li>
<li><p>Orthogonal polynomials</p></li>
<li><p>etc</p></li>
</ul>
<p>In this lecture, we focus on</p>
<ul class="simple">
<li><p>key ideas</p></li>
<li><p>least squares regression</p></li>
</ul>
<p>We’ll require the following imports:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="kn">from</span> <span class="nn">scipy.linalg</span> <span class="kn">import</span> <span class="n">qr</span>
</pre></div>
</div>
</div>
</div>
<section id="further-reading">
<h3><span class="section-number">1.1.1. </span>Further Reading<a class="headerlink" href="#further-reading" title="Permalink to this heading">#</a></h3>
<p>For background and foundational concepts, see our lecture <a class="reference external" href="https://python-intro.quantecon.org/linear_algebra.html">on linear algebra</a>.</p>
<p>For more proofs and greater theoretical detail, see <a class="reference external" href="http://www.johnstachurski.net/emet.html">A Primer in Econometric Theory</a>.</p>
<p>For a complete set of proofs in a general setting, see, for example, <span id="id1">[<a class="reference internal" href="zreferences.html#id112" title="Steven Roman. Advanced linear algebra. Volume 3. Springer, 2005.">Roman, 2005</a>]</span>.</p>
<p>For an advanced treatment of projection in the context of least squares prediction, see <a class="reference external" href="http://www.tomsargent.com/books/TOMchpt.2.pdf">this book chapter</a>.</p>
</section>
</section>
<section id="key-definitions">
<h2><span class="section-number">1.2. </span>Key Definitions<a class="headerlink" href="#key-definitions" title="Permalink to this heading">#</a></h2>
<p>Assume  <span class="math notranslate nohighlight">\(x, z \in \mathbb R^n\)</span>.</p>
<p>Define <span class="math notranslate nohighlight">\(\langle x,  z\rangle = \sum_i x_i z_i\)</span>.</p>
<p>Recall <span class="math notranslate nohighlight">\(\|x \|^2 = \langle x, x \rangle\)</span>.</p>
<p>The <strong>law of cosines</strong> states that <span class="math notranslate nohighlight">\(\langle x, z \rangle = \| x \| \| z \| \cos(\theta)\)</span> where <span class="math notranslate nohighlight">\(\theta\)</span> is the angle between the vectors <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(z\)</span>.</p>
<p>When <span class="math notranslate nohighlight">\(\langle x,  z\rangle = 0\)</span>, then <span class="math notranslate nohighlight">\(\cos(\theta) = 0\)</span> and  <span class="math notranslate nohighlight">\(x\)</span> and <span class="math notranslate nohighlight">\(z\)</span> are said to be <strong>orthogonal</strong> and we write <span class="math notranslate nohighlight">\(x \perp z\)</span>.</p>
<figure class="align-default">
<img alt="_images/orth_proj_def1.png" src="_images/orth_proj_def1.png" />
</figure>
<p>For a linear subspace  <span class="math notranslate nohighlight">\(S \subset \mathbb R^n\)</span>, we call <span class="math notranslate nohighlight">\(x \in \mathbb R^n\)</span> <strong>orthogonal to</strong> <span class="math notranslate nohighlight">\(S\)</span> if <span class="math notranslate nohighlight">\(x \perp z\)</span> for all <span class="math notranslate nohighlight">\(z \in S\)</span>, and write <span class="math notranslate nohighlight">\(x \perp S\)</span>.</p>
<figure class="align-default">
<img alt="_images/orth_proj_def2.png" src="_images/orth_proj_def2.png" />
</figure>
<p>The <strong>orthogonal complement</strong> of linear subspace <span class="math notranslate nohighlight">\(S \subset \mathbb R^n\)</span> is the set <span class="math notranslate nohighlight">\(S^{\perp} := \{x \in \mathbb R^n \,:\, x \perp S\}\)</span>.</p>
<figure class="align-default">
<img alt="_images/orth_proj_def3.png" src="_images/orth_proj_def3.png" />
</figure>
<p><span class="math notranslate nohighlight">\(S^\perp\)</span> is  a linear subspace of <span class="math notranslate nohighlight">\(\mathbb R^n\)</span></p>
<ul class="simple">
<li><p>To see this, fix <span class="math notranslate nohighlight">\(x, y \in S^{\perp}\)</span> and <span class="math notranslate nohighlight">\(\alpha, \beta \in \mathbb R\)</span>.</p></li>
<li><p>Observe that if <span class="math notranslate nohighlight">\(z \in S\)</span>, then</p></li>
</ul>
<div class="math notranslate nohighlight">
\[
\langle \alpha x + \beta y, z \rangle
= \alpha \langle x, z \rangle + \beta \langle y, z \rangle
 = \alpha \times 0  + \beta \times 0 = 0
\]</div>
<ul class="simple">
<li><p>Hence <span class="math notranslate nohighlight">\(\alpha x + \beta y \in S^{\perp}\)</span>, as was to be shown</p></li>
</ul>
<p>A set of vectors <span class="math notranslate nohighlight">\(\{x_1, \ldots, x_k\} \subset \mathbb R^n\)</span> is called an <strong>orthogonal set</strong> if <span class="math notranslate nohighlight">\(x_i \perp x_j\)</span> whenever <span class="math notranslate nohighlight">\(i \not= j\)</span>.</p>
<p>If <span class="math notranslate nohighlight">\(\{x_1, \ldots, x_k\}\)</span> is an orthogonal set, then the <strong>Pythagorean Law</strong> states that</p>
<div class="math notranslate nohighlight">
\[
\| x_1 + \cdots + x_k \|^2
= \| x_1 \|^2 + \cdots + \| x_k \|^2
\]</div>
<p>For example, when  <span class="math notranslate nohighlight">\(k=2\)</span>, <span class="math notranslate nohighlight">\(x_1 \perp x_2\)</span> implies</p>
<div class="math notranslate nohighlight">
\[
\| x_1 + x_2 \|^2
 = \langle x_1 + x_2, x_1 + x_2 \rangle
 = \langle x_1, x_1 \rangle + 2 \langle  x_2, x_1 \rangle + \langle x_2, x_2 \rangle
 = \| x_1 \|^2 + \| x_2 \|^2
\]</div>
<section id="linear-independence-vs-orthogonality">
<h3><span class="section-number">1.2.1. </span>Linear Independence vs Orthogonality<a class="headerlink" href="#linear-independence-vs-orthogonality" title="Permalink to this heading">#</a></h3>
<p>If <span class="math notranslate nohighlight">\(X \subset \mathbb R^n\)</span> is an orthogonal set and <span class="math notranslate nohighlight">\(0 \notin X\)</span>, then <span class="math notranslate nohighlight">\(X\)</span> is linearly independent.</p>
<p>Proving this is a nice exercise.</p>
<p>While the converse is not true, a kind of partial converse holds, as we’ll <a class="reference internal" href="#gram-schmidt"><span class="std std-ref">see below</span></a>.</p>
</section>
</section>
<section id="the-orthogonal-projection-theorem">
<h2><span class="section-number">1.3. </span>The Orthogonal Projection Theorem<a class="headerlink" href="#the-orthogonal-projection-theorem" title="Permalink to this heading">#</a></h2>
<p>What vector within a linear subspace of <span class="math notranslate nohighlight">\(\mathbb R^n\)</span>  best approximates a given vector in <span class="math notranslate nohighlight">\(\mathbb R^n\)</span>?</p>
<p>The next theorem answers this question.</p>
<p><strong>Theorem</strong> (OPT) Given <span class="math notranslate nohighlight">\(y \in \mathbb R^n\)</span> and linear subspace <span class="math notranslate nohighlight">\(S \subset \mathbb R^n\)</span>,
there exists a unique solution to the minimization problem</p>
<div class="math notranslate nohighlight">
\[
\hat y := \argmin_{z \in S} \|y - z\|
\]</div>
<p>The minimizer <span class="math notranslate nohighlight">\(\hat y\)</span> is the unique vector in <span class="math notranslate nohighlight">\(\mathbb R^n\)</span> that satisfies</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(\hat y \in S\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(y - \hat y \perp S\)</span></p></li>
</ul>
<p>The vector <span class="math notranslate nohighlight">\(\hat y\)</span> is called the <strong>orthogonal projection</strong> of <span class="math notranslate nohighlight">\(y\)</span> onto <span class="math notranslate nohighlight">\(S\)</span>.</p>
<p>The next figure provides some intuition</p>
<figure class="align-default">
<img alt="_images/orth_proj_thm1.png" src="_images/orth_proj_thm1.png" />
</figure>
<section id="proof-of-sufficiency">
<h3><span class="section-number">1.3.1. </span>Proof of Sufficiency<a class="headerlink" href="#proof-of-sufficiency" title="Permalink to this heading">#</a></h3>
<p>We’ll omit the full proof.</p>
<p>But we will prove sufficiency of the asserted conditions.</p>
<p>To this end, let <span class="math notranslate nohighlight">\(y \in \mathbb R^n\)</span> and let <span class="math notranslate nohighlight">\(S\)</span> be a linear subspace of <span class="math notranslate nohighlight">\(\mathbb R^n\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(\hat y\)</span> be a vector in <span class="math notranslate nohighlight">\(\mathbb R^n\)</span> such that <span class="math notranslate nohighlight">\(\hat y \in S\)</span> and <span class="math notranslate nohighlight">\(y - \hat y \perp S\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(z\)</span> be any other point in <span class="math notranslate nohighlight">\(S\)</span> and use the fact that <span class="math notranslate nohighlight">\(S\)</span> is a linear subspace to deduce</p>
<div class="math notranslate nohighlight">
\[
\| y - z \|^2
= \| (y - \hat y) + (\hat y - z) \|^2
= \| y - \hat y \|^2  + \| \hat y - z  \|^2
\]</div>
<p>Hence <span class="math notranslate nohighlight">\(\| y - z \| \geq \| y - \hat y \|\)</span>, which completes the proof.</p>
</section>
<section id="orthogonal-projection-as-a-mapping">
<h3><span class="section-number">1.3.2. </span>Orthogonal Projection as a Mapping<a class="headerlink" href="#orthogonal-projection-as-a-mapping" title="Permalink to this heading">#</a></h3>
<p>For a linear space <span class="math notranslate nohighlight">\(Y\)</span> and a fixed linear subspace <span class="math notranslate nohighlight">\(S\)</span>, we have a functional relationship</p>
<div class="math notranslate nohighlight">
\[
y \in Y\; \mapsto \text{ its orthogonal projection } \hat y \in S
\]</div>
<p>By the OPT, this is a well-defined mapping  or <em>operator</em> from <span class="math notranslate nohighlight">\(\mathbb R^n\)</span> to <span class="math notranslate nohighlight">\(\mathbb R^n\)</span>.</p>
<p>In what follows we denote this operator by a matrix <span class="math notranslate nohighlight">\(P\)</span></p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(P y\)</span> represents the projection <span class="math notranslate nohighlight">\(\hat y\)</span>.</p></li>
<li><p>This is sometimes expressed as <span class="math notranslate nohighlight">\(\hat E_S y = P y\)</span>, where <span class="math notranslate nohighlight">\(\hat E\)</span> denotes a <strong>wide-sense expectations operator</strong> and the subscript <span class="math notranslate nohighlight">\(S\)</span> indicates that we are projecting <span class="math notranslate nohighlight">\(y\)</span> onto the linear subspace <span class="math notranslate nohighlight">\(S\)</span>.</p></li>
</ul>
<p>The operator <span class="math notranslate nohighlight">\(P\)</span> is called the <strong>orthogonal projection mapping onto</strong> <span class="math notranslate nohighlight">\(S\)</span>.</p>
<figure class="align-default">
<img alt="_images/orth_proj_thm2.png" src="_images/orth_proj_thm2.png" />
</figure>
<p>It is immediate from the OPT that for any <span class="math notranslate nohighlight">\(y \in \mathbb R^n\)</span></p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(P y \in S\)</span> and</p></li>
<li><p><span class="math notranslate nohighlight">\(y - P y \perp S\)</span></p></li>
</ol>
<p>From this, we can deduce additional useful properties, such as</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(\| y \|^2 = \| P y \|^2 + \| y - P y \|^2\)</span> and</p></li>
<li><p><span class="math notranslate nohighlight">\(\| P y \| \leq \| y \|\)</span></p></li>
</ol>
<p>For example, to prove 1, observe that <span class="math notranslate nohighlight">\(y  = P y  + y - P y\)</span> and apply the Pythagorean law.</p>
<section id="orthogonal-complement">
<h4><span class="section-number">1.3.2.1. </span>Orthogonal Complement<a class="headerlink" href="#orthogonal-complement" title="Permalink to this heading">#</a></h4>
<p>Let <span class="math notranslate nohighlight">\(S \subset \mathbb R^n\)</span>.</p>
<p>The <strong>orthogonal complement</strong> of <span class="math notranslate nohighlight">\(S\)</span> is the linear subspace <span class="math notranslate nohighlight">\(S^{\perp}\)</span> that satisfies
<span class="math notranslate nohighlight">\(x_1 \perp x_2\)</span> for every <span class="math notranslate nohighlight">\(x_1 \in S\)</span> and <span class="math notranslate nohighlight">\(x_2 \in S^{\perp}\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(Y\)</span> be a linear space with linear subspace <span class="math notranslate nohighlight">\(S\)</span> and its orthogonal complement <span class="math notranslate nohighlight">\(S^{\perp}\)</span>.</p>
<p>We write</p>
<div class="math notranslate nohighlight">
\[
Y = S \oplus S^{\perp}
\]</div>
<p>to indicate that for every <span class="math notranslate nohighlight">\(y \in Y\)</span> there is unique <span class="math notranslate nohighlight">\(x_1 \in S\)</span> and a unique <span class="math notranslate nohighlight">\(x_2 \in S^{\perp}\)</span>
such that <span class="math notranslate nohighlight">\(y = x_1 + x_2\)</span>.</p>
<p>Moreover, <span class="math notranslate nohighlight">\(x_1 = \hat E_S y\)</span> and <span class="math notranslate nohighlight">\(x_2 = y - \hat E_S y\)</span>.</p>
<p>This amounts to another version of the OPT:</p>
<p><strong>Theorem</strong>.  If <span class="math notranslate nohighlight">\(S\)</span> is a linear subspace of <span class="math notranslate nohighlight">\(\mathbb R^n\)</span>, <span class="math notranslate nohighlight">\(\hat E_S y = P y\)</span> and <span class="math notranslate nohighlight">\(\hat E_{S^{\perp}} y = M y\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
P y \perp M y
 \quad \text{and} \quad
y = P y + M y
 \quad \text{for all } \, y \in \mathbb R^n
\]</div>
<p>The next figure illustrates</p>
<figure class="align-default">
<img alt="_images/orth_proj_thm3.png" src="_images/orth_proj_thm3.png" />
</figure>
</section>
</section>
</section>
<section id="orthonormal-basis">
<h2><span class="section-number">1.4. </span>Orthonormal Basis<a class="headerlink" href="#orthonormal-basis" title="Permalink to this heading">#</a></h2>
<p>An orthogonal set of vectors <span class="math notranslate nohighlight">\(O \subset \mathbb R^n\)</span> is called an <strong>orthonormal set</strong> if <span class="math notranslate nohighlight">\(\| u \| = 1\)</span> for all <span class="math notranslate nohighlight">\(u \in O\)</span>.</p>
<p>Let <span class="math notranslate nohighlight">\(S\)</span> be a linear subspace of <span class="math notranslate nohighlight">\(\mathbb R^n\)</span> and let <span class="math notranslate nohighlight">\(O \subset S\)</span>.</p>
<p>If <span class="math notranslate nohighlight">\(O\)</span> is orthonormal and <span class="math notranslate nohighlight">\(\mathop{\mathrm{span}} O = S\)</span>, then <span class="math notranslate nohighlight">\(O\)</span> is called an <strong>orthonormal basis</strong> of <span class="math notranslate nohighlight">\(S\)</span>.</p>
<p><span class="math notranslate nohighlight">\(O\)</span> is necessarily a basis of <span class="math notranslate nohighlight">\(S\)</span> (being independent by orthogonality and the fact that no element is the zero vector).</p>
<p>One example of an orthonormal set is the canonical basis <span class="math notranslate nohighlight">\(\{e_1, \ldots, e_n\}\)</span>
that forms an orthonormal basis of <span class="math notranslate nohighlight">\(\mathbb R^n\)</span>, where <span class="math notranslate nohighlight">\(e_i\)</span> is the <span class="math notranslate nohighlight">\(i\)</span> th unit vector.</p>
<p>If <span class="math notranslate nohighlight">\(\{u_1, \ldots, u_k\}\)</span> is an orthonormal basis of linear subspace <span class="math notranslate nohighlight">\(S\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
x = \sum_{i=1}^k \langle x, u_i \rangle u_i
\quad \text{for all} \quad
x \in S
\]</div>
<p>To see this, observe that since <span class="math notranslate nohighlight">\(x \in \mathop{\mathrm{span}}\{u_1, \ldots, u_k\}\)</span>, we can find
scalars <span class="math notranslate nohighlight">\(\alpha_1, \ldots, \alpha_k\)</span> that verify</p>
<div class="math notranslate nohighlight" id="equation-pob">
<span class="eqno">(1.1)<a class="headerlink" href="#equation-pob" title="Permalink to this equation">#</a></span>\[x = \sum_{j=1}^k \alpha_j u_j\]</div>
<p>Taking the inner product with respect to <span class="math notranslate nohighlight">\(u_i\)</span> gives</p>
<div class="math notranslate nohighlight">
\[
\langle x, u_i \rangle
= \sum_{j=1}^k \alpha_j \langle u_j, u_i \rangle
= \alpha_i
\]</div>
<p>Combining this result with <a class="reference internal" href="#equation-pob">(1.1)</a> verifies the claim.</p>
<section id="projection-onto-an-orthonormal-basis">
<h3><span class="section-number">1.4.1. </span>Projection onto an Orthonormal Basis<a class="headerlink" href="#projection-onto-an-orthonormal-basis" title="Permalink to this heading">#</a></h3>
<p>When a subspace onto which we project is orthonormal, computing the projection simplifies:</p>
<p><strong>Theorem</strong> If <span class="math notranslate nohighlight">\(\{u_1, \ldots, u_k\}\)</span> is an orthonormal basis for <span class="math notranslate nohighlight">\(S\)</span>, then</p>
<div class="math notranslate nohighlight" id="equation-exp-for-op">
<span class="eqno">(1.2)<a class="headerlink" href="#equation-exp-for-op" title="Permalink to this equation">#</a></span>\[P y = \sum_{i=1}^k \langle y, u_i \rangle u_i,
\quad
\forall \; y \in \mathbb R^n\]</div>
<p>Proof: Fix <span class="math notranslate nohighlight">\(y \in \mathbb R^n\)</span> and let <span class="math notranslate nohighlight">\(P y\)</span> be  defined as in <a class="reference internal" href="#equation-exp-for-op">(1.2)</a>.</p>
<p>Clearly, <span class="math notranslate nohighlight">\(P y \in S\)</span>.</p>
<p>We claim that <span class="math notranslate nohighlight">\(y - P y \perp S\)</span> also holds.</p>
<p>It sufficies to show that <span class="math notranslate nohighlight">\(y - P y \perp\)</span> any basis vector <span class="math notranslate nohighlight">\(u_i\)</span>.</p>
<p>This is true because</p>
<div class="math notranslate nohighlight">
\[
\left\langle y - \sum_{i=1}^k \langle y, u_i \rangle u_i, u_j \right\rangle
= \langle y, u_j \rangle  - \sum_{i=1}^k \langle y, u_i \rangle
\langle u_i, u_j  \rangle = 0
\]</div>
<p>(Why is this sufficient to establish the claim that <span class="math notranslate nohighlight">\(y - P y \perp S\)</span>?)</p>
</section>
</section>
<section id="projection-via-matrix-algebra">
<h2><span class="section-number">1.5. </span>Projection Via Matrix Algebra<a class="headerlink" href="#projection-via-matrix-algebra" title="Permalink to this heading">#</a></h2>
<p>Let <span class="math notranslate nohighlight">\(S\)</span> be a linear subspace of <span class="math notranslate nohighlight">\(\mathbb R^n\)</span> and  let <span class="math notranslate nohighlight">\(y \in \mathbb R^n\)</span>.</p>
<p>We want to compute the matrix <span class="math notranslate nohighlight">\(P\)</span> that verifies</p>
<div class="math notranslate nohighlight">
\[
\hat E_S y = P y
\]</div>
<p>Evidently  <span class="math notranslate nohighlight">\(Py\)</span> is a linear function from <span class="math notranslate nohighlight">\(y \in \mathbb R^n\)</span> to <span class="math notranslate nohighlight">\(P y \in \mathbb R^n\)</span>.</p>
<p><a class="reference external" href="https://en.wikipedia.org/wiki/Linear_map#Matrices">This reference</a> is useful.</p>
<p><strong>Theorem.</strong> Let the columns of <span class="math notranslate nohighlight">\(n \times k\)</span> matrix <span class="math notranslate nohighlight">\(X\)</span> form a basis of <span class="math notranslate nohighlight">\(S\)</span>.  Then</p>
<div class="math notranslate nohighlight">
\[
P = X (X'X)^{-1} X'
\]</div>
<p>Proof: Given arbitrary <span class="math notranslate nohighlight">\(y \in \mathbb R^n\)</span> and <span class="math notranslate nohighlight">\(P = X (X'X)^{-1} X'\)</span>, our claim is that</p>
<ol class="arabic simple">
<li><p><span class="math notranslate nohighlight">\(P y \in S\)</span>, and</p></li>
<li><p><span class="math notranslate nohighlight">\(y - P y \perp S\)</span></p></li>
</ol>
<p>Claim 1 is true because</p>
<div class="math notranslate nohighlight">
\[
P y = X (X' X)^{-1} X' y = X a
\quad \text{when} \quad
a := (X' X)^{-1} X' y
\]</div>
<p>An expression of the form <span class="math notranslate nohighlight">\(X a\)</span> is precisely a linear combination of the
columns of <span class="math notranslate nohighlight">\(X\)</span> and hence an element of <span class="math notranslate nohighlight">\(S\)</span>.</p>
<p>Claim 2 is equivalent to the statement</p>
<div class="math notranslate nohighlight">
\[
y - X (X' X)^{-1} X' y \, \perp\,  X b
\quad \text{for all} \quad
b \in \mathbb R^K
\]</div>
<p>To verify this, notice that if <span class="math notranslate nohighlight">\(b \in \mathbb R^K\)</span>, then</p>
<div class="math notranslate nohighlight">
\[
(X b)' [y - X (X' X)^{-1} X'
y]
= b' [X' y - X' y]
= 0
\]</div>
<p>The proof is now complete.</p>
<section id="starting-with-the-basis">
<h3><span class="section-number">1.5.1. </span>Starting with the Basis<a class="headerlink" href="#starting-with-the-basis" title="Permalink to this heading">#</a></h3>
<p>It is common in applications to start with <span class="math notranslate nohighlight">\(n \times k\)</span> matrix <span class="math notranslate nohighlight">\(X\)</span>  with linearly independent columns and let</p>
<div class="math notranslate nohighlight">
\[
S := \mathop{\mathrm{span}} X := \mathop{\mathrm{span}} \{\col_1 X, \ldots, \col_k X \}
\]</div>
<p>Then the columns of <span class="math notranslate nohighlight">\(X\)</span> form a basis of <span class="math notranslate nohighlight">\(S\)</span>.</p>
<p>From the preceding theorem, <span class="math notranslate nohighlight">\(P = X (X' X)^{-1} X' y\)</span> projects <span class="math notranslate nohighlight">\(y\)</span> onto <span class="math notranslate nohighlight">\(S\)</span>.</p>
<p>In this context, <span class="math notranslate nohighlight">\(P\)</span> is often called the <strong>projection matrix</strong></p>
<ul class="simple">
<li><p>The matrix <span class="math notranslate nohighlight">\(M = I - P\)</span> satisfies <span class="math notranslate nohighlight">\(M y = \hat E_{S^{\perp}} y\)</span> and is sometimes called the <strong>annihilator matrix</strong>.</p></li>
</ul>
</section>
<section id="the-orthonormal-case">
<h3><span class="section-number">1.5.2. </span>The Orthonormal Case<a class="headerlink" href="#the-orthonormal-case" title="Permalink to this heading">#</a></h3>
<p>Suppose that <span class="math notranslate nohighlight">\(U\)</span> is <span class="math notranslate nohighlight">\(n \times k\)</span> with orthonormal columns.</p>
<p>Let <span class="math notranslate nohighlight">\(u_i := \mathop{\mathrm{col}} U_i\)</span> for each <span class="math notranslate nohighlight">\(i\)</span>, let <span class="math notranslate nohighlight">\(S := \mathop{\mathrm{span}} U\)</span> and let <span class="math notranslate nohighlight">\(y \in \mathbb R^n\)</span>.</p>
<p>We know that the projection of <span class="math notranslate nohighlight">\(y\)</span> onto <span class="math notranslate nohighlight">\(S\)</span> is</p>
<div class="math notranslate nohighlight">
\[
P y = U (U' U)^{-1} U' y
\]</div>
<p>Since <span class="math notranslate nohighlight">\(U\)</span> has orthonormal columns, we have <span class="math notranslate nohighlight">\(U' U = I\)</span>.</p>
<p>Hence</p>
<div class="math notranslate nohighlight">
\[
P y
= U U' y
= \sum_{i=1}^k \langle u_i, y \rangle u_i
\]</div>
<p>We have recovered our earlier result about projecting onto the span of an orthonormal
basis.</p>
</section>
<section id="application-overdetermined-systems-of-equations">
<h3><span class="section-number">1.5.3. </span>Application: Overdetermined Systems of Equations<a class="headerlink" href="#application-overdetermined-systems-of-equations" title="Permalink to this heading">#</a></h3>
<p>Let <span class="math notranslate nohighlight">\(y \in \mathbb R^n\)</span> and let <span class="math notranslate nohighlight">\(X\)</span> be <span class="math notranslate nohighlight">\(n \times k\)</span> with linearly independent columns.</p>
<p>Given <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(y\)</span>, we seek <span class="math notranslate nohighlight">\(b \in \mathbb R^k\)</span> that  satisfies the system of linear equations <span class="math notranslate nohighlight">\(X b = y\)</span>.</p>
<p>If <span class="math notranslate nohighlight">\(n &gt; k\)</span> (more equations than unknowns), then <span class="math notranslate nohighlight">\(b\)</span> is said to be <strong>overdetermined</strong>.</p>
<p>Intuitively, we may not be able to find a <span class="math notranslate nohighlight">\(b\)</span> that satisfies all <span class="math notranslate nohighlight">\(n\)</span> equations.</p>
<p>The best approach here is to</p>
<ul class="simple">
<li><p>Accept that an exact solution may not exist.</p></li>
<li><p>Look instead for an approximate solution.</p></li>
</ul>
<p>By approximate solution, we mean a <span class="math notranslate nohighlight">\(b \in \mathbb R^k\)</span> such that <span class="math notranslate nohighlight">\(X b\)</span> is  close to <span class="math notranslate nohighlight">\(y\)</span>.</p>
<p>The next theorem shows that a best approximation is well defined and unique.</p>
<p>The proof uses the OPT.</p>
<p><strong>Theorem</strong> The unique minimizer of  <span class="math notranslate nohighlight">\(\| y - X b \|\)</span> over <span class="math notranslate nohighlight">\(b \in \mathbb R^K\)</span> is</p>
<div class="math notranslate nohighlight">
\[
\hat \beta := (X' X)^{-1} X' y
\]</div>
<p>Proof:  Note that</p>
<div class="math notranslate nohighlight">
\[
X \hat \beta = X (X' X)^{-1} X' y =
P y
\]</div>
<p>Since <span class="math notranslate nohighlight">\(P y\)</span> is the orthogonal projection onto <span class="math notranslate nohighlight">\(\mathop{\mathrm{span}}(X)\)</span> we have</p>
<div class="math notranslate nohighlight">
\[
\| y - P y \|
\leq \| y - z \| \text{ for any } z \in \mathop{\mathrm{span}}(X)
\]</div>
<p>Because <span class="math notranslate nohighlight">\(Xb \in \mathop{\mathrm{span}}(X)\)</span></p>
<div class="math notranslate nohighlight">
\[
\| y - X \hat \beta \|
\leq \| y - X b \| \text{ for any } b \in \mathbb R^K
\]</div>
<p>This is what we aimed to show.</p>
</section>
</section>
<section id="least-squares-regression">
<h2><span class="section-number">1.6. </span>Least Squares Regression<a class="headerlink" href="#least-squares-regression" title="Permalink to this heading">#</a></h2>
<p>Let’s apply the theory of orthogonal projection to least squares regression.</p>
<p>This approach provides insights about  many geometric  properties of linear regression.</p>
<p>We treat only some examples.</p>
<section id="squared-risk-measures">
<h3><span class="section-number">1.6.1. </span>Squared Risk Measures<a class="headerlink" href="#squared-risk-measures" title="Permalink to this heading">#</a></h3>
<p>Given pairs <span class="math notranslate nohighlight">\((x, y) \in \mathbb R^K \times \mathbb R\)</span>, consider choosing <span class="math notranslate nohighlight">\(f \colon \mathbb R^K \to \mathbb R\)</span> to minimize
the <strong>risk</strong></p>
<div class="math notranslate nohighlight">
\[
R(f) := \mathbb{E}\, [(y - f(x))^2]
\]</div>
<p>If probabilities and hence <span class="math notranslate nohighlight">\(\mathbb{E}\,\)</span> are unknown, we cannot solve this problem directly.</p>
<p>However, if a sample is available, we can estimate the risk with the <strong>empirical risk</strong>:</p>
<div class="math notranslate nohighlight">
\[
\min_{f \in \mathcal{F}} \frac{1}{N} \sum_{n=1}^N (y_n - f(x_n))^2
\]</div>
<p>Minimizing this expression is called <strong>empirical risk minimization</strong>.</p>
<p>The set <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> is sometimes called the hypothesis space.</p>
<p>The theory of statistical learning tells us that to prevent overfitting we should take the set <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> to be relatively simple.</p>
<p>If we let <span class="math notranslate nohighlight">\(\mathcal{F}\)</span> be the class of linear functions, the problem is</p>
<div class="math notranslate nohighlight">
\[
\min_{b \in \mathbb R^K} \;
\sum_{n=1}^N (y_n - b' x_n)^2
\]</div>
<p>This is the sample <strong>linear least squares problem</strong>.</p>
</section>
<section id="solution">
<h3><span class="section-number">1.6.2. </span>Solution<a class="headerlink" href="#solution" title="Permalink to this heading">#</a></h3>
<p>Define the matrices</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y :=
\left(
\begin{array}{c}
    y_1 \\
    y_2 \\
    \vdots \\
    y_N
\end{array}
\right),
\quad
x_n :=
\left(
\begin{array}{c}
    x_{n1} \\
    x_{n2} \\
    \vdots \\
    x_{nK}
\end{array}
\right)
= n\text{-th obs on all regressors}
\end{split}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X :=
\left(
\begin{array}{c}
    x_1'  \\
    x_2'  \\
    \vdots     \\
    x_N'
\end{array}
\right)
:=:
\left(
\begin{array}{cccc}
    x_{11} &amp; x_{12} &amp; \cdots &amp; x_{1K} \\
    x_{21} &amp; x_{22} &amp; \cdots &amp; x_{2K} \\
    \vdots &amp; \vdots &amp;  &amp; \vdots \\
    x_{N1} &amp; x_{N2} &amp; \cdots &amp; x_{NK}
\end{array}
\right)
\end{split}\]</div>
<p>We assume throughout that <span class="math notranslate nohighlight">\(N &gt; K\)</span> and <span class="math notranslate nohighlight">\(X\)</span> is full column rank.</p>
<p>If you work through the algebra, you will be able to verify that <span class="math notranslate nohighlight">\(\| y - X b \|^2 = \sum_{n=1}^N (y_n - b' x_n)^2\)</span>.</p>
<p>Since monotone transforms don’t affect minimizers, we have</p>
<div class="math notranslate nohighlight">
\[
\argmin_{b \in \mathbb R^K} \sum_{n=1}^N (y_n - b' x_n)^2
= \argmin_{b \in \mathbb R^K} \| y - X b \|
\]</div>
<p>By our results about overdetermined linear systems of equations, the solution is</p>
<div class="math notranslate nohighlight">
\[
\hat \beta := (X' X)^{-1} X' y
\]</div>
<p>Let <span class="math notranslate nohighlight">\(P\)</span> and <span class="math notranslate nohighlight">\(M\)</span> be the projection and annihilator associated with <span class="math notranslate nohighlight">\(X\)</span>:</p>
<div class="math notranslate nohighlight">
\[
P := X (X' X)^{-1} X'
\quad \text{and} \quad
M := I - P
\]</div>
<p>The <strong>vector of fitted values</strong> is</p>
<div class="math notranslate nohighlight">
\[
\hat y := X \hat \beta = P y
\]</div>
<p>The <strong>vector of residuals</strong> is</p>
<div class="math notranslate nohighlight">
\[
\hat u :=  y - \hat y = y - P y = M y
\]</div>
<p>Here are some more standard definitions:</p>
<ul class="simple">
<li><p>The <strong>total sum of squares</strong> is <span class="math notranslate nohighlight">\(:=  \| y \|^2\)</span>.</p></li>
<li><p>The <strong>sum of squared residuals</strong> is <span class="math notranslate nohighlight">\(:= \| \hat u \|^2\)</span>.</p></li>
<li><p>The <strong>explained sum of squares</strong> is <span class="math notranslate nohighlight">\(:= \| \hat y \|^2\)</span>.</p></li>
</ul>
<blockquote>
<div><p>TSS = ESS + SSR</p>
</div></blockquote>
<p>We can prove this easily using the OPT.</p>
<p>From the OPT we have <span class="math notranslate nohighlight">\(y =  \hat y + \hat u\)</span> and <span class="math notranslate nohighlight">\(\hat u \perp \hat y\)</span>.</p>
<p>Applying the Pythagorean law completes the proof.</p>
</section>
</section>
<section id="orthogonalization-and-decomposition">
<h2><span class="section-number">1.7. </span>Orthogonalization and Decomposition<a class="headerlink" href="#orthogonalization-and-decomposition" title="Permalink to this heading">#</a></h2>
<p>Let’s return to the connection between linear independence and orthogonality touched on above.</p>
<p>A result of much interest is a famous algorithm for constructing orthonormal sets from linearly independent sets.</p>
<p>The next section gives details.</p>
<section id="gram-schmidt-orthogonalization">
<span id="gram-schmidt"></span><h3><span class="section-number">1.7.1. </span>Gram-Schmidt Orthogonalization<a class="headerlink" href="#gram-schmidt-orthogonalization" title="Permalink to this heading">#</a></h3>
<p><strong>Theorem</strong> For each linearly independent set <span class="math notranslate nohighlight">\(\{x_1, \ldots, x_k\} \subset \mathbb R^n\)</span>, there exists an
orthonormal set <span class="math notranslate nohighlight">\(\{u_1, \ldots, u_k\}\)</span> with</p>
<div class="math notranslate nohighlight">
\[
\mathop{\mathrm{span}} \{x_1, \ldots, x_i\} =
\mathop{\mathrm{span}} \{u_1, \ldots, u_i\}
\quad \text{for} \quad
i = 1, \ldots, k
\]</div>
<p>The <strong>Gram-Schmidt orthogonalization</strong> procedure constructs an orthogonal set <span class="math notranslate nohighlight">\(\{ u_1, u_2, \ldots, u_n\}\)</span>.</p>
<p>One description of this procedure is as follows:</p>
<ul class="simple">
<li><p>For <span class="math notranslate nohighlight">\(i = 1, \ldots, k\)</span>, form <span class="math notranslate nohighlight">\(S_i := \mathop{\mathrm{span}}\{x_1, \ldots, x_i\}\)</span> and <span class="math notranslate nohighlight">\(S_i^{\perp}\)</span></p></li>
<li><p>Set <span class="math notranslate nohighlight">\(v_1 = x_1\)</span></p></li>
<li><p>For <span class="math notranslate nohighlight">\(i \geq 2\)</span> set <span class="math notranslate nohighlight">\(v_i := \hat E_{S_{i-1}^{\perp}} x_i\)</span> and <span class="math notranslate nohighlight">\(u_i := v_i / \| v_i \|\)</span></p></li>
</ul>
<p>The sequence <span class="math notranslate nohighlight">\(u_1, \ldots, u_k\)</span> has the stated properties.</p>
<p>A Gram-Schmidt orthogonalization construction is a key idea behind the Kalman filter described in <a class="reference external" href="https://python-intro.quantecon.org/kalman.html">A First Look at the Kalman filter</a>.</p>
<p>In some exercises below, you are asked to implement this algorithm and test it using projection.</p>
</section>
<section id="qr-decomposition">
<h3><span class="section-number">1.7.2. </span>QR Decomposition<a class="headerlink" href="#qr-decomposition" title="Permalink to this heading">#</a></h3>
<p>The following result uses the preceding algorithm to produce a useful decomposition.</p>
<p><strong>Theorem</strong> If <span class="math notranslate nohighlight">\(X\)</span> is <span class="math notranslate nohighlight">\(n \times k\)</span> with linearly independent columns, then there exists a factorization <span class="math notranslate nohighlight">\(X = Q R\)</span> where</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(R\)</span> is <span class="math notranslate nohighlight">\(k \times k\)</span>, upper triangular, and nonsingular</p></li>
<li><p><span class="math notranslate nohighlight">\(Q\)</span> is <span class="math notranslate nohighlight">\(n \times k\)</span> with orthonormal columns</p></li>
</ul>
<p>Proof sketch: Let</p>
<ul class="simple">
<li><p><span class="math notranslate nohighlight">\(x_j := \col_j (X)\)</span></p></li>
<li><p><span class="math notranslate nohighlight">\(\{u_1, \ldots, u_k\}\)</span> be orthonormal with the same span as <span class="math notranslate nohighlight">\(\{x_1, \ldots, x_k\}\)</span> (to be constructed using Gram–Schmidt)</p></li>
<li><p><span class="math notranslate nohighlight">\(Q\)</span> be formed from cols <span class="math notranslate nohighlight">\(u_i\)</span></p></li>
</ul>
<p>Since <span class="math notranslate nohighlight">\(x_j \in \mathop{\mathrm{span}}\{u_1, \ldots, u_j\}\)</span>, we have</p>
<div class="math notranslate nohighlight">
\[
x_j = \sum_{i=1}^j \langle u_i, x_j  \rangle u_i
\quad \text{for } j = 1, \ldots, k
\]</div>
<p>Some rearranging gives <span class="math notranslate nohighlight">\(X = Q R\)</span>.</p>
</section>
<section id="linear-regression-via-qr-decomposition">
<h3><span class="section-number">1.7.3. </span>Linear Regression via QR Decomposition<a class="headerlink" href="#linear-regression-via-qr-decomposition" title="Permalink to this heading">#</a></h3>
<p>For matrices <span class="math notranslate nohighlight">\(X\)</span> and <span class="math notranslate nohighlight">\(y\)</span> that overdetermine <span class="math notranslate nohighlight">\(\beta\)</span> in the linear
equation system <span class="math notranslate nohighlight">\(y = X \beta\)</span>, we found  the least squares approximator <span class="math notranslate nohighlight">\(\hat \beta = (X' X)^{-1} X' y\)</span>.</p>
<p>Using the QR decomposition <span class="math notranslate nohighlight">\(X = Q R\)</span> gives</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\begin{aligned}
    \hat \beta
    &amp; = (R'Q' Q R)^{-1} R' Q' y \\
    &amp; = (R' R)^{-1} R' Q' y \\
    &amp; = R^{-1} (R')^{-1} R' Q' y
        = R^{-1} Q' y
\end{aligned}
\end{split}\]</div>
<p>Numerical routines would in this case use the alternative form <span class="math notranslate nohighlight">\(R \hat \beta = Q' y\)</span> and back substitution.</p>
</section>
</section>
<section id="exercises">
<h2><span class="section-number">1.8. </span>Exercises<a class="headerlink" href="#exercises" title="Permalink to this heading">#</a></h2>
<div class="exercise admonition" id="op_ex1">

<p class="admonition-title"><span class="caption-number">Exercise 1.1 </span></p>
<section id="exercise-content">
<p>Show that, for any linear subspace <span class="math notranslate nohighlight">\(S \subset \mathbb R^n\)</span>,  <span class="math notranslate nohighlight">\(S \cap S^{\perp} = \{0\}\)</span>.</p>
</section>
</div>
<div class="solution dropdown admonition" id="orth_proj-solution-1">

<p class="admonition-title">Solution to<a class="reference internal" href="#op_ex1"> Exercise 1.1</a></p>
<section id="solution-content">
<p>If <span class="math notranslate nohighlight">\(x \in S\)</span> and <span class="math notranslate nohighlight">\(x \in S^\perp\)</span>, then we have in particular
that <span class="math notranslate nohighlight">\(\langle x, x \rangle = 0\)</span>, but then <span class="math notranslate nohighlight">\(x = 0\)</span>.</p>
</section>
</div>
<div class="exercise admonition" id="op_ex2">

<p class="admonition-title"><span class="caption-number">Exercise 1.2 </span></p>
<section id="exercise-content">
<p>Let <span class="math notranslate nohighlight">\(P = X (X' X)^{-1} X'\)</span> and let <span class="math notranslate nohighlight">\(M = I - P\)</span>.  Show that
<span class="math notranslate nohighlight">\(P\)</span> and <span class="math notranslate nohighlight">\(M\)</span> are both idempotent and symmetric.  Can you give any
intuition as to why they should be idempotent?</p>
</section>
</div>
<div class="solution dropdown admonition" id="orth_proj-solution-3">

<p class="admonition-title">Solution to<a class="reference internal" href="#op_ex2"> Exercise 1.2</a></p>
<section id="solution-content">
<p>Symmetry and idempotence of <span class="math notranslate nohighlight">\(M\)</span> and <span class="math notranslate nohighlight">\(P\)</span> can be established
using standard rules for matrix algebra. The intuition behind
idempotence of <span class="math notranslate nohighlight">\(M\)</span> and <span class="math notranslate nohighlight">\(P\)</span> is that both are orthogonal
projections. After a point is projected into a given subspace, applying
the projection again makes no difference (A point inside the subspace
is not shifted by orthogonal projection onto that space because it is
already the closest point in the subspace to itself).</p>
</section>
</div>
<div class="exercise admonition" id="op_ex3">

<p class="admonition-title"><span class="caption-number">Exercise 1.3 </span></p>
<section id="exercise-content">
<p>Using Gram-Schmidt orthogonalization, produce a linear projection of <span class="math notranslate nohighlight">\(y\)</span> onto the column space of <span class="math notranslate nohighlight">\(X\)</span> and verify this using the projection matrix <span class="math notranslate nohighlight">\(P := X (X' X)^{-1} X'\)</span> and also using QR decomposition, where:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
y :=
\left(
\begin{array}{c}
    1 \\
    3 \\
    -3
\end{array}
\right),
\quad
\end{split}\]</div>
<p>and</p>
<div class="math notranslate nohighlight">
\[\begin{split}
X :=
\left(
\begin{array}{cc}
    1 &amp;  0  \\
    0 &amp; -6 \\
    2 &amp;  2
\end{array}
\right)
\end{split}\]</div>
</section>
</div>
<div class="solution dropdown admonition" id="orth_proj-solution-5">

<p class="admonition-title">Solution to<a class="reference internal" href="#op_ex3"> Exercise 1.3</a></p>
<section id="solution-content">
<p>Here’s a function that computes the orthonormal vectors using the GS
algorithm given in the lecture</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">gram_schmidt</span><span class="p">(</span><span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Implements Gram-Schmidt orthogonalization.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    X : an n x k array with linearly independent columns</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    U : an n x k array with orthonormal columns</span>

<span class="sd">    &quot;&quot;&quot;</span>

    <span class="c1"># Set up</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">k</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">U</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">empty</span><span class="p">((</span><span class="n">n</span><span class="p">,</span> <span class="n">k</span><span class="p">))</span>
    <span class="n">I</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">eye</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>

    <span class="c1"># The first col of U is just the normalized first col of X</span>
    <span class="n">v1</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span><span class="mi">0</span><span class="p">]</span>
    <span class="n">U</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">]</span> <span class="o">=</span> <span class="n">v1</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">v1</span> <span class="o">*</span> <span class="n">v1</span><span class="p">))</span>

    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">1</span><span class="p">,</span> <span class="n">k</span><span class="p">):</span>
        <span class="c1"># Set up</span>
        <span class="n">b</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span>       <span class="c1"># The vector we&#39;re going to project</span>
        <span class="n">Z</span> <span class="o">=</span> <span class="n">X</span><span class="p">[:,</span> <span class="mi">0</span><span class="p">:</span><span class="n">i</span><span class="p">]</span>     <span class="c1"># First i-1 columns of X</span>

        <span class="c1"># Project onto the orthogonal complement of the col span of Z</span>
        <span class="n">M</span> <span class="o">=</span> <span class="n">I</span> <span class="o">-</span> <span class="n">Z</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">Z</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">Z</span><span class="p">)</span> <span class="o">@</span> <span class="n">Z</span><span class="o">.</span><span class="n">T</span>
        <span class="n">u</span> <span class="o">=</span> <span class="n">M</span> <span class="o">@</span> <span class="n">b</span>

        <span class="c1"># Normalize</span>
        <span class="n">U</span><span class="p">[:,</span> <span class="n">i</span><span class="p">]</span> <span class="o">=</span> <span class="n">u</span> <span class="o">/</span> <span class="n">np</span><span class="o">.</span><span class="n">sqrt</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">u</span> <span class="o">*</span> <span class="n">u</span><span class="p">))</span>

    <span class="k">return</span> <span class="n">U</span>
</pre></div>
</div>
</div>
</div>
<p>Here are the arrays we’ll work with</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">3</span><span class="p">,</span> <span class="o">-</span><span class="mi">3</span><span class="p">]</span>

<span class="n">X</span> <span class="o">=</span> <span class="p">[[</span><span class="mi">1</span><span class="p">,</span>  <span class="mi">0</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="o">-</span><span class="mi">6</span><span class="p">],</span>
     <span class="p">[</span><span class="mi">2</span><span class="p">,</span>  <span class="mi">2</span><span class="p">]]</span>

<span class="n">X</span><span class="p">,</span> <span class="n">y</span> <span class="o">=</span> <span class="p">[</span><span class="n">np</span><span class="o">.</span><span class="n">asarray</span><span class="p">(</span><span class="n">z</span><span class="p">)</span> <span class="k">for</span> <span class="n">z</span> <span class="ow">in</span> <span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)]</span>
</pre></div>
</div>
</div>
</div>
<p>First, let’s try projection of <span class="math notranslate nohighlight">\(y\)</span> onto the column space of
<span class="math notranslate nohighlight">\(X\)</span> using the ordinary matrix expression:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Py1</span> <span class="o">=</span> <span class="n">X</span> <span class="o">@</span> <span class="n">np</span><span class="o">.</span><span class="n">linalg</span><span class="o">.</span><span class="n">inv</span><span class="p">(</span><span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">X</span><span class="p">)</span> <span class="o">@</span> <span class="n">X</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
<span class="n">Py1</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.56521739,  3.26086957, -2.2173913 ])
</pre></div>
</div>
</div>
</div>
<p>Now let’s do the same using an orthonormal basis created from our
<code class="docutils literal notranslate"><span class="pre">gram_schmidt</span></code> function</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">U</span> <span class="o">=</span> <span class="n">gram_schmidt</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
<span class="n">U</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[ 0.4472136 , -0.13187609],
       [ 0.        , -0.98907071],
       [ 0.89442719,  0.06593805]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Py2</span> <span class="o">=</span> <span class="n">U</span> <span class="o">@</span> <span class="n">U</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
<span class="n">Py2</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.56521739,  3.26086957, -2.2173913 ])
</pre></div>
</div>
</div>
</div>
<p>This is the same answer. So far so good. Finally, let’s try the same
thing but with the basis obtained via QR decomposition:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Q</span><span class="p">,</span> <span class="n">R</span> <span class="o">=</span> <span class="n">qr</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">mode</span><span class="o">=</span><span class="s1">&#39;economic&#39;</span><span class="p">)</span>
<span class="n">Q</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([[-0.4472136 , -0.13187609],
       [-0.        , -0.98907071],
       [-0.89442719,  0.06593805]])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">Py3</span> <span class="o">=</span> <span class="n">Q</span> <span class="o">@</span> <span class="n">Q</span><span class="o">.</span><span class="n">T</span> <span class="o">@</span> <span class="n">y</span>
<span class="n">Py3</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([-0.56521739,  3.26086957, -2.2173913 ])
</pre></div>
</div>
</div>
</div>
<p>Again, we obtain the same answer.</p>
</section>
</div>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "binder-examples/jupyter-stacks-datascience",
            ref: "master",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                    </div>
                    
                </main> <!-- .page__content -->
                


                <footer class="qe-page__footer">

                    <p><a href="https://creativecommons.org/licenses/by-sa/4.0/"><img src="https://licensebuttons.net/l/by-sa/4.0/80x15.png"></a></p>

                    <p>Creative Commons License &ndash; This work is licensed under a Creative Commons Attribution-ShareAlike 4.0 International.</p>

                </footer> <!-- .page__footer -->

            </div> <!-- .page -->

            

            
            <div class="qe-sidebar bd-sidebar inactive" id="site-navigation">

                <div class="qe-sidebar__header">


                    Contents

                </div>

                <nav class="qe-sidebar__nav" id="qe-sidebar-nav" aria-label="Main navigation">
                    <p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Tools and Techniques
 </span>
</p>
<ul class="current nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1 current active active">
  <a class="current reference internal" href="#">
   1. Orthogonal Projections and Their Applications
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="stationary_densities.html">
   2. Continuous State Markov Chains
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="muth_kalman.html">
   3. Reverse Engineering a la Muth
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="discrete_dp.html">
   4. Discrete State Dynamic Programming
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  LQ Control
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="cons_news.html">
   5. Information and Consumption Smoothing
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="smoothing.html">
   6. Consumption Smoothing with Complete and Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="smoothing_tax.html">
   7. Tax Smoothing with Complete and Incomplete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="markov_jump_lq.html">
   8. Markov Jump Linear Quadratic Dynamic Programming
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tax_smoothing_1.html">
   9. How to Pay for a War: Part 1
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tax_smoothing_2.html">
   10. How to Pay for a War: Part 2
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="tax_smoothing_3.html">
   11. How to Pay for a War: Part 3
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lqramsey.html">
   12. Optimal Taxation in an LQ Economy
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Multiple Agent Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="arellano.html">
   13. Default Risk and Income Fluctuations
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="matsuyama.html">
   14. Globalization and Cycles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="coase.html">
   15. Coase’s Theory of the Firm
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dynamic Linear Economies
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="hs_recursive_models.html">
   16. Recursive Models of Dynamic Linear Economies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="growth_in_dles.html">
   17. Growth in Dynamic Linear Economies
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lucas_asset_pricing_dles.html">
   18. Lucas Asset Pricing Using DLE
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="irfs_in_hall_model.html">
   19. IRFs in Hall Models
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="permanent_income_dles.html">
   20. Permanent Income Model using the DLE Class
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rosen_schooling_model.html">
   21. Rosen Schooling Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="cattle_cycles.html">
   22. Cattle Cycles
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="hs_invertibility_example.html">
   23. Shock Non Invertibility
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Risk, Model Uncertainty, and Robustness
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="five_preferences.html">
   24. Risk and Model Uncertainty
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="entropy.html">
   25. Etymology of Entropy
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="robustness.html">
   26. Robustness
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="rob_markov_perf.html">
   27. Robust Markov Perfect Equilibrium
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Time Series Models
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="arma.html">
   28. Covariance Stationary Processes
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="estspec.html">
   29. Estimation of Spectra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="additive_functionals.html">
   30. Additive and Multiplicative Functionals
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="lu_tricks.html">
   31. Classical Control with Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="classical_filtering.html">
   32. Classical Prediction and Filtering With Linear Algebra
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="knowing_forecasts_of_others.html">
   33. Knowing the Forecasts of Others
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Asset Pricing and Finance
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="lucas_model.html">
   34. Asset Pricing II: The Lucas Asset Pricing Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="asset_pricing_lph.html">
   35. Elementary Asset Pricing Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="black_litterman.html">
   36. Two Modifications of Mean-Variance Portfolio Theory
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="BCG_complete_mkts.html">
   37. Irrelevance of Capital Structures with Complete Markets
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="BCG_incomplete_mkts.html">
   38. Equilibrium Capital Structures with Incomplete Markets
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Dynamic Programming Squared
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="un_insure.html">
   39. Optimal Unemployment Insurance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="dyn_stack.html">
   40. Stackelberg Plans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calvo_machine_learn.html">
   41. Machine Learning a Ramsey Plan
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calvo.html">
   42. Time Inconsistency of Ramsey Plans
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="calvo_abreu.html">
   43. Sustainable Plans for a Calvo Model
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="opt_tax_recur.html">
   44. Optimal Taxation with State-Contingent Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="amss.html">
   45. Optimal Taxation without State-Contingent Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="amss2.html">
   46. Fluctuating Interest Rates Deliver Fiscal Insurance
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="amss3.html">
   47. Fiscal Risk and Government Debt
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chang_ramsey.html">
   48. Competitive Equilibria of a Model of Chang
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="chang_credible.html">
   49. Credible Government Policies in a Model of Chang
  </a>
 </li>
</ul>
<p aria-level="2" class="caption" role="heading">
 <span class="caption-text">
  Other
 </span>
</p>
<ul class="nav bd-sidenav nav sidenav_l1">
 <li class="toctree-l1">
  <a class="reference internal" href="troubleshooting.html">
   50. Troubleshooting
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="zreferences.html">
   51. References
  </a>
 </li>
 <li class="toctree-l1">
  <a class="reference internal" href="status.html">
   52. Execution Statistics
  </a>
 </li>
</ul>

                </nav>

                <div class="qe-sidebar__footer">

                </div>

            </div> <!-- .sidebar -->
            
        </div> <!-- .main -->

        <div class="qe-toolbar">

            <div class="qe-toolbar__inner">

                <ul class="qe-toolbar__main">
                    <li data-tippy-content="Table of Contents" class="btn__sidebar"><i data-feather="menu"></i></li>
                    <li data-tippy-content="Home"><a href="intro.html"><i data-feather="home"></i></a></li>
                    <li class="btn__qelogo"><a href="https://quantecon.org" title=""><span class="show-for-sr">QuantEcon</span></a></li>
                </ul>

                <ul class="qe-toolbar__links">
                    <li class="btn__search">
                        <form action="search.html" method="get">
                            <input type="search" class="form-control" name="q" id="search-input" placeholder="Search..." aria-label="Search..." autocomplete="off" accesskey="k">
                            <i data-feather="search" id="search-icon"></i>
                        </form>
                    </li>
                    <li data-tippy-content="Fullscreen" class="btn__fullscreen"><i data-feather="maximize"></i></li>
                    <li data-tippy-content="Increase font size" class="btn__plus"><i data-feather="plus-circle"></i></li>
                    <li data-tippy-content="Decrease font size" class="btn__minus"><i data-feather="minus-circle"></i></li>
                    <li data-tippy-content="Change contrast" class="btn__contrast"><i data-feather="sunset"></i></li>
                    <li data-tippy-content="Download Notebook"><a href="/_notebooks/orth_proj.ipynb" download><i data-feather="download-cloud"></i></a></li>
                    <li class="settings-button" id="settingsButton"><div data-tippy-content="Launch Notebook"><i data-feather="play-circle"></i></div></li>
                        <li class="download-pdf" id="downloadButton"><i data-feather="file"></i></li>
                    <li data-tippy-content="View Source"><a target="_blank" href="https://github.com/QuantEcon/lecture-python-advanced.myst/blob/main/lectures/orth_proj.md" download><i data-feather="github"></i></a></li>
                </ul>

            </div>

        </div> <!-- .toolbar -->
        <div id="downloadPDFModal" style="display: none;">
            <ul class="pdf-options" style="display: block;">
                <li class="download-pdf-book" onClick="window.print()">
                    <p>Lecture (PDF)</p>
                </li>
                <li class="download-pdf-file">
                    <a href="/_pdf/quantecon-python-advanced.pdf" download><p>Book (PDF)</p></a>
                </li>
            </ul>
        </div>
        <div id="settingsModal" style="display: none;">
            <p class="modal-title"> Notebook Launcher </p>
            <div class="modal-desc">
            <p>
                Choose public or private cloud service for "Launch" button.
            </p>
            </div>
            <p class="modal-subtitle">Select a server</p>
            <ul class="modal-servers">
            <li class="active launcher-public">
                <span class="label">Public</span>
                <select id="launcher-public-input">
                
                    <option value="https://colab.research.google.com/github/QuantEcon/lecture-python-advanced.notebooks/blob/main/orth_proj.ipynb">Colab</option>
                
                </select>
                <i class="fas fa-check-circle"></i>
            </li>
            <li class="launcher-private">
                <span class="label">Private</span>
                <input type="text" id="launcher-private-input" data-repourl="https://github.com/QuantEcon/lecture-python-advanced.notebooks" data-urlpath="tree/lecture-python-advanced.notebooks/orth_proj.ipynb" data-branch=main>
                <i class="fas fa-check-circle"></i>
            </li>
            </ul>
            <p class="launch"><a href="https://colab.research.google.com/github/QuantEcon/lecture-python-advanced.notebooks/blob/main/orth_proj.ipynb" id="advancedLaunchButton" target="_blank">Launch Notebook</a></p>
            <script>
                // QuantEcon Notebook Launcher
                const launcherTypeElements = document.querySelectorAll('#settingsModal .modal-servers li');
                // Highlight the server type if previous selection exists
                if (typeof localStorage.launcherType !== 'undefined') {
                  for (var i = 0; i < launcherTypeElements.length; i++) {
                    launcherTypeElements[i].classList.remove('active');
                    if ( launcherTypeElements[i].classList.contains(localStorage.launcherType) ) {
                      launcherTypeElements[i].classList.add('active');
                    }
                  }
                }
                // Highlight server type on click and set local storage value
                for (var i = 0; i < launcherTypeElements.length; i++) {
                  launcherTypeElements[i].addEventListener('click', function() {
                    for (var j = 0; j < launcherTypeElements.length; j++) {
                      launcherTypeElements[j].classList.remove('active');
                    }
                    this.classList.add('active');
                    if ( this.classList.contains('launcher-private') ) {
                      localStorage.launcherType = 'launcher-private';
                    } else if ( this.classList.contains('launcher-public') ) {
                      localStorage.launcherType = 'launcher-public';
                    }
                    setLaunchServer();
                  })
                }
                const launcherPublic = document.getElementById('launcher-public-input');
                const launcherPrivate = document.getElementById('launcher-private-input');
                const pageName = "orth_proj";
                const repoURL = "https://github.com/QuantEcon/lecture-python-advanced.notebooks";
                const urlPath = "tree/lecture-python-advanced.notebooks/orth_proj.ipynb";
                const branch = "main"
                const launchNotebookLink = document.getElementById('advancedLaunchButton');

                // Highlight public server option if previous selection exists
                if (typeof localStorage.launcherPublic !== 'undefined') {
                  launcherPublic.value = localStorage.launcherPublic;
                }
                // Update local storage upon public server selection
                launcherPublic.addEventListener('change', (event) => {
                  setLaunchServer();
                });
                // Populate private server input if previous entry exists
                if (typeof localStorage.launcherPrivate !== 'undefined') {
                  launcherPrivate.value = localStorage.launcherPrivate;
                }
                // Update local storage when a private server is entered
                launcherPrivate.addEventListener('input', (event) => {
                  setLaunchServer();
                });

                // Function to update the "Launch Notebook" link href
                function setLaunchServer() {
                  launchNotebookLink.removeAttribute("style")
                  if ( localStorage.launcherType == 'launcher-private' ) {
                    let repoPrefix = "/jupyter/hub/user-redirect/git-pull?repo=" + repoURL + "&branch=" + branch + "&urlpath=" + urlPath;
                    launcherPrivateValue = launcherPrivate.value
                    if (!launcherPrivateValue) {
                        launchNotebookLink.removeAttribute("href")
                        launchNotebookLink.style.background = "grey"
                        return
                    }
                    localStorage.launcherPrivate = launcherPrivateValue;
                    privateServer = localStorage.launcherPrivate.replace(/\/$/, "")
                    if (!privateServer.includes("http")) {
                        privateServer = "http://" + privateServer
                    }
                    launchNotebookLinkURL = privateServer + repoPrefix;
                  } else if ( localStorage.launcherType == 'launcher-public' ) {
                    launcherPublicValue = launcherPublic.options[launcherPublic.selectedIndex].value;
                    localStorage.launcherPublic = launcherPublicValue;
                    launchNotebookLinkURL = localStorage.launcherPublic;
                  }
                  if (launchNotebookLinkURL) launchNotebookLink.href = launchNotebookLinkURL;
                }
                // Check if user has previously selected a server
                if ( (typeof localStorage.launcherPrivate !== 'undefined') || (typeof localStorage.launcherPublic !== 'undefined') ) {
                  setLaunchServer();
                }
                </script>

        </div>

    </div> <!-- .wrapper-->
  </body>
</html>